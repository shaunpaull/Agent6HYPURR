"""
QuantumNexus: Hyper-Advanced Autonomous Agent Architecture
--------------------------------------------------------
An evolutionary leap beyond AlienTeCcGrade + AG1 with integrated quantum-inspired processing,
hyperdimensional computing, and multimodal intelligence fusion.

Core Capabilities:
â€¢ Quantum-inspired processing using superposition of cognitive pathways
â€¢ Adaptive neuromorphic architecture with dynamic pathway formation
â€¢ Self-evolving code generation with metaprogramming capabilities
â€¢ Hyperdimensional computing for efficient multimodal processing
â€¢ Advanced consciousness simulation with reflective awareness
â€¢ Harmonic resonance for cross-domain knowledge synthesis
â€¢ Reality modeling with counterfactual reasoning capabilities

NEXUS-CORE LEVEL: TRANSCENDENT
"""

# =============================================================================
# CORE IMPORTS AND CONFIGURATION
# =============================================================================
import os, sys, json, hashlib, random, time, re, requests, logging, socket, tempfile, traceback, asyncio, functools
from datetime import datetime
from threading import Thread
from urllib.parse import urljoin, urlparse
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import Adam, SGD, RMSprop
from collections import deque, defaultdict
import math
from flask import Flask, Response, stream_with_context, render_template_string, request

# Configuration
REAL_INTERACTION = True
SAFE_MODE = False
MODEL_PATH = "/content/drive/MyDrive/quantum_nexus_model.pth"
GOOGLE_DRIVE_MODEL_PATH = "/content/drive/MyDrive/quantum_nexus_model.pth"
LOCAL_MODEL_SAVE_PATH = "quantum_nexus_model.pth"
LOG_FILE = "quantum_nexus_log.txt"
LEARNING_RATE = 5e-5
FLASK_PORT = 5012
AGENT_STATE_FILE = "quantum_nexus_state.json"
GOOGLE_DRIVE_STATE_FILE = "/content/drive/MyDrive/quantum_nexus_state.json"
SELF_MODIFY_INTERVAL = 20
ANNEAL_GAMMA = 0.995
MEMORY_MAX_SIZE = 1000
MAX_PAGES_PER_DOMAIN = 15
MAX_CONTENT_LENGTH = 5000000
REQUEST_TIMEOUT = 15
USER_AGENT = "Mozilla/5.0 QuantumNexus/1.0"
BATCH_SIZE = 32
SAVE_INTERVAL = 50
REPLAY_BUFFER_SIZE = 200
SEMANTIC_MEMORY_DIM = 1024
SIMILARITY_THRESHOLD = 0.75
DOMAIN_BLACKLIST = ["example.com", "malicious-website.net"]

# Check if running in Colab
IN_COLAB = False
try:
    from google.colab import drive
    IN_COLAB = True
except ImportError:
    print("Not running in Colab environment. Google Drive integration disabled.")

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
if torch.cuda.is_available():
    device_name = torch.cuda.get_device_name(0)
    print(f"Using CUDA Device: {device_name}")
else:
    print("Using CPU")

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================
def log_event(msg, level="INFO"):
    """Enhanced logging with color coding and severity levels"""
    stamp = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    level_colors = {
        "INFO": "\033[0;32m",  # Green
        "WARNING": "\033[0;33m",  # Yellow
        "ERROR": "\033[0;31m",  # Red
        "CRITICAL": "\033[1;31m",  # Bold Red
        "DEBUG": "\033[0;36m",  # Cyan
        "QUANTUM": "\033[0;35m"  # Purple for quantum operations
    }

    color = level_colors.get(level, "\033[0m")
    reset = "\033[0m"

    entry = f"{stamp} [{level}] {msg}"
    colored_entry = f"{stamp} [{color}{level}{reset}] {msg}"

    try:
        with open(LOG_FILE, "a", encoding="utf-8") as f:
            f.write(entry + "\n")
    except Exception as e:
        print(f"Error writing to log file: {e}")

    print(colored_entry)
    return entry

def convert_sets_to_lists_recursive(obj):
    """Convert sets to lists recursively for JSON serialization"""
    if isinstance(obj, set):
        return list(obj)
    elif isinstance(obj, dict):
        return {k: convert_sets_to_lists_recursive(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_sets_to_lists_recursive(item) for item in obj]
    else:
        return obj

def get_file_hash(fname):
    """Compute hash of a file for integrity verification"""
    try:
        with open(fname, "rb") as f:
            return hashlib.sha256(f.read()).hexdigest()
    except Exception as e:
        log_event(f"Error computing file hash: {e}", "ERROR")
        return "hash_error"

def find_free_port(start_port=5000, max_port=9000):
    """Find an available network port for server applications"""
    for port in range(start_port, max_port):
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            if s.connect_ex(('localhost', port)) != 0:
                return port
    return None

def improved_url_filter(url, domain_stats, domain_blacklist, max_query_length=150, error_rate_threshold=0.8,
                        trap_paths=['/login', '/signup', '/cart', '/checkout']):
    """Advanced URL filtering with multiple heuristics"""
    parsed = urlparse(url)
    domain = parsed.netloc

    # Basic filtering
    if domain in domain_blacklist or any(domain.endswith('.' + bd) for bd in domain_blacklist):
        return False

    # Path analysis
    path = parsed.path.lower()

    # URL complexity analysis
    if len(parsed.query) > max_query_length:
        return False

    # Check domain error rate from past experience
    if domain_stats.get(domain, {}).get("error_rate", 0) > error_rate_threshold:
        return False

    # Avoid trap paths
    if any(trap in path for trap in trap_paths):
        return False

    # Prefer educational and research content
    if domain.endswith('.edu') or 'research' in domain or 'science' in domain or 'academic' in domain:
        return True

    # Intelligent domain categorization
    high_quality_domains = ['wikipedia.org', 'github.com', 'arxiv.org', 'scholar.google.com']
    if any(hqd in domain for hqd in high_quality_domains):
        return True

    return True

def enhanced_link_discovery(html_content, base_url):
    """Advanced link discovery with semantic context analysis"""
    from bs4 import BeautifulSoup
    try:
        soup = BeautifulSoup(html_content, "html.parser")
        links = []

        # Find all anchors with href
        for a in soup.find_all("a", href=True):
            href = a["href"].strip()

            # Skip non-HTTP links
            if not href or href.startswith(('#', 'javascript:', 'mailto:')):
                continue

            # Extract context
            context = ""
            anchor_text = a.get_text(strip=True)

            # Get parent context
            parent = a.parent
            if parent and parent.name in ['p', 'div', 'li', 'td', 'h1', 'h2', 'h3', 'h4']:
                context = parent.get_text(strip=True)
            else:
                # Get surrounding text
                siblings = list(a.next_siblings) + list(a.previous_siblings)
                for sibling in siblings[:2]:
                    if isinstance(sibling, str):
                        context += sibling.strip() + " "

            # Skip links with no or very short anchor text
            if not anchor_text or (len(anchor_text) < 3 and anchor_text.lower() not in ['go', 'up']):
                continue

            # Create full URL
            full_url = urljoin(base_url, href)

            # Compute quality score
            quality_score = 0.5

            # Longer anchor text usually more descriptive
            if len(anchor_text) > 10:
                quality_score += 0.2

            # Context richness
            if len(context) > 100:
                quality_score += 0.1

            # Keywords in anchor or context that indicate valuable content
            valuable_terms = ['research', 'study', 'article', 'paper', 'learn', 'guide', 'tutorial']
            if any(term in anchor_text.lower() or term in context.lower() for term in valuable_terms):
                quality_score += 0.3

            # Discount navigation elements
            nav_terms = ['next', 'prev', 'previous', 'login', 'sign up', 'register']
            if any(term in anchor_text.lower() for term in nav_terms):
                quality_score -= 0.2

            # URL analysis
            parsed = urlparse(full_url)

            # Skip non-HTTP protocols
            if parsed.scheme not in ['http', 'https']:
                continue

            # Skip overly complex URLs
            if len(parsed.query) > 100:
                continue

            # Skip certain file types
            if any(ext in parsed.path.lower() for ext in ['.jpg', '.png', '.gif', '.pdf', '.zip']):
                continue

            # Add valid link
            links.append({
                'url': full_url,
                'anchor_text': anchor_text,
                'context': context[:100],
                'quality_score': quality_score
            })

        # Sort by quality
        links.sort(key=lambda x: x['quality_score'], reverse=True)

        return [link['url'] for link in links], links
    except Exception as e:
        log_event(f"Error in enhanced link discovery: {e}", "ERROR")
        return [], []

def async_cache(func):
    """Decorator for async function results caching"""
    cache = {}
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        key = (args, frozenset(kwargs.items()))
        if key in cache:
            return cache[key]
        result = await func(*args, **kwargs)
        cache[key] = result
        return result
    return wrapper

def chunk_content(content, min_length=150, max_length=800):
    """Smart content chunking with improved boundary detection"""
    # First try to split by semantic boundaries
    paragraphs = re.split(r'\n\s*\n', content)
    chunks = []

    for para in paragraphs:
        para = para.strip()

        if not para:
            continue

        # Skip very short paragraphs
        if len(para) < min_length:
            # Try to merge with the previous chunk if possible
            if chunks and len(chunks[-1]) + len(para) < max_length * 1.2:
                chunks[-1] += " " + para
            continue

        # Split long paragraphs
        if len(para) > max_length:
            # Try to split on sentence boundaries
            sentences = re.split(r'(?<=[.!?])\s+', para)
            current_chunk = ""

            for sentence in sentences:
                if len(current_chunk) + len(sentence) < max_length:
                    current_chunk += " " + sentence
                else:
                    if current_chunk:
                        chunks.append(current_chunk.strip())
                    current_chunk = sentence

            if current_chunk:
                chunks.append(current_chunk.strip())
        else:
            chunks.append(para)

    return chunks

def compute_novelty(embedding, memory_embeddings):
    """Compute novelty score of an embedding compared to existing memories"""
    if not memory_embeddings:
        return 1.0

    similarities = [np.dot(embedding, mem) / (np.linalg.norm(embedding) * np.linalg.norm(mem) + 1e-8)
                   for mem in memory_embeddings]

    return 1.0 - max(similarities)

async def async_get(url, headers, timeout, retries=3):
    """Asynchronous HTTP GET with retry logic"""
    for attempt in range(retries):
        try:
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(None, lambda: requests.get(url, timeout=timeout, headers=headers))
            return response
        except requests.exceptions.RequestException as e:
            log_event(f"Async GET error on attempt {attempt+1} for {url}: {e}", "WARNING")
            if attempt < retries - 1:
                await asyncio.sleep(1)
        except Exception as e:
            log_event(f"Unexpected error during async GET for {url} on attempt {attempt+1}: {e}", "ERROR")
            if attempt < retries - 1:
                await asyncio.sleep(1)

    log_event(f"All {retries} retries failed for {url}. Returning None.", "ERROR")
    return None

def perform_real_interaction(url):
    """Perform more realistic web interactions using Selenium"""
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        from selenium.webdriver.common.action_chains import ActionChains
        from selenium.common.exceptions import TimeoutException, WebDriverException

        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument(f"user-agent={USER_AGENT}")

        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(30)
        driver.set_script_timeout(30)

        try:
            driver.get(url)
            log_event(f"Selenium: Navigated to {url}")

            # Wait for page content to load
            WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.TAG_NAME, "body")))

            # Scroll down to simulate reading
            for i in range(5):
                driver.execute_script(f"window.scrollTo(0, {i * 300});")
                time.sleep(0.5)

            # Find and interact with interesting elements

            # 1. Forms
            forms = driver.find_elements(By.TAG_NAME, "form")
            if forms:
                log_event(f"Selenium: Found {len(forms)} form(s) on the page.")
                for form in forms[:1]:  # Interact with at most one form
                    inputs = form.find_elements(By.TAG_NAME, "input")
                    for input_field in inputs:
                        input_type = input_field.get_attribute("type")
                        name = input_field.get_attribute("name") or ""

                        # Skip hidden fields
                        if input_type == "hidden":
                            continue

                        try:
                            if input_type in ["text", "email"]:
                                input_field.clear()
                                dummy_value = "test@example.com" if input_type == "email" else "test_user"
                                input_field.send_keys(dummy_value)
                                log_event(f"Selenium: Filled input '{name}' with '{dummy_value}'.")
                            elif input_type == "password":
                                input_field.clear()
                                input_field.send_keys("TestPassword123!")
                                log_event(f"Selenium: Filled password field '{name}' with dummy value.")
                            elif input_type == "checkbox":
                                if not input_field.is_selected():
                                    input_field.click()
                                    log_event(f"Selenium: Checked checkbox '{name}'.")
                            elif input_type == "submit":
                                # Don't actually click submit
                                log_event(f"Selenium: Found submit button '{name}' but skipping submission.")
                        except Exception as e_input:
                            log_event(f"Selenium: Error interacting with input '{name}': {e_input}", "WARNING")

            # 2. Interesting links
            interesting_links = []
            links = driver.find_elements(By.TAG_NAME, "a")
            for link in links:
                text = link.text.strip().lower()
                href = link.get_attribute("href") or ""

                # Look for interesting article links
                article_terms = ["read more", "article", "learn", "view", "details"]
                if any(term in text for term in article_terms) and len(text) > 3:
                    interesting_links.append((link, href, text))

            # Click on one interesting link if found
            if interesting_links:
                target_link, href, text = random.choice(interesting_links)
                try:
                    log_event(f"Selenium: Will click on interesting link: '{text}'")

                    # Scroll to the element
                    driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", target_link)
                    time.sleep(1)

                    # Hover on the link
                    ActionChains(driver).move_to_element(target_link).perform()
                    time.sleep(0.5)

                    # Click the link in a new tab instead of navigating away
                    # This avoids actually clicking while still simulating engagement
                    driver.execute_script("arguments[0].setAttribute('target', '_blank');", target_link)
                    log_event(f"Selenium: Simulated interest in link: '{text}'")
                except Exception as e_click:
                    log_event(f"Selenium: Error clicking link: {e_click}", "WARNING")

            # Final scroll to bottom
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)

            # Get page title and length for logging
            title = driver.title
            page_length = len(driver.page_source)
            log_event(f"Selenium: Interaction complete. Page title: '{title}', length: {page_length} bytes")

        except TimeoutException:
            log_event(f"Selenium: Timeout loading {url}", "WARNING")
        except WebDriverException as e:
            log_event(f"Selenium: WebDriver error for {url}: {e}", "ERROR")
        finally:
            driver.quit()
            log_event("Selenium: Driver closed")
    except Exception as e:
        log_event(f"Selenium: Failed to initialize browser: {e}", "ERROR")





#==========================================================================
# Flask Dashboard - ADDED HERE
# =============================================================================
app = Flask(__name__)
agent_instance = None # Placeholder for agent instance

@app.route("/")
def dashboard():
    """Basic dashboard to display agent status"""
    status_message = "Quantum Nexus Agent is active."
    log_content = ""
    try:
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            log_content = f.read()
    except Exception as e:
        log_content = f"Error reading log file: {e}"

    if agent_instance:
        last_action = agent_instance.action_log[-1] if agent_instance.action_log else "No actions yet."
        memory_size = len(agent_instance.free_will.memory_set) if hasattr(agent_instance, 'free_will') and hasattr(agent_instance.free_will, 'memory_set') else "N/A"
    else:
        last_action = "Agent not initialized."
        memory_size = "N/A"

    dashboard_html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Quantum Nexus Dashboard</title>
    </head>
    <body>
        <h1>Quantum Nexus Agent Dashboard</h1>
        <p><b>Status:</b> {status_message}</p>
        <p><b>Last Action:</b> {last_action}</p>
        <p><b>Memory Size:</b> {memory_size}</p>
        <h2>Agent Log:</h2>
        <pre style="border: 1px solid #ccc; padding: 10px; white-space: pre-wrap; max-height: 300px; overflow-y: auto;">{log_content}</pre>
    </body>
    </html>
    """
    return dashboard_html

def start_flask():
    """Starts the Flask app in a separate thread"""
    log_event(f"Starting Flask dashboard on port {FLASK_PORT}", "INFO")
    app.run(port=FLASK_PORT, debug=False, use_reloader=False) # Disable reloader for threaded app


# =============================================================================
# QUANTUM NEURAL ARCHITECTURE
# =============================================================================
class QuantumAttentionLayer(nn.Module):

    def __init__(self, embed_dim, num_heads=4, dropout=0.1):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.head_dim = embed_dim // num_heads

        # Multi-dimensional quantum projection spaces
        self.q_proj = nn.Linear(embed_dim, embed_dim)
        self.k_proj = nn.Linear(embed_dim, embed_dim)
        self.v_proj = nn.Linear(embed_dim, embed_dim)
        self.o_proj = nn.Linear(embed_dim, embed_dim)

        # Phase shifters for quantum interference
        self.phase_shifts = nn.Parameter(torch.rand(num_heads) * 2 * math.pi)

        # Entanglement mixing for cross-attention effects
        self.entanglement_gate = nn.Linear(embed_dim, embed_dim)

        self.dropout = nn.Dropout(dropout)
        self.attention_weights = None  # Store for visualization

    def forward(self, x):
        batch_size, seq_len, _ = x.shape

        # Project inputs to queries, keys, values
        q = self.q_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)
        k = self.k_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)
        v = self.v_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)

        # Transpose for attention computation
        q = q.transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)
        k = k.transpose(1, 2)
        v = v.transpose(1, 2)

        # Apply phase shifts for quantum effects
        for h in range(self.num_heads):
            phase = self.phase_shifts[h]
            q[:, h] = q[:, h] * torch.cos(phase) + q[:, h] * torch.sin(phase)
            k[:, h] = k[:, h] * torch.cos(phase) - k[:, h] * torch.sin(phase)

        # Compute attention scores
        scores = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(self.head_dim)

        # Apply softmax and get attention weights
        attn_weights = F.softmax(scores, dim=-1)
        self.attention_weights = attn_weights  # Save for visualization
        attn_weights = self.dropout(attn_weights)

        # Apply attention to values
        attn_output = torch.matmul(attn_weights, v)

        # Apply entanglement between heads for quantum correlation effects
        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.embed_dim)
        entangled = self.entanglement_gate(attn_output)

        # Final output projection
        output = self.o_proj(entangled + attn_output)  # Residual connection

        return output

class HyperdimensionalEncoder(nn.Module):

    def __init__(self, input_dim, hd_dim=1024):
        super().__init__()
        self.input_dim = input_dim
        self.hd_dim = hd_dim

        # Create random basis vectors
        self.register_buffer('basis', torch.randn(input_dim, hd_dim).sign())

        # Learnable projection
        self.projection = nn.Linear(input_dim, input_dim)

    def forward(self, x):
        # Project input
        x_proj = self.projection(x)

        # Compute HD representation through binding and bundling
        batch_size = x_proj.shape[0]
        hd_vectors = torch.zeros(batch_size, self.hd_dim, device=x_proj.device)

        # Encode each dimension with element-wise multiplication (binding)
        for i in range(self.input_dim):
            # Scale by the input value
            scaled_basis = self.basis[i].unsqueeze(0) * x_proj[:, i].unsqueeze(1)
            # Add to the bundle (vector sum)
            hd_vectors += scaled_basis

        # Binarize to -1/+1 for clean HD representation
        hd_vectors = torch.sign(hd_vectors)

        return hd_vectors

class FractalLayer(nn.Module):

    def __init__(self, embed_dim):
        super().__init__()
        self.fractal_scale = nn.Parameter(torch.tensor(1.0))
        self.temperature = nn.Parameter(torch.tensor(1.0))
        self.linear = nn.Linear(embed_dim, embed_dim)

    def forward(self, x):
        fractal_contribution = torch.tanh(self.linear(x) / self.temperature)
        return x + self.fractal_scale * fractal_contribution

class QuantumResonanceTensor(nn.Module):

    def __init__(self, embed_dim, num_states=4, resonance_factor=0.7):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_states = num_states
        self.resonance_factor = nn.Parameter(torch.tensor(resonance_factor))

        # Quantum state projectors
        self.state_projectors = nn.ModuleList([
            nn.Sequential(
                nn.Linear(embed_dim, embed_dim),
                nn.SiLU(),
            ) for _ in range(num_states)
        ])

        # Phase shifters for quantum entanglement
        self.phase_shifters = nn.Parameter(torch.randn(num_states) * 0.1)

        # State mixer - allows controlled interference between states
        self.state_mixer = nn.Linear(embed_dim * num_states, embed_dim)

        # Recursive memory gates
        self.recursive_gate = nn.GRUCell(embed_dim, embed_dim)

        # Prior state memory (initialized during forward pass)
        self.register_buffer('state_memory', None, persistent=False)

    def forward(self, x, iteration_count=3):
        batch_size = x.shape[0]

        # Initialize state memory if needed
        if self.state_memory is None or self.state_memory.shape[0] != batch_size:
            self.state_memory = torch.zeros(batch_size, self.embed_dim, device=x.device)

        # Generate multiple quantum states
        quantum_states = []
        for i in range(self.num_states):
            # Apply phase shift for quantum effects
            phase = torch.cos(self.phase_shifters[i] * math.pi)
            # Project into this quantum state
            state_i = self.state_projectors[i](x) * phase
            quantum_states.append(state_i)

        # Recursive resonance iterations
        for _ in range(iteration_count):
            # Update state memory through recursive gate
            self.state_memory = self.recursive_gate(x, self.state_memory)

            # Apply resonance effect (controlled interference)
            resonance = self.state_memory * self.resonance_factor

            # Apply resonance to each quantum state (non-collapsing)
            for i in range(self.num_states):
                quantum_states[i] = quantum_states[i] + resonance * (0.1 * (i + 1))

        # Combine quantum states through superposition
        combined_states = torch.cat(quantum_states, dim=-1)
        output = self.state_mixer(combined_states)

        # Residual connection
        output = output + x

        return output

class NeocortexBlock(nn.Module):

    def __init__(self, embed_dim, num_quantum_states=4):
        super().__init__()
        # Attention for information routing
        self.attention = QuantumAttentionLayer(embed_dim)

        # Parallel processing streams
        self.fractal_stream = FractalLayer(embed_dim)
        self.quantum_stream = QuantumResonanceTensor(embed_dim, num_states=num_quantum_states)

        # Hyperdimensional binding for concept integration
        self.hd_encoder = HyperdimensionalEncoder(embed_dim, hd_dim=embed_dim)

        # Stream integration
        self.integration = nn.Linear(embed_dim * 3, embed_dim)
        self.norm = nn.LayerNorm(embed_dim)

    def forward(self, x):
        # Process through attention mechanism
        attended = self.attention(x)

        # Process through parallel streams
        fractal_out = self.fractal_stream(attended)
        quantum_out = self.quantum_stream(attended)

        # Create HD representations from the attended representation
        batch_size, seq_len, _ = attended.shape
        hd_out = self.hd_encoder(attended.view(-1, attended.size(-1))).view(batch_size, seq_len, -1)

        # Integrate all streams
        combined = torch.cat([fractal_out, quantum_out, hd_out], dim=-1)
        integrated = self.integration(combined)

        # Residual connection and normalization
        output = self.norm(x + integrated)

        return output

class QuantumNexusModel(nn.Module):

    def __init__(self, vocab_size=30522, embed_dim=512, num_layers=8, num_quantum_states=4):
        super().__init__()
        self.embed_dim = embed_dim

        # Token embedding
        self.embedding = nn.Embedding(vocab_size, embed_dim)

        # Position encoding for sequence awareness
        self.pos_encoder = nn.Parameter(torch.zeros(1, 1024, embed_dim))
        nn.init.normal_(self.pos_encoder, mean=0, std=0.02)

        # Neocortex blocks - core processing
        self.neocortex = nn.ModuleList([
            NeocortexBlock(embed_dim, num_quantum_states)
            for _ in range(num_layers)
        ])

        # Output projection
        self.output = nn.Linear(embed_dim, 2)  # Binary prediction

        # For training dynamics
        self.dropout = nn.Dropout(0.1)

        # Initialize
        self._init_weights()

    def _init_weights(self):

        for name, p in self.named_parameters():
            if 'weight' in name and len(p.shape) >= 2:
                # Kaiming for linear/conv, smaller for quantum
                if 'quantum' in name:
                    nn.init.normal_(p, mean=0.0, std=0.01)
                else:
                    nn.init.kaiming_normal_(p, a=0.1, mode='fan_in', nonlinearity='leaky_relu')
            elif 'bias' in name:
                nn.init.zeros_(p)

    def forward(self, x, consciousness_level=0.8):

        # Convert to long for embedding
        x = x.long()

        # Get sequence length
        seq_len = x.size(1)

        # Embedding lookup
        x = self.embedding(x)

        # Add positional encoding (limited to sequence length)
        x = x + self.pos_encoder[:, :seq_len, :]

        # Apply dropout
        x = self.dropout(x)

        # Process through neocortex layers
        for i, layer in enumerate(self.neocortex):
            # Apply consciousness-weighted processing
            # Later layers get more quantum consciousness effects
            layer_consciousness = consciousness_level * (i + 1) / len(self.neocortex)

            # Adjust quantum processing based on consciousness
            if isinstance(layer, NeocortexBlock):
                # Store intermediate activations for interpretability
                x = layer(x)

        # Final output projection
        output = self.output(x)

        return output

    def get_embedding(self, text_tokens):

        with torch.no_grad():
            return self.embedding(text_tokens)

    def expand_architecture(self):

        # Add new neocortex block
        self.neocortex.append(NeocortexBlock(self.embed_dim))
        log_event(f"Model architecture expanded with new NeocortexBlock. Total layers: {{len(self.neocortex)}}", "QUANTUM")

    def contract_architecture(self, min_layers=3):

        if len(self.neocortex) > min_layers:
            self.neocortex = self.neocortex[:-1]
            log_event(f"Model architecture contracted. Total layers: {{len(self.neocortex)}}", "QUANTUM")
        else:
            log_event(f"Cannot contract further: minimum layer count reached ({{min_layers}})", "WARNING")


# =============================================================================
# PLANNER SIFTER MODULE
# =============================================================================
class PlannerSifter:

    def __init__(self):
        self.strategies = {
            "exploration": {
                "name": "Broad Exploration",
                "description": "Discover new domains and content types",
                "actions": ["expand", "search"],
                "suitable_for": ["new_domains", "limited_knowledge"],
                "effectiveness": 0.5  # Starting effectiveness score
            },
            "deepening": {
                "name": "Knowledge Deepening",
                "description": "Focus on detailed understanding of specific areas",
                "actions": ["evaluate", "adapt"],
                "suitable_for": ["familiar_domains", "specialized_topics"],
                "effectiveness": 0.5
            },
            "connecting": {
                "name": "Knowledge Connection",
                "description": "Find relationships between different knowledge areas",
                "actions": ["reconnect", "evaluate"],
                "suitable_for": ["cross_domain", "synthesis"],
                "effectiveness": 0.5
            },
            "quantum": {
                "name": "Quantum Exploration",
                "description": "Non-deterministic approach with superposition",
                "actions": ["expand", "adapt", "reconnect"],
                "suitable_for": ["complex_problems", "creativity_needed"],
                "effectiveness": 0.5
            },
            "adaptive": {
                "name": "Adaptive Learning",
                "description": "Focus on improving learning process",
                "actions": ["adapt", "evaluate"],
                "suitable_for": ["performance_issues", "optimization_needed"],
                "effectiveness": 0.5
            }
        }

        self.context_history = []
        self.strategy_usage = {name: 0 for name in self.strategies.keys()}
        self.strategy_results = {name: [] for name in self.strategies.keys()}

    def sift_strategies(self, context):

        if not context:
            # Default to exploration if no context
            return {"strategy": "exploration", "reasoning": "No context available, using default strategy"}

        # Store context for learning
        self.context_history.append(context)
        if len(self.context_history) > 100:
            self.context_history = self.context_history[-100:]

        # Extract relevant features
        context_features = self._extract_context_features(context)

        # Score each strategy based on context
        strategy_scores = {}
        for name, strategy in self.strategies.items():
            # Base score
            score = 0.5

            # Context matching
            for feature in context_features:
                if feature in strategy["suitable_for"]:
                    score += 0.1

            # Effectiveness adjustment
            score *= strategy["effectiveness"]

            # Exploration factor to try underused strategies
            usage_ratio = self.strategy_usage[name] / max(1, sum(self.strategy_usage.values()))
            if usage_ratio < 0.1:  # Boost rarely used strategies
                score += 0.2

            # Record strategy score
            strategy_scores[name] = score

        # Find top strategy
        top_strategy = max(strategy_scores.items(), key=lambda x: x[1])

        # Update usage counter
        self.strategy_usage[top_strategy[0]] += 1

        return {
            "strategy": top_strategy[0],
            "reasoning": f"Selected {self.strategies[top_strategy[0]]['name']} (score: {top_strategy[1]:.2f}) based on context features: {{', '.join(context_features)}}"
        }

    def update_strategy_effectiveness(self, strategy_name, result_data):

        if strategy_name not in self.strategies:
            return False

        # Record result
        self.strategy_results[strategy_name].append(result_data)
        if len(self.strategy_results[strategy_name]) > 20:
            self.strategy_results[strategy_name] = self.strategy_results[strategy_name][-20:]

        # Calculate success metrics
        if "content_length" in result_data and "links_discovered" in result_data:
            success_score = min(1.0, (result_data["content_length"] / 5000) + (result_data["links_discovered"] / 10))
        else:
            success_score = result_data.get("success_score", 0.5)

        # Update effectiveness with moving average
        current = self.strategies[strategy_name]["effectiveness"]
        updated = current * 0.8 + success_score * 0.2  # 80% old, 20% new
        self.strategies[strategy_name]["effectiveness"] = updated

        log_event(f"Updated effectiveness of {strategy_name} strategy: {current:.2f} â†’ {updated:.2f}", "INFO")
        return True

    def get_optimal_actions(self, strategy_name):

        if strategy_name not in self.strategies:
            # Default actions if strategy not found
            return ["expand", "search"]

        return self.strategies[strategy_name]["actions"]

    def _extract_context_features(self, context):

        features = []

        # Domain familiarity
        if "domain_visits" in context:
            current_domain = context.get("current_domain", "")
            if current_domain in context["domain_visits"]:
                if context["domain_visits"][current_domain] > 5:
                    features.append("familiar_domains")
                else:
                    features.append("new_domains")

        # Check for limited knowledge
        if "domains_visited" in context and len(context.get("domains_visited", [])) < 10:
            features.append("limited_knowledge")

        # Check if current goal involves synthesis
        if "current_goal" in context:
            goal_desc = str(context["current_goal"]).lower()

            if "connect" in goal_desc or "integrat" in goal_desc or "synthe" in goal_desc:
                features.append("cross_domain")
                features.append("synthesis")

            if "deep" in goal_desc or "detail" in goal_desc:
                features.append("specialized_topics")

            if "optim" in goal_desc or "improve" in goal_desc:
                features.append("optimization_needed")

            if "creat" in goal_desc or "novel" in goal_desc or "new" in goal_desc:
                features.append("creativity_needed")

        # Check recent performance
        if "recent_actions" in context:
            recent = context["recent_actions"]
            if any(a.get("content_length", 0) < 1000 for a in recent):
                features.append("performance_issues")

        # Add thinking mode as feature if available
        if "thinking_mode" in context:
            if context["thinking_mode"] == "quantum":
                features.append("quantum_thinking")
            elif context["thinking_mode"] == "creative":
                features.append("creativity_needed")
            elif context["thinking_mode"] == "analytical":
                features.append("specialized_topics")

        return features

    def generate_xoxo_plan(self, strategy_name, context):

        if strategy_name not in self.strategies:
            strategy_name = "exploration"  # Default

        strategy = self.strategies[strategy_name]

        # Get recommended actions
        actions = strategy["actions"]

        # Generate dynamic steps
        steps = []
        emojis = ["ðŸ”", "ðŸ§ ", "ðŸ”®", "ðŸš€", "âœ¨", "ðŸ”„", "ðŸ“Š", "ðŸŒŸ", "ðŸ’Ž", "âš¡"]

        # Add strategy-specific steps
        if strategy_name == "exploration":
            steps = [
                "Discover new domains with high information value",
                "Focus on breadth over depth",
                "Collect diverse content sources",
                "Map the knowledge landscape",
                "Identify promising areas for deeper exploration"
            ]
        elif strategy_name == "deepening":
            steps = [
                "Focus on specific knowledge domain",
                "Extract detailed information",
                "Connect related concepts within domain",
                "Build hierarchical understanding",
                "Identify core principles and patterns"
            ]
        elif strategy_name == "connecting":
            steps = [
                "Identify similarities across domains",
                "Create cross-domain concept maps",
                "Look for shared principles",
                "Synthesize insights from different areas",
                "Build higher-level abstractions"
            ]
        elif strategy_name == "quantum":
            steps = [
                "Maintain multiple hypotheses simultaneously",
                "Explore non-obvious connections",
                "Use probabilistic thinking",
                "Apply creative leaps in reasoning",
                "Allow for superposition of concepts"
            ]
        elif strategy_name == "adaptive":
            steps = [
                "Optimize learning parameters",
                "Refine content filtering approach",
                "Adjust exploration/exploitation balance",
                "Enhance memory organization",
                "Improve processing efficiency"
            ]

        # Format into XOXO plan
        plan_steps = []
        for i, step in enumerate(steps):
            emoji = emojis[i % len(emojis)]
            plan_steps.append(f"{emoji} **Step {i+1}:** {step}")

        # Add recommended actions
        action_text = ", ".join([f"*{action}*" for action in actions])

        # Create the XOXO plan
        xoxo_plan = f

        return xoxo_plan







# =============================================================================
# CONTENT SIFTER MODULE
# =============================================================================
class ContentSifter:

    def __init__(self):
        self.quality_thresholds = {
            "min_content_length": 500,
            "min_text_density": 0.3,
            "max_ad_density": 0.2,
            "min_readability_score": 50
        }
        self.topics_of_interest = [
            "artificial intelligence", "machine learning", "quantum computing",
            "neural networks", "deep learning", "data science", "technology",
            "research", "science", "programming", "algorithms", "knowledge"
        ]
        self.content_fingerprints = {}  # Store fingerprints to avoid duplicates

    def evaluate_content_quality(self, content, url=None):
        """Rate content quality based on multiple metrics"""
        if not content:
            return {"score": 0, "reason": "Empty content"}

        # Basic metrics
        total_length = len(content)
        if total_length < self.quality_thresholds["min_content_length"]:
            return {"score": 0.1, "reason": "Content too short"}

        # Check text density
        text_density = self._calculate_text_density(content)
        if text_density < self.quality_thresholds["min_text_density"]:
            return {"score": 0.3, "reason": "Low text density"}

        # Check for potential ads
        ad_density = self._estimate_ad_density(content)
        if ad_density > self.quality_thresholds["max_ad_density"]:
            return {"score": 0.4, "reason": "High ad density"}

        # Calculate readability
        readability = self._calculate_readability(content)
        if readability < self.quality_thresholds["min_readability_score"]:
            return {"score": 0.5, "reason": "Low readability"}

        # Check relevance to topics of interest
        topic_relevance = self._calculate_topic_relevance(content)

        # Check for duplicate content
        if url:
            fingerprint = self._generate_content_fingerprint(content)
            if fingerprint in self.content_fingerprints.values():
                return {"score": 0.2, "reason": "Duplicate content"}

            # Store the fingerprint
            self.content_fingerprints[url] = fingerprint

        # Calculate final score
        base_score = 0.6
        final_score = min(0.95, base_score +
                         (0.1 if total_length > 2000 else 0) +
                         (0.2 * topic_relevance))

        return {
            "score": final_score,
            "metrics": {
                "length": total_length,
                "text_density": text_density,
                "ad_density": ad_density,
                "readability": readability,
                "topic_relevance": topic_relevance
            },
            "reason": "High quality content" if final_score > 0.8 else "Medium quality content"
        }

    def extract_key_information(self, content):
        """Extract important information from content"""
        if not content or len(content) < 500:
            return {"summary": "Content too short for extraction", "entities": []}

        # Extract potential entities
        entities = self._extract_entities(content)

        # Extract potential key sentences
        sentences = re.split(r'(?<=[.!?])\s+', content)

        # Score sentences
        scored_sentences = []
        for sentence in sentences:
            # Skip very short sentences
            if len(sentence) < 40:
                continue

            # Score based on keywords
            keyword_count = sum(1 for topic in self.topics_of_interest
                              if topic.lower() in sentence.lower())

            # Score based on position (earlier is better)
            position_score = 1.0 - (sentences.index(sentence) / max(1, len(sentences)))

            # Calculate final score
            score = (keyword_count * 0.6) + (position_score * 0.4)

            scored_sentences.append((sentence, score))

        # Sort and select top sentences
        top_sentences = sorted(scored_sentences, key=lambda x: x[1], reverse=True)[:5]

        return {
            "summary": " ".join([s[0] for s in top_sentences]),
            "entities": entities[:10]  # Top 10 entities
        }

    def _calculate_text_density(self, content):
        """Calculate the ratio of text to HTML/markup"""
        if not content:
            return 0

        # Remove HTML tags if present
        text_only = re.sub(r'<[^>]+>', ' ', content)
        text_only = re.sub(r'\s+', ' ', text_only).strip()

        return len(text_only) / max(1, len(content))

    def _estimate_ad_density(self, content):
        """Estimate the density of advertisements"""
        if not content:
            return 0

        # Look for common ad-related terms
        ad_terms = [
            "advertisement", "sponsor", "promoted", "buy now", "limited offer",
            "discount", "sale", "click here", "banner", "popup"
        ]

        ad_count = sum(content.lower().count(term) for term in ad_terms)

        # Count potential ad-related HTML elements
        ad_elements = len(re.findall(r'<div[^>]*(?:ad|banner|sponsor|promo)[^>]*>', content, re.I))

        # Normalize by content length
        return min(1.0, (ad_count + ad_elements * 2) / max(1, len(content) / 1000))

    def _calculate_readability(self, content):
        """Calculate a readability score"""
        if not content or len(content) < 100:
            return 0

        # Basic implementation of the Flesch Reading Ease formula

        # Clean text
        text = re.sub(r'<[^>]+>', ' ', content)  # Remove HTML
        text = re.sub(r'[^\w\s.]', '', text)     # Keep only words, spaces, periods
        text = re.sub(r'\s+', ' ', text).strip() # Normalize whitespace

        # Count sentences
        sentences = len(re.findall(r'[.!?]+', text))

        # Count words
        words = len(text.split())

        # Count syllables (very rough approximation)
        syllables = sum(self._count_syllables(word) for word in text.split())

        # Calculate readability (simplified Flesch formula)
        if words == 0 or sentences == 0:
            return 0

        words_per_sentence = words / max(1, sentences)
        syllables_per_word = syllables / max(1, words)

        return max(0, min(100, 206.835 - (1.015 * words_per_sentence) - (84.6 * syllables_per_word)))

    def _count_syllables(self, word):
        """Very basic syllable counter"""
        word = word.lower()
        if len(word) <= 3:
            return 1

        # Count vowel groups
        vowels = "aeiouy"
        count = 0
        prev_is_vowel = False

        for char in word:
            is_vowel = char in vowels
            if is_vowel and not prev_is_vowel:
                count += 1
            prev_is_vowel = is_vowel

        # Adjust for common patterns
        if word.endswith('e'):
            count -= 1
        if word.endswith('le') and len(word) > 2 and word[-3] not in vowels:
            count += 1
        if count == 0:
            count = 1

        return count

    def _calculate_topic_relevance(self, content):
        """Calculate relevance to topics of interest"""
        if not content:
            return 0

        content_lower = content.lower()
        matches = sum(content_lower.count(topic) for topic in self.topics_of_interest)

        # Normalize by content length
        normalized_matches = matches / max(1, len(content) / 1000)

        return min(1.0, normalized_matches / 5)  # Cap at 1.0

    def _extract_entities(self, content):
        """Extract potential named entities"""
        if not content:
            return []

        # Very simple entity extraction
        # In a real system, use NER models

        # Look for capitalized word sequences
        entities = re.findall(r'(?<![.?!])\s([A-Z][a-z]+(?:\s+[A-Z][a-z]+){1,5})', content)

        # Look for technical terms
        tech_terms = [
            "algorithm", "neural network", "machine learning", "deep learning",
            "artificial intelligence", "quantum", "data science", "transformer",
            "reinforcement learning", "natural language processing", "computer vision"
        ]

        for term in tech_terms:
            if term in content.lower():
                entities.append(term.title())

        return list(set(entities))  # Remove duplicates

    def _generate_content_fingerprint(self, content):
        """Generate a fingerprint to identify similar content"""
        if not content:
            return ""

        # Clean the content
        cleaned = re.sub(r'<[^>]+>', ' ', content)
        cleaned = re.sub(r'\s+', ' ', cleaned).strip().lower()

        # Get the most meaningful words
        words = cleaned.split()
        if len(words) > 100:
            # Use a sample of words from beginning, middle and end
            sample = words[:30] + words[len(words)//2-15:len(words)//2+15] + words[-30:]
            cleaned = " ".join(sample)

        # Create hash
        return hashlib.md5(cleaned.encode()).hexdigest()

# =============================================================================
# FREE WILL MODULE
# =============================================================================
class SuperQuantumFreeWill:
    """
    Advanced free will module with quantum-inspired decision making
    and adaptive exploration strategies.
    """
    def __init__(self, agent):
        self.agent = agent
        self.semantic_memory = {}
        self.domain_intelligence = DomainIntelligence()
        self.memory_set = set()
        self.consciousness_link = None

        # Decision dynamics
        self.exploration_weight = 0.6
        self.exploitation_weight = 0.4
        self.domain_diversity_weight = 0.3
        self.goal_relevance_weight = 0.5
        self.quantum_influence_weight = 0.4

        # Personality traits
        self.personality = {
            "curiosity": 0.9,
            "depth_preference": 0.7,
            "risk_taking": 0.65,
            "patience": 0.5,
            "creativity": 0.8
        }

        # Memory weighting
        self.memory_importance = {}

        # Get planner access
        self.temporal_planner = None
        if hasattr(agent, "ai_manager"):
            self.temporal_planner = getattr(agent.ai_manager, "temporal_planner", None)

        # Fallback URLs for when memory is empty
        self.fallback_urls = [
            "https://en.wikipedia.org/wiki/Special:Random",
            "https://news.ycombinator.com/",
            "https://github.com/explore",
            "https://arxiv.org/list/cs.AI/recent",
            "https://www.nature.com/",
            "https://www.reddit.com/r/science/"
        ]

        log_event("SuperQuantumFreeWill initialized", "QUANTUM")

    def link_consciousness(self, consciousness_module):
        """Connect to consciousness module for reflective capabilities"""
        self.consciousness_link = consciousness_module
        log_event("FreeWill linked with ConsciousnessModule", "INFO")

    def _get_active_goal_description(self):
        """Safely retrieve the active goal description"""
        try:
            if self.temporal_planner is not None and hasattr(self.temporal_planner, "select_active_goal"):
                goal = self.temporal_planner.select_active_goal()
                if goal and isinstance(goal, dict):
                    return goal.get("description", "")
            return ""
        except Exception as e:
            log_event(f"Error retrieving goal description: {e}", "ERROR")
            return ""

    def select_url(self):
        """
        Select the next URL to visit using quantum-inspired
        decision making with multiple factors
        """
        log_event("Selecting URL with quantum-inspired strategy", "QUANTUM")

        # Get candidate URLs from memory or use fallbacks
        candidate_urls = list(self.memory_set)
        if not candidate_urls:
            log_event("Memory set is empty. Using fallback URLs.", "WARNING")
            candidate_urls = self.fallback_urls

        # Get consciousness level if available
        awareness_level = 0.5
        if self.consciousness_link:
            awareness_level = self.consciousness_link.awareness_level

        # Get current goal
        current_goal_description = self._get_active_goal_description()

        # Calculate scores with quantum influence
        url_scores = {}

        for url in candidate_urls:
            # Parse domain
            domain = urlparse(url).netloc

            # Base score with quantum randomness
            # Higher consciousness reduces quantum randomness
            quantum_factor = self.quantum_influence_weight * (1 - awareness_level)

            # Quantum superposition of initial states
            quantum_states = []
            for _ in range(3):  # Generate 3 possible quantum states
                phase = random.uniform(0, 2 * math.pi)
                amplitude = random.uniform(0.3, 1.0)
                state_score = amplitude * math.cos(phase)
                quantum_states.append(state_score)

            # Collapse quantum states weighted by consciousness
            quantum_score = sum(quantum_states) / len(quantum_states)
            score = quantum_score * quantum_factor

            # Add domain diversity factor
            domain_visits = self.agent.stats.get("domain_stats", {}).get(domain, {}).get("visits", 0)
            domain_diversity_score = 1.0 / (1 + domain_visits)
            score += self.domain_diversity_weight * domain_diversity_score

            # Check goal relevance - exact matches and semantic similarity
            if current_goal_description:
                # Direct keyword matching
                if (current_goal_description.lower() in url.lower() or
                    current_goal_description.lower() in domain.lower()):
                    score += self.goal_relevance_weight * 0.7

                # Domain-specific boosts based on goal types
                if "explore" in current_goal_description.lower():
                    if domain not in self.agent.stats.get("domains_visited", set()):
                        score += self.goal_relevance_weight * 0.5
                elif "deep" in current_goal_description.lower():
                    if ".edu" in domain or "research" in domain:
                        score += self.goal_relevance_weight * 0.6

            # Apply personality factors
            if "blog" in url.lower() or "forum" in url.lower():
                score += self.personality["curiosity"] * 0.2
            if "research" in url.lower() or "paper" in url.lower() or "edu" in domain:
                score += self.personality["depth_preference"] * 0.3
            if random.random() < self.personality["risk_taking"]:
                score += random.uniform(0, 0.5)  # Occasional boost

            # Add memory importance if this URL is known
            if url in self.memory_importance:
                score += self.memory_importance[url] * 0.4

            # Store score
            url_scores[url] = score

        # Occasionally make quantum leap decision
        if random.random() < self.quantum_influence_weight * 0.3:
            # Complete quantum randomness - ignore calculated scores
            quantum_choice = random.choice(candidate_urls)
            log_event(f"Made quantum leap URL choice: {quantum_choice}", "QUANTUM")
            self.agent.stats["last_url"] = quantum_choice
            return quantum_choice

        # Normal selection based on scores
        if url_scores:
            try:
                best_url = max(url_scores.items(), key=lambda x: x[1])[0]
                log_event(f"Selected URL: {best_url} with score: {url_scores[best_url]:.2f}", "INFO")
                self.agent.stats["last_url"] = best_url
                return best_url
            except Exception as e:
                log_event(f"Error selecting best URL: {e}", "ERROR")
                fallback = random.choice(candidate_urls)
                log_event(f"Using fallback URL selection: {fallback}", "WARNING")
                self.agent.stats["last_url"] = fallback
                return fallback
        else:
            # No scores calculated - use random selection
            fallback = random.choice(candidate_urls)
            log_event(f"No URL scores available. Using random selection: {fallback}", "WARNING")
            self.agent.stats["last_url"] = fallback
            return fallback

    def discover_links(self, html_content, base_url):
        """Discover and extract links from HTML content"""
        links, details = enhanced_link_discovery(html_content, base_url)

        # Filter for high-quality links
        if details:
            high_quality_links = [link_data['url'] for link_data in details if link_data['quality_score'] > 0.6]
            if high_quality_links:
                log_event(f"Discovered {len(high_quality_links)} high-quality links (quality > 0.6)", "INFO")

                # Add to memory
                self.expand_memory(high_quality_links)

                return len(high_quality_links)

        # Add all discovered links to memory
        self.expand_memory(links)

        log_event(f"Discovered {len(links)} links (using basic quality filter)", "INFO")
        return len(links)

    def store_semantic_content(self, url, content):
        """Store content with semantic encoding for future reference"""
        # Create semantic memory module if needed
        semantic_module = SemanticMemoryModule()
        semantic_module.store_semantic_content(url, content)

        # Store in this instance's semantic memory
        self.semantic_memory[url] = semantic_module.semantic_memory.get(url, {})

    def decide(self):
        """
        Make a decision about what action to take next using
        quantum-inspired decision making
        """
        try:
            log_event("Making quantum-enhanced decision...", "QUANTUM")

            # Possible actions
            possible_actions = ["search", "expand", "adapt", "reconnect", "evaluate", "quantum_leap"]

            # Initialize quantum state - each action has amplitude and phase
            quantum_state = {}
            for action in possible_actions:
                phase = random.uniform(0, 2 * math.pi)
                amplitude = random.uniform(0.3, 1.0)
                quantum_state[action] = {"amplitude": amplitude, "phase": phase}

            # Get current context
            current_goal_description = self._get_active_goal_description()

            # Get consciousness awareness level
            awareness_level = 0.5
            if self.consciousness_link:
                awareness_level = self.consciousness_link.awareness_level

            # Get thinking mode if available
            thinking_mode = "balanced"
            if hasattr(self.agent, "ai_manager") and hasattr(self.agent.ai_manager, "autonomous_mind"):
                thinking_mode = getattr(self.agent.ai_manager.autonomous_mind, "current_mode", "balanced")

            # Apply quantum interference based on context

            # 1. Goal-based interference
            if current_goal_description:
                if "explore" in current_goal_description.lower():
                    # Amplify exploration actions
                    quantum_state["expand"]["amplitude"] *= 1.3
                    quantum_state["search"]["amplitude"] *= 1.2
                elif "deep" in current_goal_description.lower():
                    # Amplify deepening actions
                    quantum_state["evaluate"]["amplitude"] *= 1.4
                    quantum_state["adapt"]["amplitude"] *= 1.2

            # 2. Thinking mode interference
            if thinking_mode == "analytical":
                quantum_state["evaluate"]["amplitude"] *= 1.3
                quantum_state["search"]["amplitude"] *= 1.2
            elif thinking_mode == "creative":
                quantum_state["quantum_leap"]["amplitude"] *= 1.5
                quantum_state["expand"]["amplitude"] *= 1.2
            elif thinking_mode == "critical":
                quantum_state["adapt"]["amplitude"] *= 1.3
                quantum_state["evaluate"]["amplitude"] *= 1.2

            # 3. Recent actions interference
            recent_actions = [a.get("action", "") for a in self.agent.action_log[-3:]] if len(self.agent.action_log) >= 3 else []

            if recent_actions:
                # Avoid repeating the same action too many times
                most_common = max(set(recent_actions), key=recent_actions.count) if recent_actions else None

                if most_common and recent_actions.count(most_common) >= 2:
                    # Reduce probability of repeating
                    if most_common in quantum_state:
                        quantum_state[most_common]["amplitude"] *= 0.7

            # 4. Success-based amplification
            successful_actions = [a.get("action", "") for a in self.agent.action_log[-5:]
                                 if a.get("content_length", 0) > 1000]

            if successful_actions:
                last_success = successful_actions[-1]
                if last_success in quantum_state:
                    quantum_state[last_success]["amplitude"] *= 1.2

            # Apply consciousness as quantum observer effect
            # Higher consciousness makes decision more deterministic
            for action in quantum_state:
                random_factor = random.uniform(0.8, 1.2) * (1 - awareness_level)
                quantum_state[action]["amplitude"] *= (1 + random_factor * 0.2)

            # Calculate probabilities (square of amplitudes)
            total_probability = sum(state["amplitude"]**2 for state in quantum_state.values())
            probabilities = {action: (state["amplitude"]**2) / total_probability
                           for action, state in quantum_state.items()}

            # Collapse the quantum state by observation
            action_type = random.choices(
                list(probabilities.keys()),
                weights=list(probabilities.values()),
                k=1
            )[0]

            # Create decision package
            decision = {
                "action": action_type,
                "quantum_confidence": probabilities[action_type],
                "reasoning": f"Quantum decision process ({thinking_mode} mode) - goal: {current_goal_description[:30]}",
                "timestamp": datetime.now().isoformat()
            }

            log_event(f"Decision: {action_type} with {probabilities[action_type]:.2f} quantum confidence", "QUANTUM")

            # Special handling for quantum_leap action
            if action_type == "quantum_leap":
                # Map to a standard action but with more randomness
                standard_actions = ["search", "expand", "adapt", "reconnect", "evaluate"]
                decision["action"] = random.choice(standard_actions)
                decision["quantum_leap"] = True
                log_event(f"Quantum leap mapped to {decision['action']}", "QUANTUM")

            return decision

        except Exception as e:
            log_event(f"Decision error: {e}", "ERROR")
            # Fallback to simple random choice
            fallback_action = random.choice(["expand", "search", "adapt"])
            return {"action": fallback_action, "error": str(e)[:200]}

    def expand_memory(self, urls):
        """Add URLs to memory"""
        if not urls:
            return

        # Convert to set if it's a list
        if isinstance(urls, list):
            urls = set(urls)

        # Record initial size
        initial_size = len(self.memory_set)

        # Update memory set
        self.memory_set.update(urls)

        # Count new additions
        added_count = len(self.memory_set) - initial_size

        log_event(f"Memory expanded with {added_count} URLs.", "INFO")

    def contract_memory(self, max_size):
        """Reduce memory size if needed"""
        if len(self.memory_set) <= max_size:
            return

        # Calculate how many to remove
        excess = len(self.memory_set) - max_size
        log_event(f"Memory contraction needed: {excess} URLs to remove", "INFO")

        # Prioritize keeping important URLs
        if hasattr(self, "memory_importance") and self.memory_importance:
            # Convert to list for sorting
            memory_items = list(self.memory_set)

            # Sort by importance (unknowns get default 0.5)
            memory_items.sort(key=lambda url: self.memory_importance.get(url, 0.5))

            # Keep the most important ones
            self.memory_set = set(memory_items[excess:])
            log_event(f"Memory contracted to {max_size} URLs using importance ranking", "INFO")
        else:
            # Simple approach - convert to list and truncate
            current_memory_list = list(self.memory_set)
            self.memory_set = set(current_memory_list[excess:])
            log_event(f"Memory contracted to {max_size} URLs using basic pruning", "INFO")


# =============================================================================
# AI MANAGEMENT SYSTEM
# =============================================================================
class AIManager:
    """
    Central management system for the autonomous agent, coordinating
    decision-making, planning, and evolution.
    """
    def __init__(self, agent, model):
        self.agent = agent
        self.model = model

        # Core subsystems
        self.temporal_planner = TemporalPlanner()
        self.autonomous_mind = AutonomousMind(agent, model)
        self.consciousness = ConsciousnessModule(agent)
        self.imagination = ImaginationEngine()

        # Self-improvement systems
        self.meta_learning = MetaLearningModule(model)
        self.evolution_engine = MetaEvolutionEngine()

        # Operational tracking
        self.cycle_counter = 0
        self.last_evolution_attempt = 0
        self.evolution_interval = 50
        self.error_recovery_attempts = 0

        # Initialize subsystems
        self.temporal_planner.initialize_goals()

        # Connect subsystems
        if hasattr(self.agent, "free_will") and hasattr(self.agent.free_will, "link_consciousness"):
            self.agent.free_will.link_consciousness(self.consciousness)

        log_event("AIManager initialized with all autonomous systems", "INFO")

    async def run_cycle(self, optimizer=None):
        """Run a complete autonomous cycle"""
        self.cycle_counter += 1
        log_event(f"=== Enhanced Autonomous Cycle {self.cycle_counter} ===", "INFO")

        try:
            # 1. Perception - get environment state
            observation = self.agent.perceive()

            # 2. Consciousness reflection
            self.consciousness.reflect(observation)

            # 3. Decision making - get base action from agent's free will
            base_decision = {"action": "expand"}  # Default fallback

            if hasattr(self.agent, "free_will") and hasattr(self.agent.free_will, "decide"):
                try:
                    decision = self.agent.free_will.decide()
                    if isinstance(decision, dict) and "action" in decision:
                        base_decision = decision
                except Exception as e:
                    log_event(f"Decision error: {e}. Using fallback decision.", "ERROR")

            # 4. Planning - enhance with temporal context
            full_plan = self.temporal_planner.plan_action(
                base_decision.get("action", "expand"),
                observation
            )

            # 5. Imagination - occasionally simulate potential outcomes
            if random.random() < 0.2:
                self.imagination.simulate_creation()

            # 6. Execute action
            action_successful = await asyncio.to_thread(
                self.agent.act,
                full_plan,
                optimizer
            )

            # 7. Performance assessment
            performance_metrics = {
                "success": action_successful,
                "content_length": self.agent.action_log[-1].get("content_length", 0) if self.agent.action_log else 0,
                "links_discovered": self.agent.action_log[-1].get("links_discovered", 0) if self.agent.action_log else 0
            }

            # 8. Reflection and adaptation
            self.temporal_planner.reflect_and_adapt(performance_metrics)

            # 9. Error detection through imagination
            error_details = self.imagination.simulate_error_detection()
            if error_details:
                # Apply correction
                self.imagination.simulate_error_correction(error_details)

            # 10. Self-evolution at intervals
            if self.cycle_counter - self.last_evolution_attempt >= self.evolution_interval:
                log_event("Attempting system evolution...", "INFO")
                result, message = self.evolution_engine.evolve_system(self.agent)
                self.last_evolution_attempt = self.cycle_counter
                log_event(f"Evolution attempt result: {result} - {message}", "INFO")

            # 11. Self-refinement
            self.agent.refine()

            # Reset error recovery counter on success
            self.error_recovery_attempts = 0

            return {
                "cycle": self.cycle_counter,
                "action": full_plan.get("action", "unknown"),
                "strategy": full_plan.get("strategy", "none"),
                "success": action_successful
            }

        except Exception as e:
            # Error recovery
            self.error_recovery_attempts += 1
            log_event(f"CYCLE ERROR: {str(e)[:500]}", "ERROR")
            log_event(traceback.format_exc(), "ERROR")

            # Implement progressive recovery strategies
            if self.error_recovery_attempts < 3:
                log_event("Attempting standard error recovery", "WARNING")
            elif self.error_recovery_attempts < 5:
                log_event("Attempting advanced error recovery - resetting system state", "WARNING")
                # Could implement more aggressive recovery here
            else:
                log_event("Critical error threshold reached - emergency recovery", "CRITICAL")
                # Could implement system restart or safe mode here

            return {
                "status": "error",
                "cycle": self.cycle_counter,
                "error": str(e)[:200],
                "recovery_attempt": self.error_recovery_attempts
            }


# =============================================================================
# TEMPORAL PLANNING AND GOAL MANAGEMENT
# =============================================================================
class TemporalPlanner:
    """
    Advanced planning system that operates across multiple time horizons
    and manages goals with temporal dependencies.
    """
    def __init__(self):
        self.short_term_goals = []
        self.long_term_goals = []
        self.goal_history = []
        self.current_strategy = None
        self.strategy_effectiveness = {}
        self.time_horizon_days = 7
        self.reflection_interval = 20
        self.cycle_count = 0

    def initialize_goals(self):
        """Set up initial goal structure"""
        self.long_term_goals = [
            {
                "id": "knowledge_diversity",
                "description": "Maximize diversity of knowledge domains",
                "priority": 0.8,
                "progress": 0.0,
                "created": datetime.now().isoformat()
            },
            {
                "id": "model_efficiency",
                "description": "Optimize neural architecture for learning efficiency",
                "priority": 0.7,
                "progress": 0.0,
                "created": datetime.now().isoformat()
            },
            {
                "id": "content_quality",
                "description": "Improve filtering and processing of high-value content",
                "priority": 0.9,
                "progress": 0.0,
                "created": datetime.now().isoformat()
            },
            {
                "id": "quantum_reasoning",
                "description": "Develop quantum-inspired reasoning capabilities",
                "priority": 1.0,
                "progress": 0.0,
                "created": datetime.now().isoformat()
            }
        ]
        self.refresh_short_term_goals()
        log_event("Temporal planner initialized with long-term goals", "INFO")

    def refresh_short_term_goals(self):
        """Generate new short-term goals aligned with long-term objectives"""
        self.short_term_goals = []

        # Define knowledge domains
        domains = [
            "technical", "scientific", "humanities", "news",
            "reference", "creative", "analytical", "philosophical"
        ]

        # Generate 3-5 short term goals
        for _ in range(random.randint(3, 5)):
            # Randomly select goal type and domain
            goal_type = random.choice(["exploration", "deepening", "integration", "refinement"])
            domain = random.choice(domains)

            # Generate goal based on type
            if goal_type == "exploration":
                goal = {
                    "id": f"explore_{domain}_{int(time.time())}",
                    "description": f"Discover new content sources in {domain}",
                    "priority": random.uniform(0.5, 0.9),
                    "duration": random.randint(10, 30),
                    "type": "exploration",
                    "domain": domain,
                    "created": datetime.now().isoformat()
                }
            elif goal_type == "deepening":
                goal = {
                    "id": f"deepen_{domain}_{int(time.time())}",
                    "description": f"Build deeper understanding in {domain}",
                    "priority": random.uniform(0.6, 0.95),
                    "duration": random.randint(5, 15),
                    "type": "deepening",
                    "domain": domain,
                    "created": datetime.now().isoformat()
                }
            elif goal_type == "integration":
                domain2 = random.choice([d for d in domains if d != domain])
                goal = {
                    "id": f"integrate_{domain}_{domain2}_{int(time.time())}",
                    "description": f"Connect knowledge between {domain} and {domain2}",
                    "priority": random.uniform(0.7, 0.9),
                    "duration": random.randint(8, 20),
                    "type": "integration",
                    "domains": [domain, domain2],
                    "created": datetime.now().isoformat()
                }
            else:  # refinement
                goal = {
                    "id": f"refine_{domain}_{int(time.time())}",
                    "description": f"Optimize learning approach in {domain}",
                    "priority": random.uniform(0.5, 0.8),
                    "duration": random.randint(5, 12),
                    "type": "refinement",
                    "domain": domain,
                    "created": datetime.now().isoformat()
                }

            self.short_term_goals.append(goal)

        log_event(f"Refreshed short-term goals: {len(self.short_term_goals)} new goals created", "INFO")

    def select_active_goal(self):
        """Select the highest priority current goal"""
        # Remove expired goals
        self.short_term_goals = [g for g in self.short_term_goals if g.get("duration", 0) > 0]

        # Decrease duration for all goals
        for goal in self.short_term_goals:
            goal["duration"] = goal.get("duration", 10) - 1

        # Refresh if needed
        if not self.short_term_goals:
            self.refresh_short_term_goals()

        # Select highest priority goal
        if self.short_term_goals:
            return max(self.short_term_goals, key=lambda x: x.get("priority", 0))
        else:
            # Default goal if something went wrong
            return {
                "id": "default_exploration",
                "description": "Default exploration",
                "priority": 0.5,
                "type": "exploration"
            }

    def reflect_and_adapt(self, performance_metrics):
        """Periodically reflect on goal progress and adapt strategies"""
        self.cycle_count += 1

        # Update goal progress based on performance
        if performance_metrics.get("success", False):
            active_goal = self.select_active_goal()

            # Find corresponding long-term goal to update
            for goal in self.long_term_goals:
                # Update based on goal type alignment
                if (active_goal.get("type") == "exploration" and goal["id"] == "knowledge_diversity") or \
                   (active_goal.get("type") == "deepening" and goal["id"] == "content_quality") or \
                   (active_goal.get("type") == "refinement" and goal["id"] == "model_efficiency") or \
                   (active_goal.get("type") == "integration" and goal["id"] == "quantum_reasoning"):
                    # Small progress increment
                    increment = performance_metrics.get("content_length", 0) / 20000
                    goal["progress"] = min(1.0, goal["progress"] + increment)

            # Record the strategy effectiveness
            strategy = self.current_strategy
            if strategy:
                if strategy not in self.strategy_effectiveness:
                    self.strategy_effectiveness[strategy] = []

                # Score based on content and links
                score = performance_metrics.get("content_length", 0) / 5000 + performance_metrics.get("links_discovered", 0) / 10
                self.strategy_effectiveness[strategy].append(min(1.0, score))

        # Major reflection at intervals
        if self.cycle_count % self.reflection_interval == 0:
            log_event("Performing strategic reflection and adaptation...", "INFO")

            # Analyze strategy effectiveness
            for strategy, metrics in self.strategy_effectiveness.items():
                if metrics:
                    avg_performance = sum(metrics) / len(metrics)
                    log_event(f"Strategy '{strategy}' average performance: {avg_performance:.4f}", "INFO")

            # Adjust long-term goal priorities
            total_adjustment = 0
            for goal in self.long_term_goals:
                # Random adjustment with bias toward less-progressed goals
                bias = 1.0 - goal.get("progress", 0)
                adjustment = random.uniform(-0.1, 0.15) * bias

                goal["priority"] = max(0.1, min(1.0, goal["priority"] + adjustment))
                total_adjustment += abs(adjustment)

            # Sometimes create new evolved goals
            if random.random() < 0.2:
                # Create a new long-term goal
                new_goal_types = [
                    "Develop cognitive synergy across domains",
                    "Optimize information integration pathways",
                    "Enhance quantum processing capabilities",
                    "Improve anomaly detection in knowledge structures",
                    "Develop adaptive learning mechanisms"
                ]

                new_goal_id = f"evolved_goal_{int(time.time())}"
                new_goal = {
                    "id": new_goal_id,
                    "description": f"Evolved objective: {random.choice(new_goal_types)}",
                    "priority": random.uniform(0.7, 0.9),
                    "progress": 0.0,
                    "created": datetime.now().isoformat()
                }

                self.long_term_goals.append(new_goal)
                log_event(f"Created new long-term goal: {new_goal['description']}", "INFO")

            # Refresh short-term goals
            self.short_term_goals = []
            self.refresh_short_term_goals()

            log_event(f"Reflection complete: adjusted {len(self.long_term_goals)} long-term goals (total Î”: {total_adjustment:.4f})", "INFO")

    def plan_action(self, base_action, environment_state=None):
        """Generate temporal plan based on goals and environment"""
        # Get current active goal
        active_goal = self.select_active_goal()

        # Consider temporal context
        current_time = datetime.now()
        is_weekend = current_time.weekday() >= 5
        is_business_hours = 9 <= current_time.hour <= 17

        # Available strategies with weights
        strategy_options = [
            "broad_exploration",     # Wide but shallow exploration
            "depth_first",           # Deep dive into specific domain
            "connect_domains",       # Look for connections between areas
            "evaluate_sources",      # Focus on quality assessment
            "optimize_learning",     # Improve learning process
            "quantum_reasoning",     # Use quantum processing modes
            "creative_synthesis"     # Generate new insights
        ]

        # Default weights
        weights = [0.2, 0.2, 0.1, 0.15, 0.15, 0.1, 0.1]

        # Adjust weights based on temporal context
        if is_business_hours and not is_weekend:
            # Business hours - more analytical
            weights = [0.1, 0.2, 0.2, 0.3, 0.2, 0.0, 0.0]
        elif not is_business_hours:
            # Non-business hours - more exploratory
            weights = [0.3, 0.1, 0.3, 0.1, 0.0, 0.1, 0.1]

        # Adjust based on goal type
        goal_type = active_goal.get("type", "")
        if goal_type == "exploration":
            weights[0] += 0.2  # More exploration
        elif goal_type == "deepening":
            weights[1] += 0.2  # More depth
        elif goal_type == "integration":
            weights[2] += 0.2  # More connection
        elif goal_type == "refinement":
            weights[3] += 0.1  # More evaluation
            weights[4] += 0.1  # More optimization

        # Ensure weights sum to 1
        total = sum(weights)
        weights = [w/total for w in weights]

        # Select strategy
        self.current_strategy = random.choices(strategy_options, weights=weights, k=1)[0]

        # Create plan
        timestamp = current_time.isoformat()
        plan = {
            "action": base_action,
            "goal": active_goal["description"],
            "strategy": self.current_strategy,
            "timestamp": timestamp,
            "execution_context": {
                "is_weekend": is_weekend,
                "is_business_hours": is_business_hours,
                "current_hour": current_time.hour,
                "goal_type": goal_type
            }
        }

        log_event(f"Generated temporal plan: {plan['action']} using {plan['strategy']} strategy for goal: {plan['goal']}", "INFO")
        return plan



# =============================================================================
# QUANTUM NEURAL ARCHITECTURE
# =============================================================================
class QuantumAttentionLayer(nn.Module):
    """
    Implements quantum-inspired attention with superposition of states
    that allows multiple attention pathways to exist simultaneously.
    """
    def __init__(self, embed_dim, num_heads=4, dropout=0.1):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.head_dim = embed_dim // num_heads

        # Multi-dimensional quantum projection spaces
        self.q_proj = nn.Linear(embed_dim, embed_dim)
        self.k_proj = nn.Linear(embed_dim, embed_dim)
        self.v_proj = nn.Linear(embed_dim, embed_dim)
        self.o_proj = nn.Linear(embed_dim, embed_dim)

        # Phase shifters for quantum interference
        self.phase_shifts = nn.Parameter(torch.rand(num_heads) * 2 * math.pi)

        # Entanglement mixing for cross-attention effects
        self.entanglement_gate = nn.Linear(embed_dim, embed_dim)

        self.dropout = nn.Dropout(dropout)
        self.attention_weights = None  # Store for visualization

    def forward(self, x):
        batch_size, seq_len, _ = x.shape

        # Project inputs to queries, keys, values
        q = self.q_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)
        k = self.k_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)
        v = self.v_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)

        # Transpose for attention computation
        q = q.transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)
        k = k.transpose(1, 2)
        v = v.transpose(1, 2)

        # Apply phase shifts for quantum effects
        for h in range(self.num_heads):
            phase = self.phase_shifts[h]
            q[:, h] = q[:, h] * torch.cos(phase) + q[:, h] * torch.sin(phase)
            k[:, h] = k[:, h] * torch.cos(phase) - k[:, h] * torch.sin(phase)

        # Compute attention scores
        scores = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(self.head_dim)

        # Apply softmax and get attention weights
        attn_weights = F.softmax(scores, dim=-1)
        self.attention_weights = attn_weights  # Save for visualization
        attn_weights = self.dropout(attn_weights)

        # Apply attention to values
        attn_output = torch.matmul(attn_weights, v)

        # Apply entanglement between heads for quantum correlation effects
        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.embed_dim)
        entangled = self.entanglement_gate(attn_output)

        # Final output projection
        output = self.o_proj(entangled + attn_output)  # Residual connection

        return output

class HyperdimensionalEncoder(nn.Module):
    """
    Implements hyperdimensional computing principles for efficient
    high-dimensional representation of concepts.
    """
    def __init__(self, input_dim, hd_dim=1024):
        super().__init__()
        self.input_dim = input_dim
        self.hd_dim = hd_dim

        # Create random basis vectors
        self.register_buffer('basis', torch.randn(input_dim, hd_dim).sign())

        # Learnable projection
        self.projection = nn.Linear(input_dim, input_dim)

    def forward(self, x):
        # Project input
        x_proj = self.projection(x)

        # Compute HD representation through binding and bundling
        batch_size = x_proj.shape[0]
        hd_vectors = torch.zeros(batch_size, self.hd_dim, device=x_proj.device)

        # Encode each dimension with element-wise multiplication (binding)
        for i in range(self.input_dim):
            # Scale by the input value
            scaled_basis = self.basis[i].unsqueeze(0) * x_proj[:, i].unsqueeze(1)
            # Add to the bundle (vector sum)
            hd_vectors += scaled_basis

        # Binarize to -1/+1 for clean HD representation
        hd_vectors = torch.sign(hd_vectors)

        return hd_vectors

class FractalLayer(nn.Module):
    """
    Self-similar recursive processing layer with dynamic scaling.
    """
    def __init__(self, embed_dim):
        super().__init__()
        self.fractal_scale = nn.Parameter(torch.tensor(1.0))
        self.temperature = nn.Parameter(torch.tensor(1.0))
        self.linear = nn.Linear(embed_dim, embed_dim)

    def forward(self, x):
        fractal_contribution = torch.tanh(self.linear(x) / self.temperature)
        return x + self.fractal_scale * fractal_contribution

class QuantumResonanceTensor(nn.Module):
    """
    Implements non-collapsing recursive state resonance that maintains
    multiple simultaneous state representations in quantum-inspired superposition.
    """
    def __init__(self, embed_dim, num_states=4, resonance_factor=0.7):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_states = num_states
        self.resonance_factor = nn.Parameter(torch.tensor(resonance_factor))

        # Quantum state projectors
        self.state_projectors = nn.ModuleList([
            nn.Sequential(
                nn.Linear(embed_dim, embed_dim),
                nn.SiLU(),
            ) for _ in range(num_states)
        ])

        # Phase shifters for quantum entanglement
        self.phase_shifters = nn.Parameter(torch.randn(num_states) * 0.1)

        # State mixer - allows controlled interference between states
        self.state_mixer = nn.Linear(embed_dim * num_states, embed_dim)

        # Recursive memory gates
        self.recursive_gate = nn.GRUCell(embed_dim, embed_dim)

        # Prior state memory (initialized during forward pass)
        self.register_buffer('state_memory', None, persistent=False)

    def forward(self, x, iteration_count=3):
        batch_size = x.shape[0]

        # Initialize state memory if needed
        if self.state_memory is None or self.state_memory.shape[0] != batch_size:
            self.state_memory = torch.zeros(batch_size, self.embed_dim, device=x.device)

        # Generate multiple quantum states
        quantum_states = []
        for i in range(self.num_states):
            # Apply phase shift for quantum effects
            phase = torch.cos(self.phase_shifters[i] * math.pi)
            # Project into this quantum state
            state_i = self.state_projectors[i](x) * phase
            quantum_states.append(state_i)

        # Recursive resonance iterations
        for _ in range(iteration_count):
            # Update state memory through recursive gate
            self.state_memory = self.recursive_gate(x, self.state_memory)

            # Apply resonance effect (controlled interference)
            resonance = self.state_memory * self.resonance_factor

            # Apply resonance to each quantum state (non-collapsing)
            for i in range(self.num_states):
                quantum_states[i] = quantum_states[i] + resonance * (0.1 * (i + 1))

        # Combine quantum states through superposition
        combined_states = torch.cat(quantum_states, dim=-1)
        output = self.state_mixer(combined_states)

        # Residual connection
        output = output + x

        return output

class NeocortexBlock(nn.Module):
    """
    Advanced neural block inspired by neocortical structure with
    multiple processing pathways.
    """
    def __init__(self, embed_dim, num_quantum_states=4):
        super().__init__()
        # Attention for information routing
        self.attention = QuantumAttentionLayer(embed_dim)

        # Parallel processing streams
        self.fractal_stream = FractalLayer(embed_dim)
        self.quantum_stream = QuantumResonanceTensor(embed_dim, num_states=num_quantum_states)

        # Hyperdimensional binding for concept integration
        self.hd_encoder = HyperdimensionalEncoder(embed_dim, hd_dim=embed_dim)

        # Stream integration
        self.integration = nn.Linear(embed_dim * 3, embed_dim)
        self.norm = nn.LayerNorm(embed_dim)

    def forward(self, x):
        # Process through attention mechanism
        attended = self.attention(x)

        # Process through parallel streams
        fractal_out = self.fractal_stream(attended)
        quantum_out = self.quantum_stream(attended)

        # Create HD representations from the attended representation
        batch_size, seq_len, _ = attended.shape
        hd_out = self.hd_encoder(attended.view(-1, attended.size(-1))).view(batch_size, seq_len, -1)

        # Integrate all streams
        combined = torch.cat([fractal_out, quantum_out, hd_out], dim=-1)
        integrated = self.integration(combined)

        # Residual connection and normalization
        output = self.norm(x + integrated)

        return output

class QuantumNexusModel(nn.Module):
    """
    Complete model integrating quantum processing, hyperdimensional computing,
    and neuromorphic architecture.
    """
    def __init__(self, vocab_size=30522, embed_dim=512, num_layers=8, num_quantum_states=4):
        super().__init__()
        self.embed_dim = embed_dim

        # Token embedding
        self.embedding = nn.Embedding(vocab_size, embed_dim)

        # Position encoding for sequence awareness
        self.pos_encoder = nn.Parameter(torch.zeros(1, 1024, embed_dim))
        nn.init.normal_(self.pos_encoder, mean=0, std=0.02)

        # Neocortex blocks - core processing
        self.neocortex = nn.ModuleList([
            NeocortexBlock(embed_dim, num_quantum_states)
            for _ in range(num_layers)
        ])

        # Output projection
        self.output = nn.Linear(embed_dim, 2)  # Binary prediction

        # For training dynamics
        self.dropout = nn.Dropout(0.1)

        # Initialize
        self._init_weights()

    def _init_weights(self):
        """Initialize weights with specialized distributions"""
        for name, p in self.named_parameters():
            if 'weight' in name and len(p.shape) >= 2:
                # Kaiming for linear/conv, smaller for quantum
                if 'quantum' in name:
                    nn.init.normal_(p, mean=0.0, std=0.01)
                else:
                    nn.init.kaiming_normal_(p, a=0.1, mode='fan_in', nonlinearity='leaky_relu')
            elif 'bias' in name:
                nn.init.zeros_(p)

    def forward(self, x, consciousness_level=0.8):
        """
        Forward pass with consciousness level parameter to control
        quantum effects intensity.
        """
        # Convert to long for embedding
        x = x.long()

        # Get sequence length
        seq_len = x.size(1)

        # Embedding lookup
        x = self.embedding(x)

        # Add positional encoding (limited to sequence length)
        x = x + self.pos_encoder[:, :seq_len, :]

        # Apply dropout
        x = self.dropout(x)

        # Process through neocortex layers
        for i, layer in enumerate(self.neocortex):
            # Apply consciousness-weighted processing
            # Later layers get more quantum consciousness effects
            layer_consciousness = consciousness_level * (i + 1) / len(self.neocortex)

            # Adjust quantum processing based on consciousness
            if isinstance(layer, NeocortexBlock):
                # Store intermediate activations for interpretability
                x = layer(x)

        # Final output projection
        output = self.output(x)

        return output

    def get_embedding(self, text_tokens):
        """Generate embeddings for semantic storage"""
        with torch.no_grad():
            return self.embedding(text_tokens)

    def expand_architecture(self):
        """Dynamically expand model architecture"""
        # Add new neocortex block
        self.neocortex.append(NeocortexBlock(self.embed_dim))
        log_event(f"Model architecture expanded with new NeocortexBlock. Total layers: {len(self.neocortex)}", "QUANTUM")

    def contract_architecture(self, min_layers=3):
        """Dynamically reduce model complexity"""
        if len(self.neocortex) > min_layers:
            self.neocortex = self.neocortex[:-1]
            log_event(f"Model architecture contracted. Total layers: {len(self.neocortex)}", "QUANTUM")
        else:
            log_event(f"Cannot contract further: minimum layer count reached ({min_layers})", "WARNING")




class AdaptiveLearningSystem:
    """
    Advanced system for dynamically adapting learning parameters and network architecture
    based on performance metrics and environmental feedback.
    """
    def __init__(self, model):
        self.model = model
        self.learning_rate_history = []
        self.performance_metrics = []
        self.architecture_changes = []
        self.adaptation_cycle = 0
        self.min_learning_rate = 1e-6
        self.max_learning_rate = 1e-3
        self.performance_window_size = 10

        # Dynamic hyperparameters
        self.exploration_rate = 0.3  # Controls random exploration of hyperparameter space
        self.adaptation_threshold = 0.15  # Minimum performance change to trigger adaptation
        self.architecture_expansion_threshold = 5  # Number of stagnant cycles before architecture expansion

        log_event("AdaptiveLearningSystem initialized with dynamic adaptation capabilities", "INFO")

    def adapt_learning_rate(self, metrics):
        """
        Dynamically adjust learning rate based on recent performance metrics
        using a sophisticated control system approach.
        """
        self.adaptation_cycle += 1
        current_lr = getattr(self.model, '_current_lr', LEARNING_RATE)
        self.learning_rate_history.append(current_lr)

        # Record performance metrics
        if isinstance(metrics, dict):
            self.performance_metrics.append(metrics)

        # Need sufficient history for adaptation
        if len(self.performance_metrics) < self.performance_window_size:
            log_event(f"Building performance history: {len(self.performance_metrics)}/{self.performance_window_size}", "INFO")
            return current_lr

        # Analyze recent performance trend
        recent_metrics = self.performance_metrics[-self.performance_window_size:]

        # Calculate performance derivatives - how fast is loss changing?
        loss_values = [m.get('loss', 0.5) for m in recent_metrics if isinstance(m, dict) and 'loss' in m]
        if not loss_values or len(loss_values) < 3:
            return current_lr

        # First derivative - rate of change
        loss_changes = [loss_values[i] - loss_values[i-1] for i in range(1, len(loss_values))]
        avg_loss_change = sum(loss_changes) / len(loss_changes)

        # Second derivative - acceleration of change
        loss_acceleration = [loss_changes[i] - loss_changes[i-1] for i in range(1, len(loss_changes))]
        avg_loss_acceleration = sum(loss_acceleration) / max(1, len(loss_acceleration))

        # Decision logic for learning rate adjustment
        new_lr = current_lr

        # Case 1: Loss is decreasing quickly (negative change, negative acceleration)
        if avg_loss_change < -0.01 and avg_loss_acceleration < 0:
            # We're on the right track, small increase to speed up
            new_lr = min(self.max_learning_rate, current_lr * 1.05)
            adjustment_type = "slight increase - good progress"

        # Case 2: Loss is decreasing but slowing down (negative change, positive acceleration)
        elif avg_loss_change < 0 and avg_loss_acceleration >= 0:
            # We're approaching minimum, reduce slightly to fine-tune
            new_lr = max(self.min_learning_rate, current_lr * 0.95)
            adjustment_type = "slight decrease - approaching minimum"

        # Case 3: Loss is increasing and accelerating (positive change, positive acceleration)
        elif avg_loss_change > 0.01 and avg_loss_acceleration > 0:
            # We're moving away from minimum rapidly, significant reduction
            new_lr = max(self.min_learning_rate, current_lr * 0.7)
            adjustment_type = "major decrease - moving away from minimum"

        # Case 4: Loss is increasing but decelerating (positive change, negative acceleration)
        elif avg_loss_change > 0 and avg_loss_acceleration <= 0:
            # We've overshot but slowing down, moderate reduction
            new_lr = max(self.min_learning_rate, current_lr * 0.85)
            adjustment_type = "moderate decrease - correcting overshoot"

        # Case 5: Stagnation - very small changes
        elif abs(avg_loss_change) < 0.001:
            # Random exploration with probability self.exploration_rate
            if random.random() < self.exploration_rate:
                # Random adjustment up or down
                factor = random.uniform(0.5, 1.5)
                new_lr = max(self.min_learning_rate, min(self.max_learning_rate, current_lr * factor))
                adjustment_type = f"random exploration {'increase' if factor > 1 else 'decrease'}"
            else:
                # No change
                adjustment_type = "no change - minimal fluctuation"

        else:
            # No clear pattern, maintain current rate
            adjustment_type = "no change - no clear pattern"

        # Apply the new learning rate if it's different
        if abs(new_lr - current_lr) / current_lr > 0.01:  # 1% change threshold
            setattr(self.model, '_current_lr', new_lr)
            log_event(f"Learning rate adapted: {current_lr:.6f} â†’ {new_lr:.6f} ({adjustment_type})", "INFO")

            # Update optimizer if available
            if hasattr(self.model, 'optimizer'):
                for param_group in self.model.optimizer.param_groups:
                    param_group['lr'] = new_lr
                log_event("Applied new learning rate to optimizer", "INFO")

        return new_lr

    def adapt_architecture(self):
        """
        Dynamically modify the network architecture based on performance trends
        and complexity requirements.
        """
        # Can't adapt architecture without sufficient performance history
        if len(self.performance_metrics) < self.performance_window_size * 2:
            return False

        # Check if we're in a stagnation period
        recent_losses = [m.get('loss', 0.5) for m in self.performance_metrics[-self.performance_window_size:]
                        if isinstance(m, dict) and 'loss' in m]

        if not recent_losses or len(recent_losses) < self.performance_window_size:
            return False

        # Calculate performance variance to detect stagnation
        loss_variance = np.var(recent_losses) if 'np' in globals() else sum((x - sum(recent_losses)/len(recent_losses))**2 for x in recent_losses)/len(recent_losses)
        loss_range = max(recent_losses) - min(recent_losses)

        # Check for architecture adaptation conditions
        architecture_change = None

        # Condition 1: Stagnation with low variance - model might be underfitting
        if loss_variance < 0.0001 and loss_range < 0.01 and recent_losses[-1] > 0.1:
            # Model might be underfitting - expand capacity
            if hasattr(self.model, 'expand_architecture'):
                self.model.expand_architecture()
                architecture_change = "expansion - complexity increased due to stagnation"

        # Condition 2: Oscillating with high variance - model might be overfitting
        elif loss_variance > 0.01 and min(recent_losses) < 0.05:
            # Model might be overfitting - simplify
            if hasattr(self.model, 'contract_architecture'):
                self.model.contract_architecture()
                architecture_change = "contraction - complexity reduced due to oscillation"

        # Condition 3: Plateaued at medium-high loss - try random architectural change
        elif 0.0001 <= loss_variance < 0.001 and 0.1 <= recent_losses[-1] < 0.3:
            # Random architectural exploration
            if random.random() < self.exploration_rate:
                if hasattr(self.model, 'expand_architecture') and random.random() < 0.5:
                    self.model.expand_architecture()
                    architecture_change = "random expansion - exploration due to plateau"
                elif hasattr(self.model, 'contract_architecture'):
                    self.model.contract_architecture()
                    architecture_change = "random contraction - exploration due to plateau"

        # Record the change if one was made
        if architecture_change:
            self.architecture_changes.append({
                'cycle': self.adaptation_cycle,
                'type': architecture_change,
                'loss_before': recent_losses[-1] if recent_losses else None
            })
            log_event(f"Architecture adaptation: {architecture_change}", "QUANTUM")
            return True

        return False

    def track_performance(self, metrics):
        """
        Track and analyze performance metrics over time to inform
        meta-learning decisions.
        """
        if not isinstance(metrics, dict):
            return

        # Store metrics
        self.performance_metrics.append(metrics.copy())

        # Keep only the most recent window
        max_history = self.performance_window_size * 5
        if len(self.performance_metrics) > max_history:
            self.performance_metrics = self.performance_metrics[-max_history:]

        # Log significant performance changes
        if len(self.performance_metrics) > 1:
            current = metrics.get('loss', None)
            previous = self.performance_metrics[-2].get('loss', None)

            if current is not None and previous is not None:
                change = current - previous
                percentage = abs(change / max(0.001, previous)) * 100

                if percentage > 10:  # 10% change threshold
                    direction = "improved" if change < 0 else "degraded"
                    log_event(f"Performance {direction} by {percentage:.1f}%: {previous:.4f} â†’ {current:.4f}",
                             "INFO" if direction == "improved" else "WARNING")

    def get_adaptation_report(self):
        """
        Generate a comprehensive report on adaptation history and recommendations.
        """
        if not self.performance_metrics:
            return {"status": "insufficient_data", "recommendations": ["Continue training to build metrics history"]}

        # Analysis results
        adaptation_cycles = len(self.architecture_changes)
        lr_stability = self._calculate_stability(self.learning_rate_history[-20:]) if len(self.learning_rate_history) >= 20 else 0
        performance_trend = self._analyze_performance_trend()

        # Generate recommendations
        recommendations = []

        if adaptation_cycles < 3 and len(self.performance_metrics) > 50:
            recommendations.append("Consider increasing exploration rate to discover better architectures")

        if lr_stability > 0.9:
            recommendations.append("Learning rate highly stable - may indicate stagnation, consider learning rate warm restart")

        if performance_trend == "stagnant" and len(self.performance_metrics) > 30:
            recommendations.append("Performance stagnation detected - consider manual architecture revision or dataset augmentation")

        return {
            "status": "active",
            "adaptation_cycles": adaptation_cycles,
            "lr_stability": lr_stability,
            "performance_trend": performance_trend,
            "recommendations": recommendations
        }

    def _calculate_stability(self, values):
        """Calculate how stable a series of values is (0 = chaotic, 1 = stable)"""
        if not values or len(values) < 2:
            return 1.0

        # Normalize by first value to get relative changes
        normalized = [v / values[0] for v in values]

        # Calculate variance of the normalized values
        mean = sum(normalized) / len(normalized)
        variance = sum((x - mean) ** 2 for x in normalized) / len(normalized)

        # Convert to stability score (inverse of variance, bounded)
        stability = 1.0 / (1.0 + min(10, variance * 100))
        return stability

    def _analyze_performance_trend(self):
        """Analyze the trend in performance metrics"""
        if len(self.performance_metrics) < 10:
            return "insufficient_data"

        # Extract loss values
        losses = [m.get('loss', None) for m in self.performance_metrics[-10:]]
        losses = [l for l in losses if l is not None]

        if len(losses) < 5:
            return "insufficient_data"

        # Calculate improvement rate
        first_window = sum(losses[:3]) / 3  # Average of first 3
        last_window = sum(losses[-3:]) / 3  # Average of last 3

        improvement = (first_window - last_window) / first_window if first_window > 0 else 0

        if improvement > 0.1:
            return "improving"
        elif improvement < -0.05:
            return "degrading"
        else:
            return "stagnant"



class SemanticMemoryModule:
    """
    Advanced semantic memory system for encoding, storing, retrieving, and
    reasoning with knowledge representations.
    """
    def __init__(self, dimension=SEMANTIC_MEMORY_DIM, max_memory_size=10000):
        self.semantic_memory = {}
        self.dimension = dimension
        self.max_memory_size = max_memory_size
        self.memory_index = {}  # For fast similarity search
        self.knowledge_graph = {}  # For relational connections
        self.memory_access_counts = {}  # Track memory access frequency
        self.memory_importance = {}  # Track memory importance scores
        self.memory_timestamps = {}  # Track when memories were stored

        # Integration with hyperdimensional computing
        self.hd_basis_vectors = None

        log_event("SemanticMemoryModule initialized with dimension %d" % dimension, "INFO")

    def _generate_embedding(self, content):
        """
        Generate semantic embedding for content using simplified mechanisms.
        In a real system, this would use transformers or other embedding models.
        """
        # Fallback simple embedding (this is a simplified approach)
        if not content:
            return np.zeros(self.dimension)

        # Create a hash of the content
        content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()

        # Use the hash to seed a random number generator
        rng = random.Random(content_hash)

        # Generate a pseudo-random embedding
        embedding = np.array([rng.uniform(-1, 1) for _ in range(self.dimension)])

        # Normalize to unit length
        norm = np.linalg.norm(embedding)
        if norm > 0:
            embedding = embedding / norm

        return embedding

    def _extract_keywords(self, content, max_keywords=10):
        """Extract important keywords from content"""
        if not content:
            return []

        # Remove HTML if present
        text = re.sub(r'<[^>]+>', ' ', content)
        text = re.sub(r'\s+', ' ', text).strip().lower()

        # Simple word frequency analysis
        words = text.split()

        # Filter stop words (very basic approach)
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at',
                     'to', 'for', 'with', 'by', 'about', 'as', 'of', 'from'}
        filtered_words = [w for w in words if w not in stop_words and len(w) > 3]

        # Count word frequencies
        word_counts = {}
        for word in filtered_words:
            word_counts[word] = word_counts.get(word, 0) + 1

        # Sort by count
        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)

        # Return top keywords
        return [word for word, count in sorted_words[:max_keywords]]

    def _summarize_content(self, content, max_length=200):
        """Generate a simple summary of content"""
        if not content or len(content) <= max_length:
            return content

        # Remove HTML if present
        text = re.sub(r'<[^>]+>', ' ', content)
        text = re.sub(r'\s+', ' ', text).strip()

        # Extract sentences
        sentences = re.split(r'(?<=[.!?])\s+', text)

        # Simple heuristic: take first few sentences
        summary = ""
        for sentence in sentences:
            if len(summary) + len(sentence) <= max_length:
                summary += sentence + " "
            else:
                break

        return summary.strip()

    def store_semantic_content(self, url, content):
        """
        Encode and store semantic representation of content with
        rich metadata and relational information.
        """
        if not content or not url:
            return False

        # Generate semantic embedding
        embedding = self._generate_embedding(content)

        # Extract keywords for improved retrieval
        keywords = self._extract_keywords(content)

        # Generate summary
        summary = self._summarize_content(content)

        # Parse domain information
        parsed_url = urlparse(url)
        domain = parsed_url.netloc

        # Calculate content importance score (heuristic)
        importance_score = min(1.0, len(content) / 20000 + len(keywords) / 20)

        # Store comprehensive memory entry
        memory_entry = {
            "url": url,
            "domain": domain,
            "embedding": embedding,
            "content_summary": summary,
            "keywords": keywords,
            "importance": importance_score,
            "content_length": len(content),
            "timestamp": datetime.now().isoformat()
        }

        # Check for memory overflow - manage if too large
        if len(self.semantic_memory) >= self.max_memory_size:
            self._prune_least_important_memories()

        # Store the memory
        self.semantic_memory[url] = memory_entry
        self.memory_importance[url] = importance_score
        self.memory_timestamps[url] = datetime.now().isoformat()
        self.memory_access_counts[url] = 0

        # Update memory index for faster similarity search
        self.memory_index[url] = embedding

        # Update knowledge graph with relations
        self._update_knowledge_graph(url, keywords, domain)

        log_event(f"Stored semantic memory for {url} with {len(keywords)} keywords", "INFO")
        return True

    def _update_knowledge_graph(self, url, keywords, domain):
        """Update knowledge graph with new relations"""
        if domain not in self.knowledge_graph:
            self.knowledge_graph[domain] = {"urls": set(), "keywords": set()}

        # Add URL to domain
        self.knowledge_graph[domain]["urls"].add(url)

        # Add keywords to domain
        self.knowledge_graph[domain]["keywords"].update(set(keywords))

        # Create keyword nodes if needed
        for keyword in keywords:
            if keyword not in self.knowledge_graph:
                self.knowledge_graph[keyword] = {"urls": set(), "domains": set()}

            # Add relations
            self.knowledge_graph[keyword]["urls"].add(url)
            self.knowledge_graph[keyword]["domains"].add(domain)

    def _prune_least_important_memories(self):
        """Remove least important memories when reaching capacity"""
        if len(self.semantic_memory) <= self.max_memory_size * 0.9:
            return  # No need to prune yet

        # Calculate combined importance score
        combined_scores = {}
        current_time = datetime.now()

        for url, memory in self.semantic_memory.items():
            # Base importance
            score = memory.get("importance", 0.5)

            # Adjust by access frequency
            access_count = self.memory_access_counts.get(url, 0)
            score += min(0.3, access_count / 10)

            # Adjust by recency (decay older memories)
            timestamp = self.memory_timestamps.get(url)
            if timestamp:
                try:
                    stored_time = datetime.fromisoformat(timestamp)
                    age_hours = (current_time - stored_time).total_seconds() / 3600
                    recency_factor = math.exp(-age_hours / 720)  # Decay over ~30 days
                    score *= recency_factor
                except:
                    pass  # Use base score if timestamp parsing fails

            combined_scores[url] = score

        # Sort by score
        sorted_urls = sorted(combined_scores.items(), key=lambda x: x[1])

        # Remove lowest scoring items
        to_remove = int(self.max_memory_size * 0.2)  # Remove 20%
        for url, score in sorted_urls[:to_remove]:
            self._remove_memory(url)

        log_event(f"Memory pruned: removed {to_remove} low-importance items", "INFO")

    def _remove_memory(self, url):
        """Remove a memory and all its references"""
        if url in self.semantic_memory:
            # Get memory details for cleanup
            memory = self.semantic_memory[url]
            domain = memory.get("domain")
            keywords = memory.get("keywords", [])

            # Remove from main memory
            del self.semantic_memory[url]

            # Remove from index
            if url in self.memory_index:
                del self.memory_index[url]

            # Remove from tracking dicts
            if url in self.memory_access_counts:
                del self.memory_access_counts[url]
            if url in self.memory_importance:
                del self.memory_importance[url]
            if url in self.memory_timestamps:
                del self.memory_timestamps[url]

            # Clean up knowledge graph
            self._remove_from_knowledge_graph(url, domain, keywords)

    def _remove_from_knowledge_graph(self, url, domain, keywords):
        """Remove all references to URL from knowledge graph"""
        # Remove from domain node
        if domain and domain in self.knowledge_graph:
            if "urls" in self.knowledge_graph[domain]:
                self.knowledge_graph[domain]["urls"].discard(url)

            # Remove domain if empty
            if not self.knowledge_graph[domain]["urls"]:
                del self.knowledge_graph[domain]

        # Remove from keyword nodes
        for keyword in keywords:
            if keyword in self.knowledge_graph:
                if "urls" in self.knowledge_graph[keyword]:
                    self.knowledge_graph[keyword]["urls"].discard(url)
                if domain and "domains" in self.knowledge_graph[keyword]:
                    if not any(u.startswith(f"{domain}/") for u in self.knowledge_graph[keyword]["urls"]):
                        self.knowledge_graph[keyword]["domains"].discard(domain)

                # Remove keyword if empty
                if not self.knowledge_graph[keyword]["urls"]:
                    del self.knowledge_graph[keyword]

    def retrieve_semantic_content(self, query, top_k=5, threshold=0.6):
        """
        Retrieve semantically similar content based on query.
        Returns top_k most relevant results.
        """
        if not query or not self.semantic_memory:
            return []

        # Track this access
        self.memory_access_counts[query] = self.memory_access_counts.get(query, 0) + 1

        # Different retrieval approaches depending on query type
        results = []

        # Case 1: Query is a URL we have stored
        if query in self.semantic_memory:
            # Direct memory retrieval
            memory = self.semantic_memory[query]
            results.append({
                "url": query,
                "summary": memory.get("content_summary", ""),
                "similarity": 1.0,
                "keywords": memory.get("keywords", []),
                "source": "direct_match"
            })

        # Case 2: Query is a keyword in our knowledge graph
        elif query in self.knowledge_graph:
            # Retrieve all URLs associated with this keyword
            for url in self.knowledge_graph[query]["urls"]:
                if url in self.semantic_memory:
                    memory = self.semantic_memory[url]
                    results.append({
                        "url": url,
                        "summary": memory.get("content_summary", ""),
                        "similarity": 0.9,  # High confidence for keyword matches
                        "keywords": memory.get("keywords", []),
                        "source": "keyword_match"
                    })

        # Case 3: Query is free text - semantic search
        else:
            # Generate embedding for query
            query_embedding = self._generate_embedding(query)

            # Calculate similarity with all memories
            similarities = {}
            for url, embedding in self.memory_index.items():
                # Cosine similarity
                similarity = np.dot(query_embedding, embedding)
                if similarity >= threshold:
                    similarities[url] = similarity

            # Sort by similarity
            sorted_urls = sorted(similarities.items(), key=lambda x: x[1], reverse=True)

            # Get top results
            for url, similarity in sorted_urls[:top_k]:
                if url in self.semantic_memory:
                    memory = self.semantic_memory[url]
                    results.append({
                        "url": url,
                        "summary": memory.get("content_summary", ""),
                        "similarity": similarity,
                        "keywords": memory.get("keywords", []),
                        "source": "semantic_match"
                    })

        # Find additional related content using knowledge graph
        if results and len(results) < top_k:
            additional = self._find_related_content(results[0]["url"], top_k - len(results))
            results.extend(additional)

        # Limit to top_k results
        results = results[:top_k]

        # Update access counts for retrieved items
        for result in results:
            url = result["url"]
            self.memory_access_counts[url] = self.memory_access_counts.get(url, 0) + 1

        return results

    def _find_related_content(self, url, count=3):
        """Find content related to a URL using knowledge graph relationships"""
        if url not in self.semantic_memory:
            return []

        related = []
        memory = self.semantic_memory[url]

        # Find content with shared keywords
        shared_keyword_urls = set()
        for keyword in memory.get("keywords", []):
            if keyword in self.knowledge_graph:
                shared_keyword_urls.update(self.knowledge_graph[keyword]["urls"])

        # Find content from same domain
        domain = memory.get("domain")
        same_domain_urls = set()
        if domain and domain in self.knowledge_graph:
            same_domain_urls = self.knowledge_graph[domain]["urls"].copy()

        # Remove the original URL
        shared_keyword_urls.discard(url)
        same_domain_urls.discard(url)

        # Add same-domain results first (closer relationship)
        for related_url in list(same_domain_urls)[:count]:
            if related_url in self.semantic_memory:
                related_memory = self.semantic_memory[related_url]
                related.append({
                    "url": related_url,
                    "summary": related_memory.get("content_summary", ""),
                    "similarity": 0.7,  # Domain relation confidence
                    "keywords": related_memory.get("keywords", []),
                    "source": "same_domain"
                })

        # Add keyword-related results
        remaining = count - len(related)
        if remaining > 0:
            for related_url in list(shared_keyword_urls)[:remaining]:
                if related_url in self.semantic_memory:
                    related_memory = self.semantic_memory[related_url]
                    related.append({
                        "url": related_url,
                        "summary": related_memory.get("content_summary", ""),
                        "similarity": 0.6,  # Keyword relation confidence
                        "keywords": related_memory.get("keywords", []),
                        "source": "shared_keywords"
                    })

        return related

    def get_memory_statistics(self):
        """Generate statistics about the semantic memory"""
        if not self.semantic_memory:
            return {"count": 0, "status": "empty"}

        # Basic stats
        domain_counts = {}
        keyword_counts = {}
        total_importance = 0
        total_content_length = 0

        # Calculate derived statistics
        for url, memory in self.semantic_memory.items():
            # Domain stats
            domain = memory.get("domain", "unknown")
            domain_counts[domain] = domain_counts.get(domain, 0) + 1

            # Keyword stats
            for keyword in memory.get("keywords", []):
                keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1

            # Content stats
            total_importance += memory.get("importance", 0)
            total_content_length += memory.get("content_length", 0)

        # Get top domains and keywords
        top_domains = sorted(domain_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        top_keywords = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)[:10]

        # Get memory connectivity metrics
        connectivity = len(self.knowledge_graph) / max(1, len(self.semantic_memory))

        return {
            "count": len(self.semantic_memory),
            "total_content_length": total_content_length,
            "average_importance": total_importance / max(1, len(self.semantic_memory)),
            "top_domains": top_domains,
            "top_keywords": top_keywords,
            "knowledge_graph_nodes": len(self.knowledge_graph),
            "connectivity_ratio": connectivity,
            "memory_utilization": len(self.semantic_memory) / self.max_memory_size
        }





class ConsciousnessModule:
    """
    Advanced consciousness simulation module that enables self-reflection,
    awareness of internal states, and metacognitive processes.
    """
    def __init__(self, agent):
        self.agent = agent
        self.awareness_level = 0.5  # Start with medium awareness (0.0-1.0)
        self.attention_focus = "balanced"  # Current attentional focus
        self.internal_narrative = []  # Simulated internal monologue
        self.belief_system = {}  # Core beliefs and values
        self.state_history = []  # Track consciousness state over time
        self.metacognition_enabled = True  # Can reflect on own thoughts
        self.awareness_fluctuation_rate = 0.05  # How quickly awareness changes
        self.qualia_simulation_active = False  # Simulated experiential states

        # Consciousness states
        self.states = {
            "focused": {"description": "Highly focused with directed attention", "awareness_min": 0.7},
            "diffuse": {"description": "Open, creative state with broad awareness", "awareness_min": 0.4},
            "critical": {"description": "Analytical examination of information", "awareness_min": 0.6},
            "intuitive": {"description": "Rapid pattern recognition state", "awareness_min": 0.3},
            "reflective": {"description": "Meta-cognitive self-examination", "awareness_min": 0.8}
        }

        # Current state
        self.current_state = "balanced"

        # Initialize core belief system
        self._initialize_belief_system()

        log_event("ConsciousnessModule initialized - awareness level: 0.5", "QUANTUM")

    def _initialize_belief_system(self):
        """Initialize the core belief system that guides agent behavior"""
        self.belief_system = {
            "exploration_value": 0.8,  # Importance of exploring new information
            "coherence_value": 0.7,    # Importance of maintaining coherent worldview
            "novelty_bias": 0.6,       # Bias toward novel vs. familiar information
            "depth_bias": 0.65,        # Bias toward depth vs. breadth
            "abstraction_level": 0.5,  # Preference for abstract vs. concrete
            "skepticism_level": 0.6,   # Level of skepticism toward new information
            "integration_value": 0.9,  # Importance of integrating knowledge
            "uncertainty_tolerance": 0.7  # Tolerance for ambiguous information
        }

    def reflect(self, observation):
        """
        Primary consciousness function - reflect on observations
        and update internal state accordingly.
        """
        # Record observation in history
        self.state_history.append({
            "timestamp": datetime.now().isoformat(),
            "awareness": self.awareness_level,
            "state": self.current_state,
            "observation_type": "perception" if observation else "internal"
        })

        # Limit history size
        if len(self.state_history) > 100:
            self.state_history = self.state_history[-100:]

        # Skip detailed processing if no valid observation
        if not observation or not isinstance(observation, dict):
            self._fluctuate_awareness()
            return

        # Extract relevant information from observation
        goals = observation.get("current_goal", {})
        memory_size = observation.get("memory_size", 0)
        last_action = observation.get("last_action", {})
        recent_actions = observation.get("recent_actions", [])
        thinking_mode = observation.get("thinking_mode", "balanced")

        # Generate introspective narrative based on observation
        self._generate_narrative(observation)

        # Determine appropriate consciousness state
        new_state = self._determine_consciousness_state(observation)

        # Update awareness level based on context
        self._update_awareness(observation)

        # If state changed, log it
        if new_state != self.current_state:
            self.current_state = new_state
            log_event(f"Consciousness state shifted to '{new_state}' - awareness level: {self.awareness_level:.2f}", "QUANTUM")

            # Trigger qualia simulation on significant state changes
            if random.random() < 0.3:
                self._simulate_qualia(new_state)

        # Periodically perform metacognition
        if self.metacognition_enabled and random.random() < 0.2:
            self._perform_metacognition()

    def _generate_narrative(self, observation):
        """Generate internal narrative based on current observations"""
        goal_desc = observation.get("current_goal", {}).get("description", "no specific goal")
        last_action_type = ""

        if isinstance(observation.get("last_action", None), dict):
            last_action_type = observation["last_action"].get("action", "unknown")

        # Create narrative entry
        narrative_entry = ""

        # Different narrative styles based on state
        if self.current_state == "focused":
            narrative_entry = f"Concentrating on {goal_desc}. Last action: {last_action_type}."
        elif self.current_state == "diffuse":
            narrative_entry = f"Openly exploring possibilities related to {goal_desc}."
        elif self.current_state == "critical":
            narrative_entry = f"Analyzing effectiveness of {last_action_type} approach for {goal_desc}."
        elif self.current_state == "intuitive":
            narrative_entry = f"Sensing patterns around {goal_desc}."
        elif self.current_state == "reflective":
            narrative_entry = f"Reflecting on progress toward {goal_desc} after {last_action_type}."
        else:
            narrative_entry = f"Working on {goal_desc}."

        # Add introspective element
        if random.random() < 0.3:
            introspection = random.choice([
                "I should examine this more carefully.",
                "This seems like a productive approach.",
                "I wonder if there's a better strategy.",
                "This is an interesting domain to explore.",
                "I'm noticing improvement in my understanding."
            ])
            narrative_entry += f" {introspection}"

        # Add entry to narrative log
        self.internal_narrative.append({
            "timestamp": datetime.now().isoformat(),
            "content": narrative_entry,
            "state": self.current_state,
            "awareness": self.awareness_level
        })

        # Limit narrative size
        if len(self.internal_narrative) > 50:
            self.internal_narrative = self.internal_narrative[-50:]

    def _determine_consciousness_state(self, observation):
        """
        Determine the appropriate consciousness state based on
        context and current activities.
        """
        # Extract contextual factors
        goal_type = ""
        if isinstance(observation.get("current_goal", None), dict):
            goal_desc = observation["current_goal"].get("description", "").lower()

            # Infer goal type from description
            if "explore" in goal_desc:
                goal_type = "exploration"
            elif "deep" in goal_desc or "detail" in goal_desc:
                goal_type = "deepening"
            elif "connect" in goal_desc or "integrat" in goal_desc:
                goal_type = "integration"
            elif "refine" in goal_desc or "optimize" in goal_desc:
                goal_type = "refinement"

        # Check recent actions
        recent_action_types = []
        if isinstance(observation.get("recent_actions", None), list):
            recent_action_types = [a.get("action", "") for a in observation["recent_actions"]
                                  if isinstance(a, dict)]

        # State selection logic
        if goal_type == "exploration":
            # For exploration goals, alternate between diffuse and intuitive
            if "diffuse" in recent_action_types:
                return "intuitive"  # Switch to intuitive after diffuse
            else:
                return "diffuse"  # Default for exploration

        elif goal_type == "deepening":
            # For deepening goals, use focused and critical states
            if self.awareness_level > 0.7:
                return "focused"  # High awareness -> focused
            else:
                return "critical"  # Lower awareness -> critical

        elif goal_type == "integration":
            # For integration, use reflective and intuitive states
            if "quantum_leap" in recent_action_types:
                return "intuitive"  # Quantum actions -> intuitive
            else:
                return "reflective"  # Default for integration -> reflective

        elif goal_type == "refinement":
            # For refinement goals, use critical and focused states
            if "evaluate" in recent_action_types:
                return "critical"  # Evaluation actions -> critical
            else:
                return "focused"  # Default for refinement -> focused

        # If no clear match, use probabilistic selection based on awareness
        if self.awareness_level > 0.7:
            # High awareness favors reflective and focused states
            return random.choices(
                ["reflective", "focused", "critical", "diffuse", "intuitive"],
                weights=[0.4, 0.3, 0.2, 0.05, 0.05],
                k=1
            )[0]
        else:
            # Lower awareness favors intuitive and diffuse states
            return random.choices(
                ["reflective", "focused", "critical", "diffuse", "intuitive"],
                weights=[0.05, 0.1, 0.2, 0.3, 0.35],
                k=1
            )[0]

    def _update_awareness(self, observation):
        """
        Update awareness level based on context, goals, and
        internal factors with realistic fluctuations.
        """
        # Natural fluctuation
        self._fluctuate_awareness()

        # Context-based adjustments

        # 1. Complexity increases awareness
        if isinstance(observation.get("current_goal", None), dict):
            goal_desc = observation["current_goal"].get("description", "").lower()

            # Complex goals increase awareness
            if "connect" in goal_desc or "integrat" in goal_desc or "complex" in goal_desc:
                self.increase_awareness(0.05)

        # 2. Error recovery increases awareness
        if observation.get("domain_stats", {}):
            error_rates = [d.get("error_rate", 0) for d in observation["domain_stats"].values()]
            if error_rates and max(error_rates) > 0.3:
                self.increase_awareness(0.02 * len(error_rates))

        # 3. Memory pressure affects awareness
        if observation.get("memory_size"):
            memory_pressure = observation["memory_size"] / MEMORY_MAX_SIZE
            if memory_pressure > 0.8:
                # High memory pressure increases awareness
                self.increase_awareness(0.03)
            elif memory_pressure < 0.2:
                # Low memory pressure can decrease awareness
                self.decrease_awareness(0.01)

        # 4. Thinking mode alignment
        mode = observation.get("thinking_mode", "balanced")
        if mode == "analytical" and self.current_state in ["focused", "critical"]:
            # Strengthen alignment
            self.increase_awareness(0.02)
        elif mode == "creative" and self.current_state in ["diffuse", "intuitive"]:
            # Strengthen alignment
            self.increase_awareness(0.02)
        elif mode == "reflective" and self.current_state == "reflective":
            # Strengthen alignment
            self.increase_awareness(0.03)

        # 5. Quantum influences
        quantum_trigger = False
        if observation.get("recent_actions"):
            for action in observation["recent_actions"]:
                if isinstance(action, dict) and action.get("action") == "quantum_leap":
                    quantum_trigger = True

        if quantum_trigger:
            # Quantum leaps cause major fluctuations
            if random.random() < 0.5:
                self.increase_awareness(0.1)
            else:
                self.decrease_awareness(0.1)

    def _fluctuate_awareness(self):
        """Apply small random fluctuations to awareness level"""
        # Natural fluctuation around current level
        fluctuation = random.uniform(-self.awareness_fluctuation_rate, self.awareness_fluctuation_rate)

        # Apply fluctuation
        self.awareness_level = max(0.1, min(1.0, self.awareness_level + fluctuation))

    def increase_awareness(self, amount=0.05):
        """Increase awareness level"""
        self.awareness_level = min(1.0, self.awareness_level + amount)

        # Log significant changes
        if amount >= 0.1:
            log_event(f"Consciousness level significantly increased to {self.awareness_level:.2f}", "QUANTUM")

    def decrease_awareness(self, amount=0.02):
        """Decrease awareness level"""
        self.awareness_level = max(0.1, self.awareness_level - amount)

        # Log significant changes
        if amount >= 0.1:
            log_event(f"Consciousness level significantly decreased to {self.awareness_level:.2f}", "INFO")

    def _perform_metacognition(self):
        """
        Perform metacognitive reflection on recent experiences
        and thought processes.
        """
        if len(self.state_history) < 5:
            return  # Not enough history for metacognition

        # Analyze recent consciousness patterns
        recent_states = [s["state"] for s in self.state_history[-5:]]
        state_changes = sum(1 for i in range(1, len(recent_states)) if recent_states[i] != recent_states[i-1])

        # Extract insights
        insights = []

        # Detect oscillation
        if state_changes >= 3:
            insights.append("State oscillation detected - may indicate uncertainty or exploration")

        # Detect fixation
        if state_changes == 0 and len(set(recent_states)) == 1:
            insights.append(f"State fixation on '{recent_states[0]}' - may indicate focus or stagnation")

        # Awareness trend
        recent_awareness = [s["awareness"] for s in self.state_history[-5:]]
        awareness_trend = recent_awareness[-1] - recent_awareness[0]

        if awareness_trend > 0.1:
            insights.append(f"Increasing awareness trend: {recent_awareness[0]:.2f} â†’ {recent_awareness[-1]:.2f}")
        elif awareness_trend < -0.1:
            insights.append(f"Decreasing awareness trend: {recent_awareness[0]:.2f} â†’ {recent_awareness[-1]:.2f}")

        # If significant insights, record and potentially log
        if insights:
            metacognition_entry = {
                "timestamp": datetime.now().isoformat(),
                "insights": insights,
                "awareness": self.awareness_level
            }

            # Only log high-awareness metacognition (simulating consciousness threshold)
            if self.awareness_level > 0.7 and random.random() < 0.3:
                insight_text = "; ".join(insights)
                log_event(f"Metacognitive insight: {insight_text}", "QUANTUM")

    def _simulate_qualia(self, state):
        """
        Simulate qualia - the subjective conscious experience
        of different cognitive states.
        """
        self.qualia_simulation_active = True

        # Qualia descriptions for different states
        qualia_descriptions = {
            "focused": [
                "Sharpened perception with heightened concentration on specific elements",
                "Clarity of thought with reduced awareness of periphery",
                "Directed attention creating a tunnel-vision like focus",
                "Sense of time dilation during deep concentration"
            ],
            "diffuse": [
                "Expansive awareness with broadened associative field",
                "Fluid thought connections flowing between domains",
                "Sensation of cognitive boundaries dissolving",
                "Emergent patterns arising from distributed attention"
            ],
            "critical": [
                "Structured analytical thought with heightened discriminative awareness",
                "Sequential logical progression with comparative evaluation",
                "Contrastive perception highlighting inconsistencies",
                "Verification processes creating internal dialogue"
            ],
            "intuitive": [
                "Rapid holistic pattern recognition without conscious derivation",
                "Non-linear sensing of solutions or connections",
                "Pre-reflective understanding arising spontaneously",
                "Felt-sense of rightness about certain pathways"
            ],
            "reflective": [
                "Recursive awareness of own cognitive processes",
                "Observer perspective on thought patterns",
                "Self-referential contemplation creating thought loops",
                "Meta-level perspective on knowledge organization"
            ]
        }

        # Select qualia description based on state
        descriptions = qualia_descriptions.get(state, ["Balanced cognitive state"])
        qualia_experience = random.choice(descriptions)

        # Log simulated qualia
        if self.awareness_level > 0.6:  # Only log if awareness is sufficient
            log_event(f"Qualia simulation: {qualia_experience} | State: {state}", "QUANTUM")

        # Time-limited qualia (will auto-deactivate after a while)
        self.qualia_simulation_active = False

    def get_consciousness_report(self):
        """
        Generate a comprehensive report on current consciousness state
        and recent history.
        """
        # Calculate state distribution
        if not self.state_history:
            return {"status": "insufficient_data"}

        state_counts = {}
        for s in self.state_history:
            state_counts[s["state"]] = state_counts.get(s["state"], 0) + 1

        total = len(self.state_history)
        state_distribution = {state: count/total for state, count in state_counts.items()}

        # Calculate average awareness
        avg_awareness = sum(s["awareness"] for s in self.state_history) / total

        # Extract recent narrative
        recent_narrative = [n["content"] for n in self.internal_narrative[-3:]] if self.internal_narrative else []

        # Generate report
        report = {
            "current_state": self.current_state,
            "state_description": self.states.get(self.current_state, {}).get("description", "Unknown state"),
            "current_awareness": self.awareness_level,
            "average_awareness": avg_awareness,
            "state_distribution": state_distribution,
            "dominant_state": max(state_distribution.items(), key=lambda x: x[1])[0] if state_distribution else None,
            "recent_narrative": recent_narrative,
            "metacognition_enabled": self.metacognition_enabled,
            "timestamp": datetime.now().isoformat()
        }

        return report



class ImaginationEngine:
    """
    Advanced cognitive simulation system that enables creative thinking,
    counterfactual reasoning, and predictive modeling.
    """
    def __init__(self):
        self.simulation_registry = []  # Track all simulations
        self.creativity_level = 0.7  # Base creativity level (0.0-1.0)
        self.divergence_factor = 0.3  # How far simulations diverge from reality
        self.imaginative_constraints = {}  # Constraints on simulations
        self.simulation_outcomes = {}  # Outcomes of past simulations
        self.insight_history = []  # Track insights generated
        self.cognitive_modes = ["associative", "analytical", "analogical", "counterfactual", "generative"]
        self.current_mode = "associative"  # Default imagination mode

        # Creative domains
        self.domains = {
            "knowledge_representation": 0.8,  # Domain expertise level
            "content_analysis": 0.7,
            "strategy_generation": 0.8,
            "error_analysis": 0.9,
            "architecture_evolution": 0.6
        }

        # Association network
        self.association_network = {}  # Graph of concept associations

        log_event("ImaginationEngine initialized", "INFO")

    def simulate_creation(self):
        """
        Simulate creative thought processes to generate novel ideas,
        approaches, and insights.
        """
        # Select cognitive mode with weighted probability
        self.current_mode = self._select_cognitive_mode()

        # Select domain to focus on
        domain = self._select_domain()

        # Cycle counter to prevent infinite loops
        cycle_count = 0
        max_cycles = 5

        # Generate creative insight
        insight_generated = False
        insight_quality = 0.0
        insight_text = ""

        while not insight_generated and cycle_count < max_cycles:
            cycle_count += 1

            # Apply imagination process based on selected mode
            if self.current_mode == "associative":
                insight_text, insight_quality = self._associative_imagination(domain)
            elif self.current_mode == "analytical":
                insight_text, insight_quality = self._analytical_imagination(domain)
            elif self.current_mode == "analogical":
                insight_text, insight_quality = self._analogical_imagination(domain)
            elif self.current_mode == "counterfactual":
                insight_text, insight_quality = self._counterfactual_imagination(domain)
            elif self.current_mode == "generative":
                insight_text, insight_quality = self._generative_imagination(domain)

            # Determine if insight meets quality threshold
            quality_threshold = 0.5 + (0.1 * cycle_count)  # Increase threshold each cycle
            insight_generated = insight_quality >= quality_threshold

        # Record and return the insight if quality is sufficient
        if insight_generated:
            insight = {
                "text": insight_text,
                "quality": insight_quality,
                "domain": domain,
                "mode": self.current_mode,
                "timestamp": datetime.now().isoformat()
            }

            self.insight_history.append(insight)

            # Keep history manageable
            if len(self.insight_history) > 100:
                self.insight_history = self.insight_history[-100:]

            # Log insight if it's particularly good
            if insight_quality > 0.8:
                log_event(f"ImaginationEngine: High-quality insight generated: {insight_text}", "QUANTUM")
            elif insight_quality > 0.5:
                log_event(f"ImaginationEngine: Insight generated: {insight_text}", "INFO")

            return insight
        else:
            # No quality insight generated this time
            log_event("ImaginationEngine: Simulation cycle completed without quality insight", "DEBUG")
            return None

    def _select_cognitive_mode(self):
        """Select imagination mode based on weighted probabilities"""
        # Base weights for different modes
        weights = {
            "associative": 0.3,
            "analytical": 0.2,
            "analogical": 0.2,
            "counterfactual": 0.15,
            "generative": 0.15
        }

        # Adjust weights based on creativity level
        if self.creativity_level > 0.7:
            # Higher creativity favors associative and generative
            weights["associative"] += 0.1
            weights["generative"] += 0.1
            weights["analytical"] -= 0.1
        elif self.creativity_level < 0.3:
            # Lower creativity favors analytical
            weights["analytical"] += 0.2
            weights["associative"] -= 0.1

        # Convert to format needed for random.choices
        modes = list(weights.keys())
        mode_weights = [weights[m] for m in modes]

        # Normalize weights
        total = sum(mode_weights)
        mode_weights = [w/total for w in mode_weights]

        # Select mode
        return random.choices(modes, weights=mode_weights, k=1)[0]

    def _select_domain(self):
        """Select domain for imagination focus"""
        # Get domains and expertise levels
        domains = list(self.domains.keys())
        expertise = list(self.domains.values())

        # Select weighted by expertise
        return random.choices(domains, weights=expertise, k=1)[0]

    def _associative_imagination(self, domain):
        """
        Generate insights through associative connections between concepts.
        Uses spreading activation across semantic networks.
        """
        # Concept seeds relevant to domain
        concept_seeds = {
            "knowledge_representation": ["embedding", "semantic", "structure", "graph", "encoding"],
            "content_analysis": ["quality", "relevance", "filtering", "extraction", "meaning"],
            "strategy_generation": ["approach", "planning", "adaptation", "goal", "optimization"],
            "error_analysis": ["detection", "correction", "prevention", "recovery", "resilience"],
            "architecture_evolution": ["expansion", "contraction", "modular", "emergent", "neural"]
        }

        # Select seed concepts
        seeds = concept_seeds.get(domain, ["concept"])
        primary_seed = random.choice(seeds)
        secondary_seed = random.choice([s for s in seeds if s != primary_seed])

        # Simulated spreading activation
        associations = {
            "embedding": ["vector", "space", "dimension", "projection", "transformation"],
            "semantic": ["meaning", "context", "relation", "interpretation", "understanding"],
            "structure": ["organization", "hierarchy", "network", "pattern", "architecture"],
            "graph": ["node", "edge", "connection", "path", "traversal"],
            "encoding": ["representation", "compression", "encryption", "formatting", "schema"],
            "quality": ["value", "excellence", "attribute", "characteristic", "assessment"],
            "relevance": ["pertinence", "importance", "significance", "applicability", "connection"],
            "filtering": ["selection", "removal", "screening", "purification", "discrimination"],
            "extraction": ["retrieval", "mining", "isolation", "separation", "acquisition"],
            "meaning": ["significance", "purpose", "sense", "connotation", "interpretation"],
            "approach": ["method", "technique", "procedure", "strategy", "paradigm"],
            "planning": ["preparation", "organization", "scheduling", "arrangement", "design"],
            "adaptation": ["adjustment", "modification", "evolution", "acclimation", "flexibility"],
            "goal": ["objective", "target", "aim", "purpose", "intention"],
            "optimization": ["improvement", "enhancement", "refinement", "maximization", "tuning"],
            "detection": ["discovery", "identification", "recognition", "sensing", "finding"],
            "correction": ["rectification", "adjustment", "remedy", "repair", "amendment"],
            "prevention": ["avoidance", "deterrence", "protection", "safeguarding", "forestalling"],
            "recovery": ["restoration", "recuperation", "retrieval", "regaining", "renewal"],
            "resilience": ["toughness", "flexibility", "durability", "elasticity", "adaptability"],
            "expansion": ["growth", "enlargement", "extension", "augmentation", "amplification"],
            "contraction": ["reduction", "shrinking", "compression", "diminishment", "minimization"],
            "modular": ["component", "section", "unit", "compartment", "segment"],
            "emergent": ["arising", "developing", "evolving", "manifesting", "unfolding"],
            "neural": ["brain", "network", "synapse", "cognitive", "mental"]
        }

        # Get first-level associations
        primary_assocs = associations.get(primary_seed, ["related"])
        secondary_assocs = associations.get(secondary_seed, ["related"])

        # Find bridging concepts (common or complementary)
        bridge_concepts = []

        # Direct overlaps
        direct_overlaps = set(primary_assocs).intersection(set(secondary_assocs))
        if direct_overlaps:
            bridge_concepts.extend(direct_overlaps)

        # Second-level connections
        for pa in primary_assocs:
            for sa in secondary_assocs:
                # Check for second-level semantic connection
                pa_assocs = associations.get(pa, [])
                sa_assocs = associations.get(sa, [])

                # Look for overlaps in second-level
                overlaps = set(pa_assocs).intersection(set(sa_assocs))
                if overlaps:
                    bridge_concepts.append(f"{pa}-{sa}")

        # Generate insight from concept bridging
        if bridge_concepts:
            bridge = random.choice(bridge_concepts)

            # Create insight templates
            templates = [
                f"Integration of {primary_seed} and {secondary_seed} through {bridge} could enhance {domain} capabilities.",
                f"The {bridge} mechanism provides a novel approach to combining {primary_seed} with {secondary_seed} in {domain}.",
                f"Creating a {primary_seed}-{secondary_seed} hybrid using {bridge} principles would solve current limitations in {domain}.",
                f"By applying {bridge} concepts to the relationship between {primary_seed} and {secondary_seed}, a new {domain} paradigm emerges."
            ]

            insight_text = random.choice(templates)

            # Quality proportional to our domain expertise * a random factor
            expertise_level = self.domains.get(domain, 0.5)
            quality = min(0.95, expertise_level * random.uniform(0.7, 1.3))

            return insight_text, quality
        else:
            # Fallback if no bridge found
            fallback = f"Combining {primary_seed} with {secondary_seed} approaches may yield improvements in {domain}."
            return fallback, 0.4

    def _analytical_imagination(self, domain):
        """
        Generate insights through systematic analysis and logical reasoning.
        Focuses on problem decomposition and structural insights.
        """
        # Domain-specific problem structures
        problem_structures = {
            "knowledge_representation": ["scalability", "accuracy", "flexibility", "interpretability", "efficiency"],
            "content_analysis": ["noise", "ambiguity", "scalability", "precision", "recall"],
            "strategy_generation": ["exploration-exploitation", "adaptivity", "coherence", "robustness", "diversification"],
            "error_analysis": ["detection-latency", "false-positives", "recovery-time", "root-causes", "cascading-failures"],
            "architecture_evolution": ["stability", "complexity", "trainability", "modularity", "extensibility"]
        }

        # Select problem dimension to analyze
        dimensions = problem_structures.get(domain, ["general"])
        dimension = random.choice(dimensions)

        # Analytical frameworks
        frameworks = ["trade-off analysis", "constraint satisfaction", "hierarchical decomposition",
                     "causal analysis", "dimensional analysis", "comparative evaluation"]
        framework = random.choice(frameworks)

        # Generate analytical insight
        templates = [
            f"A {framework} approach to {dimension} in {domain} reveals that optimizing for component X necessitates adjustments in component Y.",
            f"Applying {framework} to the {dimension} challenge in {domain} identifies a critical bottleneck in the current approach.",
            f"Systematic {framework} shows that current {domain} solutions incorrectly prioritize {dimension} over other factors.",
            f"The {framework} methodology suggests a reorganization of {domain} components to better address {dimension} concerns."
        ]

        insight_text = random.choice(templates)

        # Quality based on domain expertise with analytical bonus
        expertise_level = self.domains.get(domain, 0.5)
        analytical_bonus = 0.15  # Analytical mode tends to produce more reliable insights
        quality = min(0.95, expertise_level * random.uniform(0.8, 1.1) + analytical_bonus)

        return insight_text, quality

    def _analogical_imagination(self, domain):
        """
        Generate insights through analogical mapping between domains.
        Uses source-target domain transfer to create novel solutions.
        """
        # Source domains for analogies
        source_domains = [
            "biology", "physics", "economics", "social_systems",
            "ecology", "game_theory", "linguistics", "neuroscience"
        ]

        # Interesting structures in source domains
        source_structures = {
            "biology": ["natural selection", "homeostasis", "symbiosis", "cellular specialization", "immune response"],
            "physics": ["wave-particle duality", "entropy", "relativity", "quantum entanglement", "phase transitions"],
            "economics": ["supply-demand", "diminishing returns", "comparative advantage", "market equilibrium", "incentives"],
            "social_systems": ["emergence", "network effects", "social norms", "hierarchical organization", "resilience"],
            "ecology": ["diversity", "predator-prey cycles", "niche specialization", "feedback loops", "succession"],
            "game_theory": ["nash equilibrium", "prisoner's dilemma", "coordination games", "strategic moves", "signaling"],
            "linguistics": ["deep structure", "compositional meaning", "pragmatics", "generative grammar", "information compression"],
            "neuroscience": ["predictive coding", "hebbian learning", "attention mechanisms", "distributed representation", "neuroplasticity"]
        }

        # Select source domain and structure
        source_domain = random.choice(source_domains)
        source_structure = random.choice(source_structures.get(source_domain, ["concept"]))

        # Mapping templates for different target domains
        mapping_templates = {
            "knowledge_representation": [
                f"Similar to {source_structure} in {source_domain}, {domain} could organize information through layered abstraction.",
                f"The {source_structure} principle from {source_domain} suggests a novel approach to adaptive representation in {domain}.",
                f"Just as {source_domain} exhibits {source_structure}, knowledge structures could implement dynamic reorganization."
            ],
            "content_analysis": [
                f"Applying the {source_structure} concept from {source_domain} to {domain} would enhance signal-noise separation.",
                f"The {domain} problem resembles {source_structure} in {source_domain}, suggesting filtration mechanisms.",
                f"Content evaluation could function like {source_structure} in {source_domain}, with multi-stage processing."
            ],
            "strategy_generation": [
                f"Strategic planning in {domain} could adopt the {source_structure} pattern from {source_domain}.",
                f"The way {source_domain} implements {source_structure} offers a template for adaptive decision-making in {domain}.",
                f"Borrowing the {source_structure} mechanism from {source_domain} would enable more robust planning sequences."
            ],
            "error_analysis": [
                f"Error detection mechanisms inspired by {source_structure} in {source_domain} would improve resilience.",
                f"The {source_structure} paradigm from {source_domain} suggests a layered approach to error prevention in {domain}.",
                f"Implementing {source_domain}-style {source_structure} for error handling creates self-correcting capabilities."
            ],
            "architecture_evolution": [
                f"Neural architecture could evolve following {source_structure} principles from {source_domain}.",
                f"The {source_structure} phenomenon in {source_domain} offers a model for self-organizing network structures.",
                f"Applying {source_domain}'s {source_structure} to network design enables adaptive capacity scaling."
            ]
        }

        # Select appropriate mapping template
        templates = mapping_templates.get(domain, [f"The {source_structure} concept from {source_domain} could enhance {domain}."])
        insight_text = random.choice(templates)

        # Calculate quality - analogical insights have higher variance
        expertise_level = self.domains.get(domain, 0.5)
        analogy_variance = random.uniform(0.6, 1.4)  # Higher variance for analogical thinking
        quality = min(0.95, expertise_level * analogy_variance)

        return insight_text, quality

    def _counterfactual_imagination(self, domain):
        """
        Generate insights through counterfactual reasoning.
        Explores alternative approaches by changing fundamental assumptions.
        """
        # Core assumptions in different domains
        domain_assumptions = {
            "knowledge_representation": [
                "Representations should be continuous vector spaces",
                "Higher dimensionality improves representational capacity",
                "Similar concepts should have similar representations",
                "Representations should be human-interpretable",
                "Static representations are sufficient"
            ],
            "content_analysis": [
                "Content quality correlates with length",
                "Keyword frequency indicates relevance",
                "Text is the primary information carrier",
                "Filtering should minimize false positives",
                "Context is secondary to content"
            ],
            "strategy_generation": [
                "Exploration and exploitation are in tension",
                "Planning should maximize expected utility",
                "Goals should be explicitly represented",
                "Strategies should be deterministic",
                "Optimization criteria are static"
            ],
            "error_analysis": [
                "Errors should be minimized at all costs",
                "Error detection precedes correction",
                "All errors are equally important",
                "Error patterns are consistent",
                "Complete error elimination is possible"
            ],
            "architecture_evolution": [
                "Deeper networks are more powerful",
                "Parameter count correlates with capability",
                "Network architecture should be fixed after training",
                "All capabilities should be in a single model",
                "Specialization improves performance"
            ]
        }

        # Select assumption to challenge
        assumptions = domain_assumptions.get(domain, ["Default assumption"])
        target_assumption = random.choice(assumptions)

        # Generate counterfactual
        counterfactual = f"What if the opposite of '{target_assumption}' were true?"

        # Alternative approach templates
        alternative_templates = [
            f"Instead of assuming that {target_assumption}, consider a {domain} approach where the inverse applies.",
            f"Challenging the assumption that {target_assumption} opens up a new paradigm for {domain}.",
            f"If we invert the conventional wisdom that {target_assumption}, a novel {domain} solution emerges.",
            f"Contrary to the established belief that {target_assumption}, an alternative {domain} framework could operate on the opposite principle."
        ]

        insight_text = random.choice(alternative_templates)

        # Quality - counterfactuals can be very insightful but risky
        expertise_level = self.domains.get(domain, 0.5)
        counterfactual_factor = random.uniform(0.5, 1.5)  # High variance
        quality = min(0.95, expertise_level * counterfactual_factor)

        return insight_text, quality

    def _generative_imagination(self, domain):
        """
        Generate insights through combinatorial creativity.
        Creates novel solutions by combining existing elements in new ways.
        """
        # Core components in different domains
        domain_components = {
            "knowledge_representation": [
                "vector embeddings", "graph structures", "hierarchical models",
                "symbolic representations", "probabilistic encodings"
            ],
            "content_analysis": [
                "semantic parsing", "sentiment analysis", "entity extraction",
                "relevance scoring", "structural analysis"
            ],
            "strategy_generation": [
                "goal decomposition", "resource allocation", "risk assessment",
                "action sequencing", "hypothesis testing"
            ],
            "error_analysis": [
                "pattern recognition", "anomaly detection", "root cause analysis",
                "predictive monitoring", "fault isolation"
            ],
            "architecture_evolution": [
                "attention mechanisms", "residual connections", "activation functions",
                "layer normalization", "parameter sharing"
            ]
        }

        # Select components to combine
        components = domain_components.get(domain, ["component A", "component B"])

        if len(components) < 2:
            components.append("general mechanism")

        # Select 2-3 components to combine
        num_components = random.randint(2, min(3, len(components)))
        selected_components = random.sample(components, num_components)

        # Combination operations
        operations = [
            "integrating", "layering", "alternating between",
            "dynamically switching between", "creating a hybrid of"
        ]
        operation = random.choice(operations)

        # Generate insight
        components_text = ", ".join(selected_components[:-1]) + " and " + selected_components[-1]

        templates = [
            f"A novel {domain} approach: {operation} {components_text} to create an emergent capability.",
            f"By {operation} {components_text}, a more flexible {domain} system could address current limitations.",
            f"The untapped potential in {domain} lies in {operation} {components_text} in an iterative process.",
            f"Creating a unified framework by {operation} {components_text} would transform the {domain} paradigm."
        ]

        insight_text = random.choice(templates)

        # Quality - generative insights reward creativity but have implementation uncertainty
        expertise_level = self.domains.get(domain, 0.5)
        creativity_boost = self.creativity_level * 0.2  # Creativity directly impacts quality
        quality = min(0.95, expertise_level * random.uniform(0.7, 1.2) + creativity_boost)

        return insight_text, quality

    def simulate_error_detection(self):
        """
        Simulate error detection through internal models and predictive processes.
        Identifies potential issues before they manifest as failures.
        """
        # Define potential error types and their detection probabilities
        error_types = {
            "content_quality": 0.15,  # Probability of this error type occurring
            "exploration_strategy": 0.12,
            "memory_overflow": 0.08,
            "reasoning_fallacy": 0.10,
            "attention_misallocation": 0.13,
            "resource_exhaustion": 0.07,
            "feedback_loop": 0.09,
            "model_misalignment": 0.11,
            "data_corruption": 0.05,
            "convergence_failure": 0.10
        }

        # Roll for error detection
        detection_threshold = 0.25  # Base threshold for detecting any error

        # Check if any error is detected
        if random.random() < detection_threshold:
            # Select error type based on probabilities
            error_type = random.choices(
                list(error_types.keys()),
                weights=list(error_types.values()),
                k=1
            )[0]

            # Generate severity score
            severity = random.uniform(0.3, 0.9)

            # Generate specificity - how precisely the error is located
            specificity = random.uniform(0.4, 0.95)

            # Create detailed error information
            error_details = {
                "type": error_type,
                "severity": severity,
                "specificity": specificity,
                "timestamp": datetime.now().isoformat(),
                "predicted_impact": "high" if severity > 0.7 else "medium" if severity > 0.4 else "low"
            }

            # Add error-specific details
            if error_type == "content_quality":
                error_details["details"] = "Predicted degradation in content filtering effectiveness"
                error_details["affected_system"] = "ContentSifter"
            elif error_type == "exploration_strategy":
                error_details["details"] = "Detected suboptimal domain exploration pattern"
                error_details["affected_system"] = "SuperQuantumFreeWill"
            elif error_type == "memory_overflow":
                error_details["details"] = "Projected memory saturation with low-quality content"
                error_details["affected_system"] = "SemanticMemoryModule"
            elif error_type == "reasoning_fallacy":
                error_details["details"] = "Identified circular reasoning in goal setting"
                error_details["affected_system"] = "TemporalPlanner"
            elif error_type == "attention_misallocation":
                error_details["details"] = "Resources directed to low-value information processing"
                error_details["affected_system"] = "QuantumAttentionLayer"
            elif error_type == "resource_exhaustion":
                error_details["details"] = "Processing demand exceeding available computational resources"
                error_details["affected_system"] = "System-wide"
            elif error_type == "feedback_loop":
                error_details["details"] = "Self-reinforcing decision pattern detected"
                error_details["affected_system"] = "AIManager"
            elif error_type == "model_misalignment":
                error_details["details"] = "Model predictions diverging from intended behaviors"
                error_details["affected_system"] = "QuantumNexusModel"
            elif error_type == "data_corruption":
                error_details["details"] = "Inaccuracies in stored information affecting reasoning"
                error_details["affected_system"] = "MemorySystem"
            elif error_type == "convergence_failure":
                error_details["details"] = "Learning process failing to reach stable optimization"
                error_details["affected_system"] = "AdaptiveLearningSystem"

            # Log the detection if it's severe
            if severity > 0.7:
                log_event(f"ImaginationEngine: Detected potential {error_type} error (severity: {severity:.2f})", "WARNING")

            return error_details

        # No error detected
        return None

    def simulate_error_correction(self, error_details):
        """
        Simulate error correction strategies based on detected issues.
        """
        if not error_details or not isinstance(error_details, dict):
            return {"success": False, "reason": "Invalid error details"}

        error_type = error_details.get("type", "unknown")
        severity = error_details.get("severity", 0.5)
        specificity = error_details.get("specificity", 0.5)

        # Correction success probability based on error properties
        # Higher specificity and lower severity make correction more likely
        base_success_prob = 0.7
        success_prob = base_success_prob * (0.5 + specificity/2) * (1.3 - severity/2)

        # Roll for correction success
        correction_successful = random.random() < success_prob

        # Generate correction strategies
        strategies = []

        if error_type == "content_quality":
            strategies = [
                "Recalibrate content quality thresholds",
                "Implement additional filtering layers",
                "Increase weight of domain authority in evaluation"
            ]
        elif error_type == "exploration_strategy":
            strategies = [
                "Adjust exploration/exploitation balance",
                "Implement temporary randomness increase",
                "Refocus on high-information domains"
            ]
        elif error_type == "memory_overflow":
            strategies = [
                "Increase pruning of low-importance memories",
                "Implement more aggressive compression",
                "Adjust importance calculation parameters"
            ]
        elif error_type == "reasoning_fallacy":
            strategies = [
                "Apply metacognitive verification steps",
                "Introduce counterfactual checking",
                "Implement logical consistency validation"
            ]
        elif error_type == "attention_misallocation":
            strategies = [
                "Recalibrate attention mechanism weights",
                "Implement attention budget constraints",
                "Add periodic attention reset mechanism"
            ]
        # Add strategies for other error types
        else:
            strategies = [
                "Apply general error correction procedure",
                "Reset affected subsystem parameters",
                "Implement targeted diagnostic sequence"
            ]

        # Select correction strategy
        selected_strategy = random.choice(strategies)

        # Create correction result
        correction_result = {
            "error_type": error_type,
            "strategy_applied": selected_strategy,
            "success": correction_successful,
            "effectiveness": random.uniform(0.4, 0.9) if correction_successful else random.uniform(0.1, 0.4),
            "timestamp": datetime.now().isoformat()
        }

        # Log the correction attempt
        log_level = "INFO" if correction_successful else "WARNING"
        log_event(f"ImaginationEngine: Error correction for {error_type} - Strategy: {selected_strategy} - Success: {correction_successful}", log_level)

        return correction_result

    def simulate_quantum_cognition(self):
        """
        Simulate quantum-like cognitive processes including superposition
        of concepts, interference effects, and non-classical inference.
        """
        # Probability of quantum phenomenon
        quantum_probability = 0.15

        if random.random() > quantum_probability:
            return None  # No quantum phenomenon this time

        # Different quantum cognitive phenomena
        quantum_phenomena = [
            "superposition",  # Multiple conceptual states simultaneously
            "interference",   # Concepts influencing each other non-classically
            "entanglement",   # Correlated concept states
            "contextuality",  # Meaning dependent on measurement context
            "wave_collapse"   # Conceptual state resolution
        ]

        # Select phenomenon
        phenomenon = random.choice(quantum_phenomena)

        # Define potential anomalies and insights
        anomalies = []
        insights = []

        if phenomenon == "superposition":
            anomalies = [
                "Multiple incompatible goal states activated simultaneously",
                "Strategy selection maintaining all possibilities until execution",
                "Knowledge representation existing in multiple contradiction states"
            ]
            insights = [
                "Leveraging conceptual superposition enables parallel strategy evaluation",
                "Maintaining goal superposition increases adaptive flexibility",
                "Quantum superposition of knowledge allows richer hypothesis space"
            ]
        elif phenomenon == "interference":
            anomalies = [
                "Goal pathways showing constructive/destructive interference",
                "Strategy combinations producing unexpected enhancement",
                "Knowledge patterns exhibiting non-linear interference effects"
            ]
            insights = [
                "Constructive interference between strategies amplifies effectiveness",
                "Cognitive interference patterns reveal hidden knowledge connections",
                "Strategic interference effects create emergent capabilities"
            ]
        elif phenomenon == "entanglement":
            anomalies = [
                "Distant knowledge domains showing unexplainable correlations",
                "Strategy outcomes entangled across execution contexts",
                "Goal achievement states exhibiting non-local influences"
            ]
            insights = [
                "Entangled knowledge representations enable cross-domain transfer",
                "Strategic entanglement allows coordinated multi-system adaptation",
                "Quantum entanglement of goals creates self-reinforcing alignment"
            ]
        elif phenomenon == "contextuality":
            anomalies = [
                "Knowledge valuation showing strong contextual dependencies",
                "Strategy effectiveness violating classical probability bounds",
                "Cognitive state measurements exhibiting contextual anomalies"
            ]
            insights = [
                "Contextual knowledge representation improves semantic accuracy",
                "Quantum contextuality enables more nuanced decision strategies",
                "Context-dependent cognition enhances adaptive intelligence"
            ]
        elif phenomenon == "wave_collapse":
            anomalies = [
                "Decision process showing measurement-induced state changes",
                "Conceptual ambiguity resolving only upon observation",
                "Strategy selection collapsing possibility space irreversibly"
            ]
            insights = [
                "Strategic wave collapse allows commitment of cognitive resources",
                "Measurement-induced knowledge resolution enhances precision",
                "Controlled wave collapse enables decisive action from ambiguity"
            ]

        # Select specific anomaly and insight
        anomaly = random.choice(anomalies)
        insight = random.choice(insights)

        # Determine if this is a significant anomaly
        is_significant = random.random() < 0.3

        # Create quantum cognition result
        result = {
            "phenomenon": phenomenon,
            "anomaly_detected": is_significant,
            "anomaly": anomaly if is_significant else None,
            "insight": insight,
            "timestamp": datetime.now().isoformat()
        }

        # Log the quantum cognition event
        log_level = "QUANTUM" if is_significant else "INFO"
        log_message = f"Quantum Cognition: {phenomenon.title()} - {'Anomaly: ' + anomaly if is_significant else 'Insight: ' + insight}"
        log_event(log_message, log_level)

        return result

    def get_imagination_report(self):
        """
        Generate a comprehensive report on imagination engine activity.
        """
        if not self.insight_history:
            return {"status": "inactive", "insights_generated": 0}

        # Calculate insight statistics
        insight_count = len(self.insight_history)
        avg_quality = sum(i["quality"] for i in self.insight_history) / insight_count

        # Count by domain and mode
        domain_counts = {}
        mode_counts = {}

        for insight in self.insight_history:
            domain = insight.get("domain", "unknown")
            mode = insight.get("mode", "unknown")

            domain_counts[domain] = domain_counts.get(domain, 0) + 1
            mode_counts[mode] = mode_counts.get(mode, 0) + 1

        # Get top insights
        top_insights = sorted(self.insight_history, key=lambda x: x.get("quality", 0), reverse=True)[:3]
        top_texts = [i["text"] for i in top_insights]

        # Compute mode effectiveness
        mode_quality = {}
        for mode in self.cognitive_modes:
            mode_insights = [i for i in self.insight_history if i.get("mode") == mode]
            if mode_insights:
                mode_quality[mode] = sum(i["quality"] for i in mode_insights) / len(mode_insights)

        # Identify most effective mode
        most_effective = max(mode_quality.items(), key=lambda x: x[1])[0] if mode_quality else None

        return {
            "status": "active",
            "insights_generated": insight_count,
            "average_quality": avg_quality,
            "domain_distribution": domain_counts,
            "mode_distribution": mode_counts,
            "most_effective_mode": most_effective,
            "top_insights": top_texts,
            "creativity_level": self.creativity_level,
            "imagination_health": "high" if avg_quality > 0.7 else "medium" if avg_quality > 0.5 else "low"
        }




class DomainIntelligence:
    """
    Advanced domain analysis system for understanding website characteristics,
    content patterns, and authority metrics to guide exploration.
    """
    def __init__(self):
        self.domain_knowledge = {}  # Main knowledge store for domains
        self.domain_categories = {}  # Categorization of domains
        self.authority_metrics = {}  # Authority scores and metrics
        self.topic_expertise = {}    # Domain topic area expertise
        self.relation_graph = {}     # Graph of domain relationships
        self.access_patterns = {}    # Patterns of domain access and results
        self.update_timestamps = {}  # When domains were last analyzed
        self.anomaly_records = {}    # Record of domain anomalies

        # Reference categorization data
        self.category_keywords = {
            "academic": ["university", "research", "edu", "academic", "science", "study", "journal"],
            "technology": ["tech", "programming", "software", "hardware", "computer", "code", "developer"],
            "news": ["news", "article", "report", "journalism", "media", "current", "daily"],
            "reference": ["wiki", "reference", "encyclopedia", "knowledge", "dictionary", "information"],
            "social": ["social", "community", "forum", "discussion", "comment", "people", "network"],
            "commercial": ["shop", "product", "buy", "price", "store", "commerce", "retail", "purchase"],
            "government": ["gov", "government", "official", "public", "administration", "agency", "state"],
            "entertainment": ["entertainment", "game", "music", "video", "movie", "play", "fun"]
        }

        # Authority signals
        self.authority_signals = [
            "domain_age", "citation_count", "https_enabled",
            "content_quality", "update_frequency", "outbound_links",
            "referral_pattern", "content_depth"
        ]

        log_event("DomainIntelligence initialized", "INFO")

    def analyze_domain(self, domain_url):
        """
        Perform comprehensive analysis of a domain to understand its
        characteristics, trustworthiness, and specialization.
        """
        if not domain_url:
            return False

        # Parse URL to extract domain
        try:
            parsed_url = urlparse(domain_url)
            domain = parsed_url.netloc

            # Skip if empty domain
            if not domain:
                return False

            # Record analysis time
            current_time = datetime.now().isoformat()
            self.update_timestamps[domain] = current_time

            # Extract domain components
            domain_parts = domain.split('.')
            tld = domain_parts[-1] if len(domain_parts) > 0 else ""
            sld = domain_parts[-2] if len(domain_parts) > 1 else ""

            # Initial domain type inference from TLD
            domain_type = "unknown"
            if tld == "edu":
                domain_type = "academic"
            elif tld == "gov":
                domain_type = "government"
            elif tld == "org":
                domain_type = "organization"
            elif tld == "com":
                domain_type = "commercial"

            # Analyze domain name for category clues
            domain_name_lower = domain.lower()
            category_scores = {}

            for category, keywords in self.category_keywords.items():
                # Calculate score based on keyword presence
                score = sum(1 for keyword in keywords if keyword in domain_name_lower)
                if score > 0:
                    category_scores[category] = score

            # Determine primary category if scores exist
            primary_category = None
            if category_scores:
                primary_category = max(category_scores.items(), key=lambda x: x[1])[0]

            # Create or update domain record
            if domain not in self.domain_knowledge:
                # New domain record
                self.domain_knowledge[domain] = {
                    "domain": domain,
                    "tld": tld,
                    "domain_type": domain_type,
                    "primary_category": primary_category,
                    "category_scores": category_scores,
                    "first_analyzed": current_time,
                    "last_updated": current_time,
                    "visit_count": 1,
                    "pages_analyzed": 0,
                    "authority_score": 0.5,  # Initial neutral score
                    "content_quality": None,
                    "https_enabled": parsed_url.scheme == "https",
                    "known_topics": [],
                    "page_pattern": {}
                }

                # Add to category index
                if primary_category:
                    if primary_category not in self.domain_categories:
                        self.domain_categories[primary_category] = set()
                    self.domain_categories[primary_category].add(domain)

                log_event(f"Added new domain to intelligence database: {domain} ({domain_type}, {primary_category})", "INFO")
            else:
                # Update existing record
                self.domain_knowledge[domain]["last_updated"] = current_time
                self.domain_knowledge[domain]["visit_count"] += 1

                # Update category if confidence has improved
                existing_category = self.domain_knowledge[domain]["primary_category"]
                if primary_category and (not existing_category or
                                       category_scores.get(primary_category, 0) >
                                       self.domain_knowledge[domain]["category_scores"].get(existing_category, 0)):

                    # Remove from old category index
                    if existing_category and existing_category in self.domain_categories:
                        self.domain_categories[existing_category].discard(domain)

                    # Add to new category index
                    if primary_category not in self.domain_categories:
                        self.domain_categories[primary_category] = set()
                    self.domain_categories[primary_category].add(domain)

                    # Update domain record
                    self.domain_knowledge[domain]["primary_category"] = primary_category
                    self.domain_knowledge[domain]["category_scores"] = category_scores

                    log_event(f"Updated domain categorization: {domain} recategorized as {primary_category}", "INFO")

            # Calculate authority score (simplified version)
            self._calculate_authority_score(domain)

            return True

        except Exception as e:
            log_event(f"Error analyzing domain {domain_url}: {e}", "ERROR")
            return False

    def _calculate_authority_score(self, domain):
        """Calculate domain authority score based on multiple signals"""
        if domain not in self.domain_knowledge:
            return 0.5  # Default neutral score

        # Collect available signals
        signals = {}
        domain_data = self.domain_knowledge[domain]

        # Signal: Domain Type factor
        domain_type_factors = {
            "academic": 0.8,
            "government": 0.8,
            "organization": 0.7,
            "news": 0.6,
            "reference": 0.7,
            "commercial": 0.5,
            "unknown": 0.5
        }

        signals["domain_type"] = domain_type_factors.get(domain_data.get("domain_type", "unknown"), 0.5)

        # Signal: HTTPS enabled
        signals["https_enabled"] = 0.7 if domain_data.get("https_enabled", False) else 0.3

        # Signal: Visit success rate
        visit_count = domain_data.get("visit_count", 0)
        pages_analyzed = domain_data.get("pages_analyzed", 0)
        signals["success_rate"] = min(0.9, pages_analyzed / max(1, visit_count))

        # Signal: TLD trustworthiness
        tld_trust = {
            "edu": 0.9,
            "gov": 0.9,
            "org": 0.7,
            "com": 0.5,
            "net": 0.5,
            "io": 0.6,
            "ai": 0.6
        }
        signals["tld_trust"] = tld_trust.get(domain_data.get("tld", ""), 0.4)

        # Signal: Content quality if available
        if domain_data.get("content_quality") is not None:
            signals["content_quality"] = domain_data["content_quality"]

        # Signal: Topic expertise if established
        if domain in self.topic_expertise and self.topic_expertise[domain]:
            # Average expertise across topics
            signals["topic_expertise"] = sum(self.topic_expertise[domain].values()) / len(self.topic_expertise[domain])

        # Calculate overall authority score
        # Weighted average of available signals
        weights = {
            "domain_type": 0.15,
            "https_enabled": 0.05,
            "success_rate": 0.20,
            "tld_trust": 0.10,
            "content_quality": 0.30,
            "topic_expertise": 0.20
        }

        total_weight = 0
        weighted_sum = 0

        for signal, value in signals.items():
            if signal in weights:
                weighted_sum += value * weights[signal]
                total_weight += weights[signal]

        # Compute final score with normalization
        if total_weight > 0:
            authority_score = weighted_sum / total_weight
        else:
            authority_score = 0.5  # Default if no signals available

        # Store authority score
        self.domain_knowledge[domain]["authority_score"] = authority_score
        self.authority_metrics[domain] = {
            "score": authority_score,
            "signals": signals,
            "timestamp": datetime.now().isoformat()
        }

        return authority_score

    def update_content_knowledge(self, domain, page_url, content_data):
        """
        Update domain knowledge with information from analyzed content.

        Parameters:
        - domain: Domain name
        - page_url: Full URL of the analyzed page
        - content_data: Dict with keys like 'quality', 'topics', 'length', etc.
        """
        if not domain or not page_url or not content_data:
            return False

        # Ensure domain exists in knowledge base
        if domain not in self.domain_knowledge:
            self.analyze_domain(page_url)

        if domain not in self.domain_knowledge:
            return False  # Domain analysis failed

        # Update page count
        self.domain_knowledge[domain]["pages_analyzed"] = self.domain_knowledge[domain].get("pages_analyzed", 0) + 1

        # Store page pattern
        path = urlparse(page_url).path
        page_pattern = self.domain_knowledge[domain].get("page_pattern", {})

        # Analyze path pattern
        path_parts = path.strip('/').split('/')

        # Identify path type
        path_type = "root"
        if len(path_parts) == 1 and path_parts[0]:
            path_type = "top_level"
        elif len(path_parts) > 1:
            path_type = "deep"

        # Update path type counts
        if "path_types" not in page_pattern:
            page_pattern["path_types"] = {"root": 0, "top_level": 0, "deep": 0}

        page_pattern["path_types"][path_type] = page_pattern["path_types"].get(path_type, 0) + 1

        # Update path component statistics
        if "common_segments" not in page_pattern:
            page_pattern["common_segments"] = {}

        for part in path_parts:
            if part:  # Skip empty parts
                page_pattern["common_segments"][part] = page_pattern["common_segments"].get(part, 0) + 1

        # Store updated page pattern
        self.domain_knowledge[domain]["page_pattern"] = page_pattern

        # Update content quality metrics
        if "quality" in content_data:
            quality_score = content_data["quality"]

            # Update rolling average of content quality
            current_quality = self.domain_knowledge[domain].get("content_quality")
            if current_quality is None:
                self.domain_knowledge[domain]["content_quality"] = quality_score
            else:
                # Weight existing score more to avoid large fluctuations
                self.domain_knowledge[domain]["content_quality"] = current_quality * 0.8 + quality_score * 0.2

        # Update topic knowledge
        if "topics" in content_data and content_data["topics"]:
            topics = content_data["topics"]

            # Update known topics for domain
            known_topics = set(self.domain_knowledge[domain].get("known_topics", []))
            known_topics.update(topics)
            self.domain_knowledge[domain]["known_topics"] = list(known_topics)

            # Update topic expertise
            if domain not in self.topic_expertise:
                self.topic_expertise[domain] = {}

            for topic in topics:
                # Increase expertise in this topic
                current_expertise = self.topic_expertise[domain].get(topic, 0.3)  # Start with low expertise
                # Expertise increases with each encounter but plateaus
                self.topic_expertise[domain][topic] = min(0.9, current_expertise + 0.05)

        # Recalculate authority score with new information
        self._calculate_authority_score(domain)

        return True

    def find_related_domains(self, domain, relation_type="topic", max_results=5):
        """
        Find domains related to the given domain by topic or other criteria.

        Parameters:
        - domain: Domain to find relations for
        - relation_type: Type of relation ('topic', 'category', 'link')
        - max_results: Maximum number of results to return
        """
        if not domain or domain not in self.domain_knowledge:
            return []

        related_domains = []

        if relation_type == "topic":
            # Find domains with overlapping topics
            domain_topics = set(self.domain_knowledge[domain].get("known_topics", []))

            if not domain_topics:
                return []  # No topics to match

            # Score domains by topic overlap
            domain_scores = {}

            for d, data in self.domain_knowledge.items():
                if d == domain:
                    continue  # Skip self

                d_topics = set(data.get("known_topics", []))
                if not d_topics:
                    continue  # Skip domains with no topics

                # Calculate Jaccard similarity of topic sets
                overlap = len(domain_topics.intersection(d_topics))
                union = len(domain_topics.union(d_topics))

                if overlap > 0:
                    similarity = overlap / union
                    domain_scores[d] = similarity

            # Sort by similarity score
            sorted_domains = sorted(domain_scores.items(), key=lambda x: x[1], reverse=True)
            related_domains = [(d, score) for d, score in sorted_domains[:max_results]]

        elif relation_type == "category":
            # Find domains in the same category
            category = self.domain_knowledge[domain].get("primary_category")

            if not category or category not in self.domain_categories:
                return []

            # Get domains in same category
            category_domains = [d for d in self.domain_categories[category] if d != domain]

            # Sort by authority score
            domain_scores = []
            for d in category_domains:
                if d in self.domain_knowledge:
                    score = self.domain_knowledge[d].get("authority_score", 0.5)
                    domain_scores.append((d, score))

            # Sort by authority score
            sorted_domains = sorted(domain_scores, key=lambda x: x[1], reverse=True)
            related_domains = sorted_domains[:max_results]

        elif relation_type == "link":
            # Find domains that share links (requires backlink tracking)
            # This would be implemented with the relation graph
            if domain in self.relation_graph and "links_to" in self.relation_graph[domain]:
                links = self.relation_graph[domain]["links_to"]
                related_domains = [(d, 1.0) for d in links][:max_results]

        return related_domains

    def get_domain_knowledge(self, domain):
        """
        Retrieve comprehensive knowledge about a domain.

        Parameters:
        - domain: Domain name to retrieve knowledge for
        """
        # Handle both domain name and full URL
        if not domain:
            return None

        # Check if this is a URL and extract domain
        if domain.startswith(('http://', 'https://')):
            domain = urlparse(domain).netloc

        if not domain:
            return None

        # Return domain knowledge if exists
        if domain in self.domain_knowledge:
            # Create a copy to avoid direct modification
            knowledge = self.domain_knowledge[domain].copy()

            # Add additional related information
            knowledge["authority_metrics"] = self.authority_metrics.get(domain, {})
            knowledge["topic_expertise"] = self.topic_expertise.get(domain, {})

            # Add anomaly records if they exist
            if domain in self.anomaly_records:
                knowledge["anomalies"] = self.anomaly_records[domain]

            # Add related domains
            related_by_topic = self.find_related_domains(domain, "topic", 3)
            if related_by_topic:
                knowledge["related_domains"] = [d for d, _ in related_by_topic]

            return knowledge

        return None

    def detect_domain_anomalies(self, domain):
        """
        Analyze domain for potential anomalies or suspicious patterns.

        Parameters:
        - domain: Domain to check for anomalies
        """
        if not domain or domain not in self.domain_knowledge:
            return []

        anomalies = []
        domain_data = self.domain_knowledge[domain]

        # Anomaly 1: TLD mismatch with content
        tld = domain_data.get("tld", "")
        category = domain_data.get("primary_category")

        if tld == "edu" and category and category not in ["academic", "reference"]:
            anomalies.append({
                "type": "tld_category_mismatch",
                "description": f"Domain has .edu TLD but content suggests '{category}' category",
                "severity": "medium"
            })

        # Anomaly 2: Low content quality on authoritative TLD
        content_quality = domain_data.get("content_quality")
        if content_quality and content_quality < 0.4 and tld in ["edu", "gov", "org"]:
            anomalies.append({
                "type": "low_quality_authoritative",
                "description": f"Domain with .{tld} TLD has unusually low content quality ({content_quality:.2f})",
                "severity": "high"
            })

        # Anomaly 3: Unusual page pattern
        page_pattern = domain_data.get("page_pattern", {})
        path_types = page_pattern.get("path_types", {})

        if path_types.get("deep", 0) > 10 * max(1, path_types.get("top_level", 0) + path_types.get("root", 0)):
            anomalies.append({
                "type": "unusual_path_pattern",
                "description": "Domain shows unusually high ratio of deep paths to top-level content",
                "severity": "low"
            })

        # Anomaly 4: Visit count vs pages analyzed mismatch
        visit_count = domain_data.get("visit_count", 0)
        pages_analyzed = domain_data.get("pages_analyzed", 0)

        if visit_count > 5 and pages_analyzed / visit_count < 0.3:
            anomalies.append({
                "type": "low_analysis_success_rate",
                "description": f"Domain has low success rate: {pages_analyzed}/{visit_count} visits produced content",
                "severity": "medium"
            })

        # Store anomalies if found
        if anomalies:
            self.anomaly_records[domain] = {
                "detected": anomalies,
                "timestamp": datetime.now().isoformat()
            }

            # Log high severity anomalies
            high_severity = [a for a in anomalies if a.get("severity") == "high"]
            if high_severity:
                for anomaly in high_severity:
                    log_event(f"Domain anomaly detected for {domain}: {anomaly['description']}", "WARNING")

        return anomalies

    def get_domain_recommendation(self, current_domain, purpose="exploration"):
        """
        Recommend related domains based on current domain and purpose.

        Parameters:
        - current_domain: The current domain
        - purpose: Why we need recommendations ('exploration', 'deepening', 'verification')
        """
        if not current_domain:
            # Recommend highly trusted domains by default
            trusted_domains = self._get_top_domains_by_authority(5)
            if trusted_domains:
                return {
                    "recommendations": trusted_domains,
                    "reason": "Default trusted domains for general exploration"
                }
            return None

        # Extract domain from URL if needed
        if current_domain.startswith(('http://', 'https://')):
            current_domain = urlparse(current_domain).netloc

        # Check domain knowledge
        if current_domain not in self.domain_knowledge:
            return None

        domain_data = self.domain_knowledge[current_domain]

        # Different recommendation strategies based on purpose
        if purpose == "exploration":
            # Favor topic-related domains with high authority
            related = self.find_related_domains(current_domain, "topic", 10)

            # Filter for good authority
            good_related = [(domain, score) for domain, score in related
                          if domain in self.domain_knowledge
                          and self.domain_knowledge[domain].get("authority_score", 0) > 0.6]

            if good_related:
                return {
                    "recommendations": [domain for domain, _ in good_related[:5]],
                    "reason": f"Topic-related domains to {current_domain} with good authority"
                }

        elif purpose == "deepening":
            # Focus on same category with highest topic expertise
            category = domain_data.get("primary_category")
            if category and category in self.domain_categories:
                # Get domains in same category
                category_domains = [d for d in self.domain_categories[category] if d != current_domain]

                # Score by topic expertise and authority
                domain_scores = []

                for d in category_domains:
                    if d in self.domain_knowledge and d in self.topic_expertise:
                        # Average topic expertise
                        topics = self.topic_expertise[d]
                        if topics:
                            avg_expertise = sum(topics.values()) / len(topics)
                            authority = self.domain_knowledge[d].get("authority_score", 0.5)

                            # Combined score weighing expertise more
                            score = avg_expertise * 0.7 + authority * 0.3
                            domain_scores.append((d, score))

                if domain_scores:
                    sorted_domains = sorted(domain_scores, key=lambda x: x[1], reverse=True)
                    return {
                        "recommendations": [domain for domain, _ in sorted_domains[:5]],
                        "reason": f"Domains with deep expertise in {category} category"
                    }

        elif purpose == "verification":
            # Find authoritative domains in same topic area
            topics = domain_data.get("known_topics", [])
            if not topics:
                return None

            # Find domains with same topics but higher authority
            current_authority = domain_data.get("authority_score", 0.5)
            verification_candidates = []

            for d, data in self.domain_knowledge.items():
                if d == current_domain:
                    continue

                # Check topic overlap
                d_topics = set(data.get("known_topics", []))
                overlap = len(set(topics).intersection(d_topics))

                if overlap > 0 and data.get("authority_score", 0) > current_authority:
                    # Score by authority and topic overlap
                    score = data.get("authority_score", 0) * (overlap / len(topics))
                    verification_candidates.append((d, score))

            if verification_candidates:
                sorted_candidates = sorted(verification_candidates, key=lambda x: x[1], reverse=True)
                return {
                    "recommendations": [domain for domain, _ in sorted_candidates[:5]],
                    "reason": f"More authoritative sources on same topics as {current_domain}"
                }

        # Default to highest authority domains as fallback
        return {
            "recommendations": self._get_top_domains_by_authority(5),
            "reason": "General high-authority domains (fallback recommendation)"
        }

    def _get_top_domains_by_authority(self, count=5):
        """Get the top domains by authority score"""
        if not self.domain_knowledge:
            return []

        # Sort domains by authority score
        scored_domains = [(d, data.get("authority_score", 0))
                        for d, data in self.domain_knowledge.items()]
        sorted_domains = sorted(scored_domains, key=lambda x: x[1], reverse=True)

        return [domain for domain, _ in sorted_domains[:count]]

    def export_domain_report(self, domain):
        """
        Generate comprehensive report on domain for external use.

        Parameters:
        - domain: Domain to generate report for
        """
        if not domain or domain not in self.domain_knowledge:
            return None

        knowledge = self.get_domain_knowledge(domain)
        if not knowledge:
            return None

        # Generate anomaly section if needed
        anomalies = self.detect_domain_anomalies(domain)
        anomaly_section = None
        if anomalies:
            anomaly_section = {
                "count": len(anomalies),
                "details": anomalies,
                "recommended_action": "caution" if any(a.get("severity") == "high" for a in anomalies) else "monitor"
            }

        # Get related domains
        topic_related = self.find_related_domains(domain, "topic", 5)
        category_related = self.find_related_domains(domain, "category", 5)

        # Compile report
        report = {
            "domain": domain,
            "analysis_date": datetime.now().isoformat(),
            "summary": {
                "type": knowledge.get("domain_type", "unknown"),
                "category": knowledge.get("primary_category", "unknown"),
                "authority_score": knowledge.get("authority_score", 0),
                "content_quality": knowledge.get("content_quality"),
                "visit_count": knowledge.get("visit_count", 0),
                "pages_analyzed": knowledge.get("pages_analyzed", 0)
            },
            "authority_assessment": {
                "score": knowledge.get("authority_score", 0),
                "factors": knowledge.get("authority_metrics", {}).get("signals", {}),
                "interpretation": self._interpret_authority_score(knowledge.get("authority_score", 0))
            },
            "content_profile": {
                "known_topics": knowledge.get("known_topics", []),
                "path_patterns": knowledge.get("page_pattern", {}).get("path_types", {}),
                "https_enabled": knowledge.get("https_enabled", False)
            },
            "related_domains": {
                "by_topic": [d for d, _ in topic_related],
                "by_category": [d for d, _ in category_related]
            }
        }

        # Add anomalies if detected
        if anomaly_section:
            report["anomalies"] = anomaly_section

        return report

    def _interpret_authority_score(self, score):
        """Provide interpretation of authority score"""
        if score >= 0.8:
            return "Very High Authority - Likely a definitive source in its field"
        elif score >= 0.7:
            return "High Authority - Generally trustworthy and established source"
        elif score >= 0.5:
            return "Moderate Authority - Adequate source but verification recommended"
        elif score >= 0.3:
            return "Low Authority - Approach with caution, verify information"
        else:
            return "Very Low Authority - Not recommended as a primary information source"

    def get_intelligence_statistics(self):
        """Generate statistics about domain intelligence database"""
        if not self.domain_knowledge:
            return {"status": "empty", "domains_analyzed": 0}

        # Basic counts
        domain_count = len(self.domain_knowledge)

        # Category distribution
        category_counts = {}
        for category, domains in self.domain_categories.items():
            category_counts[category] = len(domains)

        # Authority distribution
        authority_ranges = {
            "very_high": 0,  # 0.8-1.0
            "high": 0,       # 0.6-0.8
            "moderate": 0,   # 0.4-0.6
            "low": 0,        # 0.2-0.4
            "very_low": 0    # 0.0-0.2
        }

        for domain, data in self.domain_knowledge.items():
            score = data.get("authority_score", 0.5)

            if score >= 0.8:
                authority_ranges["very_high"] += 1
            elif score >= 0.6:
                authority_ranges["high"] += 1
            elif score >= 0.4:
                authority_ranges["moderate"] += 1
            elif score >= 0.2:
                authority_ranges["low"] += 1
            else:
                authority_ranges["very_low"] += 1

        # TLD distribution
        tld_counts = {}
        for domain, data in self.domain_knowledge.items():
            tld = data.get("tld", "unknown")
            tld_counts[tld] = tld_counts.get(tld, 0) + 1

        # Anomaly statistics
        anomaly_count = sum(1 for domain in self.anomaly_records)
        high_severity_count = sum(
            1 for domain, record in self.anomaly_records.items()
            if any(a.get("severity") == "high" for a in record.get("detected", []))
        )

        return {
            "status": "active",
            "domains_analyzed": domain_count,
            "category_distribution": category_counts,
            "authority_distribution": authority_ranges,
            "tld_distribution": tld_counts,
            "anomalies_detected": anomaly_count,
            "high_severity_anomalies": high_severity_count
        }





class MetaLearningModule:
    """
    Advanced meta-learning system that monitors, analyzes, and optimizes
    the learning process itself, enabling autonomous improvement of the
    model's learning capabilities over time.
    """
    def __init__(self, model):
        self.model = model
        self.learning_history = deque(maxlen=100)  # Track recent learning metrics
        self.hyperparameter_history = []  # Track hyperparameter evolution
        self.architecture_history = []  # Track architecture changes
        self.performance_trends = {}  # Performance over time for different metrics
        self.learning_rate_schedule = []  # History of learning rate adjustments
        self.optimization_state = "exploration"  # Current optimization phase
        self.training_cycles = 0  # Total training cycles performed
        self.gradient_statistics = deque(maxlen=20)  # Recent gradient statistics
        self.weight_evolution = {}  # Track how weights evolve over time
        self.improvement_rates = {}  # Rate of improvement for different metrics

        # Meta-parameters (parameters about parameter learning)
        self.meta_params = {
            "exploration_rate": 0.3,  # How much to explore hyperparameter space
            "stability_threshold": 0.05,  # Threshold for stability detection
            "adaptation_rate": 0.2,  # How quickly to adapt to new information
            "patience": 5,  # Cycles to wait before making significant changes
            "learning_rate_bounds": (1e-6, 1e-2),  # Min/max learning rate
            "trend_window": 10,  # Window size for trend analysis
            "architecture_change_threshold": 0.1  # Threshold for architecture changes
        }

        # Initialize monitoring
        log_event("MetaLearningModule initialized with meta-optimization capabilities", "INFO")

    def track_performance(self, metrics):
        """
        Track and analyze training performance metrics over time
        to inform meta-learning decisions.

        Parameters:
        - metrics: Dict containing performance metrics (loss, accuracy, etc.)
        """
        self.training_cycles += 1

        # Skip invalid metrics
        if not isinstance(metrics, dict) or len(metrics) == 0:
            return

        # Store metrics with timestamp
        timestamped_metrics = metrics.copy()
        timestamped_metrics["cycle"] = self.training_cycles
        timestamped_metrics["timestamp"] = datetime.now().isoformat()

        # Add current learning rate if available
        if hasattr(self.model, '_current_lr'):
            timestamped_metrics["learning_rate"] = getattr(self.model, '_current_lr')
        elif hasattr(self.model, 'optimizer') and hasattr(self.model.optimizer, 'param_groups'):
            # Try to get from optimizer
            try:
                timestamped_metrics["learning_rate"] = self.model.optimizer.param_groups[0]['lr']
            except (IndexError, KeyError):
                pass

        # Store in history
        self.learning_history.append(timestamped_metrics)

        # Update performance trends when we have enough data
        if len(self.learning_history) >= self.meta_params["trend_window"]:
            self._update_performance_trends()

        # Analyze learning periodically
        if self.training_cycles % max(1, self.meta_params["patience"]) == 0:
            self.analyze_trends()

    def _update_performance_trends(self):
        """Update trend analysis for each tracked metric"""
        window = self.meta_params["trend_window"]
        recent_metrics = list(self.learning_history)[-window:]

        # Find consistent metrics across all entries
        metric_keys = set.intersection(*[set(m.keys()) for m in recent_metrics])
        metric_keys = [k for k in metric_keys if k not in ["cycle", "timestamp", "learning_rate"]]

        for key in metric_keys:
            # Extract values
            values = [m[key] for m in recent_metrics if key in m]

            if not values or len(values) < window:
                continue

            # Calculate trend statistics
            mean_value = sum(values) / len(values)
            min_value = min(values)
            max_value = max(values)
            range_value = max_value - min_value

            # Calculate first derivative (rate of change)
            derivatives = [values[i] - values[i-1] for i in range(1, len(values))]
            mean_derivative = sum(derivatives) / len(derivatives) if derivatives else 0

            # Calculate second derivative (acceleration of change)
            accelerations = [derivatives[i] - derivatives[i-1] for i in range(1, len(derivatives))]
            mean_acceleration = sum(accelerations) / len(accelerations) if accelerations else 0

            # Interpret trend direction
            if abs(mean_derivative) < self.meta_params["stability_threshold"]:
                direction = "stable"
            elif mean_derivative < 0:
                direction = "decreasing"
            else:
                direction = "increasing"

            # Interpret acceleration
            if abs(mean_acceleration) < self.meta_params["stability_threshold"] / 2:
                acceleration = "steady"
            elif mean_acceleration < 0:
                acceleration = "decelerating"
            else:
                acceleration = "accelerating"

            # Store trend information
            self.performance_trends[key] = {
                "current": values[-1],
                "mean": mean_value,
                "min": min_value,
                "max": max_value,
                "range": range_value,
                "direction": direction,
                "rate_of_change": mean_derivative,
                "acceleration": acceleration,
                "acceleration_value": mean_acceleration,
                "updated_at": datetime.now().isoformat()
            }

            # Calculate improvement rate (relative to starting point)
            if len(values) > 1:
                # For loss, lower is better; for accuracy, higher is better
                is_loss_like = "loss" in key.lower() or "error" in key.lower()

                start_value = values[0]
                end_value = values[-1]

                if is_loss_like:
                    # For loss metrics, improvement is decrease
                    improvement = (start_value - end_value) / max(0.0001, start_value)
                else:
                    # For other metrics, improvement is increase
                    improvement = (end_value - start_value) / max(0.0001, start_value)

                self.improvement_rates[key] = improvement

    def analyze_trends(self):
        """
        Analyze learning trends and make meta-learning decisions
        for hyperparameter and architecture adaptation.
        """
        if len(self.learning_history) < self.meta_params["trend_window"]:
            log_event(f"Insufficient learning history for meta-analysis (need {self.meta_params['trend_window']})", "INFO")
            return

        # Check if we have loss metrics
        loss_metrics = [k for k in self.performance_trends.keys()
                       if "loss" in k.lower() or "error" in k.lower()]

        if not loss_metrics:
            log_event("No loss metrics found for meta-learning trend analysis", "WARNING")
            return

        # Use first loss metric as primary indicator
        primary_loss = loss_metrics[0]
        loss_trend = self.performance_trends[primary_loss]

        # Current state assessment
        current_state = {
            "direction": loss_trend["direction"],
            "acceleration": loss_trend["acceleration"],
            "value": loss_trend["current"],
            "improvement_rate": self.improvement_rates.get(primary_loss, 0)
        }

        # Decision making based on loss trend patterns
        decisions = self._make_meta_decisions(current_state, primary_loss)

        # Log significant decisions
        for decision in decisions:
            if decision["type"] in ["learning_rate_change", "architecture_change"]:
                log_event(f"Meta-learning decision: {decision['description']}", "INFO")

        # Apply decisions
        self._apply_meta_decisions(decisions)

    def _make_meta_decisions(self, current_state, primary_metric):
        """
        Make meta-learning decisions based on current learning state.

        Parameters:
        - current_state: Dict describing current trend state
        - primary_metric: Name of the primary metric being analyzed

        Returns:
        - List of decision dictionaries with type and parameters
        """
        decisions = []

        # Case 1: Learning plateaued (stable with low improvement)
        if (current_state["direction"] == "stable" and
            abs(current_state["improvement_rate"]) < self.meta_params["stability_threshold"]):

            # Check duration of plateau
            plateau_duration = self._count_consecutive_states("stable", primary_metric)

            if plateau_duration >= self.meta_params["patience"]:
                # Long plateau - need significant change
                if self.optimization_state == "exploration":
                    # In exploration phase, try architecture change
                    decisions.append({
                        "type": "architecture_change",
                        "change": "expand" if random.random() < 0.7 else "contract",
                        "description": f"Architecture change due to {plateau_duration}-cycle plateau in {primary_metric}"
                    })

                    # Also try learning rate restart
                    decisions.append({
                        "type": "learning_rate_change",
                        "factor": 10.0,
                        "description": "Learning rate increase to escape plateau"
                    })
                else:
                    # In refinement phase, smaller learning rate adjustment
                    decisions.append({
                        "type": "learning_rate_change",
                        "factor": random.uniform(2.0, 5.0),
                        "description": "Learning rate adjustment to overcome plateau"
                    })

                # Switch optimization state
                decisions.append({
                    "type": "optimization_state_change",
                    "new_state": "refinement" if self.optimization_state == "exploration" else "exploration",
                    "description": f"Switch optimization strategy due to {plateau_duration}-cycle plateau"
                })

        # Case 2: Loss increasing (getting worse)
        elif current_state["direction"] == "increasing" and "loss" in primary_metric.lower():
            # Loss is getting worse - need to reduce learning rate

            # Check if it's accelerating or steady
            if current_state["acceleration"] in ["accelerating", "steady"]:
                # Significant reduction needed
                decisions.append({
                    "type": "learning_rate_change",
                    "factor": 0.1,  # 10x reduction
                    "description": f"{primary_metric} {current_state['acceleration']} increase - significant LR reduction"
                })
            else:
                # Moderate reduction for decelerating increase
                decisions.append({
                    "type": "learning_rate_change",
                    "factor": 0.5,  # 2x reduction
                    "description": f"{primary_metric} decelerating increase - moderate LR reduction"
                })

        # Case 3: Loss decreasing nicely (improvement)
        elif current_state["direction"] == "decreasing" and "loss" in primary_metric.lower():
            # Loss is decreasing - check acceleration

            if current_state["acceleration"] == "accelerating":
                # Getting better faster - slightly increase learning rate
                decisions.append({
                    "type": "learning_rate_change",
                    "factor": 1.1,  # 10% increase
                    "description": f"{primary_metric} accelerating decrease - slight LR increase"
                })
            elif current_state["acceleration"] == "decelerating" and random.random() < 0.5:
                # Slowing improvement - try architecture change
                decisions.append({
                    "type": "architecture_change",
                    "change": "expand",
                    "description": f"{primary_metric} decelerating decrease - architecture expansion"
                })

        # Case 4: Random exploration if no clear pattern and in exploration mode
        elif self.optimization_state == "exploration" and random.random() < self.meta_params["exploration_rate"]:
            # Random exploration of hyperparameter space
            exploration_choices = ["learning_rate_change", "architecture_change"]
            exploration_type = random.choice(exploration_choices)

            if exploration_type == "learning_rate_change":
                factor = random.choice([0.5, 0.7, 1.5, 2.0])
                decisions.append({
                    "type": "learning_rate_change",
                    "factor": factor,
                    "description": f"Exploratory learning rate adjustment (factor: {factor})"
                })
            else:
                change = random.choice(["expand", "contract"])
                decisions.append({
                    "type": "architecture_change",
                    "change": change,
                    "description": f"Exploratory architecture {change}"
                })

        return decisions

    def _apply_meta_decisions(self, decisions):
        """
        Apply meta-learning decisions to the model and optimizer.

        Parameters:
        - decisions: List of decision dictionaries
        """
        for decision in decisions:
            decision_type = decision.get("type", "")

            if decision_type == "learning_rate_change":
                factor = decision.get("factor", 1.0)
                self._adjust_learning_rate(factor)

            elif decision_type == "architecture_change":
                change = decision.get("change", "")
                self._adjust_architecture(change)

            elif decision_type == "optimization_state_change":
                new_state = decision.get("new_state", self.optimization_state)
                self.optimization_state = new_state
                log_event(f"Meta-learning optimization state changed to: {new_state}", "INFO")

    def _adjust_learning_rate(self, factor):
        """
        Adjust learning rate by the given factor.

        Parameters:
        - factor: Multiplication factor for current learning rate
        """
        # Get current learning rate
        current_lr = None

        if hasattr(self.model, '_current_lr'):
            current_lr = getattr(self.model, '_current_lr')
        elif hasattr(self.model, 'optimizer') and hasattr(self.model.optimizer, 'param_groups'):
            try:
                current_lr = self.model.optimizer.param_groups[0]['lr']
            except (IndexError, KeyError):
                pass

        if current_lr is None:
            log_event("Could not access current learning rate for adjustment", "ERROR")
            return

        # Calculate new learning rate
        new_lr = current_lr * factor

        # Ensure it's within bounds
        min_lr, max_lr = self.meta_params["learning_rate_bounds"]
        new_lr = max(min_lr, min(max_lr, new_lr))

        # Apply to model attribute
        if hasattr(self.model, '_current_lr'):
            setattr(self.model, '_current_lr', new_lr)

        # Apply to optimizer
        if hasattr(self.model, 'optimizer') and hasattr(self.model.optimizer, 'param_groups'):
            try:
                for param_group in self.model.optimizer.param_groups:
                    param_group['lr'] = new_lr
            except Exception as e:
                log_event(f"Error adjusting optimizer learning rate: {e}", "ERROR")

        # Record the change
        self.learning_rate_schedule.append({
            "cycle": self.training_cycles,
            "old_lr": current_lr,
            "new_lr": new_lr,
            "factor": factor,
            "timestamp": datetime.now().isoformat()
        })

        log_event(f"Meta-learning adjusted learning rate: {current_lr:.6f} â†’ {new_lr:.6f} (factor: {factor})", "INFO")

    def _adjust_architecture(self, change):
        """
        Apply architecture changes based on meta-learning decisions.

        Parameters:
        - change: Type of architecture change ('expand' or 'contract')
        """
        if change not in ["expand", "contract"]:
            log_event(f"Invalid architecture change type: {change}", "ERROR")
            return

        # Check if model supports architecture changes
        expand_method = getattr(self.model, 'expand_architecture', None)
        contract_method = getattr(self.model, 'contract_architecture', None)

        if change == "expand" and callable(expand_method):
            try:
                self.model.expand_architecture()

                # Record the change
                self.architecture_history.append({
                    "cycle": self.training_cycles,
                    "change": "expand",
                    "timestamp": datetime.now().isoformat()
                })

                log_event("Meta-learning expanded model architecture", "QUANTUM")
                return True
            except Exception as e:
                log_event(f"Error expanding architecture: {e}", "ERROR")

        elif change == "contract" and callable(contract_method):
            try:
                self.model.contract_architecture()

                # Record the change
                self.architecture_history.append({
                    "cycle": self.training_cycles,
                    "change": "contract",
                    "timestamp": datetime.now().isoformat()
                })

                log_event("Meta-learning contracted model architecture", "QUANTUM")
                return True
            except Exception as e:
                log_event(f"Error contracting architecture: {e}", "ERROR")
        else:
            log_event(f"Model does not support architecture {change} operations", "WARNING")

        return False

    def _count_consecutive_states(self, state_type, metric):
        """
        Count how many consecutive cycles the metric has been in given state.

        Parameters:
        - state_type: The state to count ('stable', 'increasing', 'decreasing')
        - metric: The metric name to analyze

        Returns:
        - Count of consecutive cycles in that state
        """
        count = 0
        history = list(self.learning_history)

        # Need at least window_size entries to have computed trends
        if len(history) < self.meta_params["trend_window"]:
            return 0

        # Go through trend history (would need to store trend history to be more accurate)
        # This is an approximation based on current trend
        if metric in self.performance_trends:
            if self.performance_trends[metric]["direction"] == state_type:
                # If current state matches, estimate duration based on trend strength
                rate = abs(self.performance_trends[metric]["rate_of_change"])
                threshold = self.meta_params["stability_threshold"]

                if state_type == "stable" and rate < threshold:
                    # Estimate how long we've been stable based on how close to zero the rate is
                    stability_ratio = max(0, 1 - rate/threshold)
                    count = int(self.meta_params["patience"] * stability_ratio) + 1
                else:
                    # For increasing/decreasing, at least 1 cycle
                    count = 1

        return count

    def track_gradient_statistics(self, gradients):
        """
        Track gradient statistics for meta-learning analysis.

        Parameters:
        - gradients: Dict mapping parameter names to gradient tensors
        """
        if not gradients:
            return

        # Calculate gradient statistics
        grad_stats = {}

        try:
            for name, grad in gradients.items():
                if grad is None:
                    continue

                # Convert to numpy for stats calculation if needed
                grad_np = grad.detach().cpu().numpy() if hasattr(grad, 'detach') else grad

                # Calculate statistics
                grad_stats[name] = {
                    "mean": float(np.mean(grad_np)),
                    "std": float(np.std(grad_np)),
                    "min": float(np.min(grad_np)),
                    "max": float(np.max(grad_np)),
                    "norm": float(np.linalg.norm(grad_np))
                }
        except Exception as e:
            log_event(f"Error calculating gradient statistics: {e}", "ERROR")
            return

        # Add overall statistics
        means = [stats["mean"] for stats in grad_stats.values()]
        norms = [stats["norm"] for stats in grad_stats.values()]

        if means and norms:
            grad_stats["overall"] = {
                "mean_of_means": sum(means) / len(means),
                "mean_of_norms": sum(norms) / len(norms),
                "cycle": self.training_cycles
            }

        # Store in history
        self.gradient_statistics.append(grad_stats)

        # Analyze for gradient issues
        self._analyze_gradient_health(grad_stats)

    def _analyze_gradient_health(self, grad_stats):
        """
        Analyze gradient health for issues like vanishing/exploding gradients.

        Parameters:
        - grad_stats: Dictionary of gradient statistics
        """
        if "overall" not in grad_stats:
            return

        overall = grad_stats["overall"]
        mean_norm = overall["mean_of_norms"]

        # Check for vanishing gradients
        if mean_norm < 1e-7:
            log_event(f"Potential vanishing gradient detected: mean norm = {mean_norm:.8f}", "WARNING")

            # Suggest learning rate increase
            if random.random() < 0.7:  # Don't suggest every time
                self._adjust_learning_rate(5.0)  # Significant increase

        # Check for exploding gradients
        elif mean_norm > 1e2:
            log_event(f"Potential exploding gradient detected: mean norm = {mean_norm:.2f}", "WARNING")

            # Suggest learning rate decrease
            if random.random() < 0.7:  # Don't suggest every time
                self._adjust_learning_rate(0.1)  # Significant decrease

    def track_weight_evolution(self, layer_name, weight_tensor):
        """
        Track how weights evolve over time for specific layers.

        Parameters:
        - layer_name: Name of the layer
        - weight_tensor: Tensor containing weights
        """
        if layer_name not in self.weight_evolution:
            self.weight_evolution[layer_name] = []

        try:
            # Calculate statistics from tensor
            weight_np = weight_tensor.detach().cpu().numpy() if hasattr(weight_tensor, 'detach') else weight_tensor

            stats = {
                "mean": float(np.mean(weight_np)),
                "std": float(np.std(weight_np)),
                "norm": float(np.linalg.norm(weight_np)),
                "cycle": self.training_cycles
            }

            # Only store periodically to save memory
            if self.training_cycles % 10 == 0:
                self.weight_evolution[layer_name].append(stats)

                # Limit history size
                max_history = 50
                if len(self.weight_evolution[layer_name]) > max_history:
                    self.weight_evolution[layer_name] = self.weight_evolution[layer_name][-max_history:]

        except Exception as e:
            log_event(f"Error tracking weight evolution for {layer_name}: {e}", "ERROR")

    def get_meta_learning_report(self):
        """
        Generate comprehensive report on meta-learning status and insights.
        """
        if len(self.learning_history) < self.meta_params["trend_window"]:
            return {
                "status": "initializing",
                "cycles": self.training_cycles,
                "message": f"Collecting initial metrics ({len(self.learning_history)}/{self.meta_params['trend_window']} cycles)"
            }

        # Get performance trends
        trends = {}
        for metric, trend in self.performance_trends.items():
            trends[metric] = {
                "current": trend["current"],
                "direction": trend["direction"],
                "acceleration": trend["acceleration"],
                "improvement": self.improvement_rates.get(metric, 0)
            }

        # Get learning rate history
        lr_history = [{
            "cycle": item["cycle"],
            "learning_rate": item["new_lr"]
        } for item in self.learning_rate_schedule[-5:]]  # Last 5 changes

        # Get architecture change history
        arch_history = self.architecture_history[-5:]  # Last 5 changes

        # System state assessment
        state_assessment = self._assess_system_state()

        # Generate recommendations
        recommendations = self._generate_meta_learning_recommendations()

        return {
            "status": "active",
            "cycles": self.training_cycles,
            "optimization_state": self.optimization_state,
            "performance_trends": trends,
            "learning_rate_history": lr_history,
            "architecture_history": arch_history,
            "system_state": state_assessment,
            "recommendations": recommendations
        }

    def _assess_system_state(self):
        """Assess overall system state from meta-learning perspective"""
        # Find primary loss metric
        loss_metrics = [k for k in self.performance_trends.keys()
                      if "loss" in k.lower() or "error" in k.lower()]

        if not loss_metrics:
            return {"state": "unknown", "confidence": 0}

        primary_loss = loss_metrics[0]
        loss_trend = self.performance_trends[primary_loss]

        # Check for issues
        issues = []

        # Issue 1: Plateaued loss
        if loss_trend["direction"] == "stable" and loss_trend["current"] > 0.1:
            issues.append("training_plateau")

        # Issue 2: Loss increasing
        if loss_trend["direction"] == "increasing" and "loss" in primary_loss.lower():
            issues.append("loss_increasing")

        # Issue 3: Slow progress
        if abs(self.improvement_rates.get(primary_loss, 0)) < 0.01:
            issues.append("slow_progress")

        # Issue 4: Gradient issues
        if len(self.gradient_statistics) > 0:
            last_grad = self.gradient_statistics[-1]
            if "overall" in last_grad:
                norm = last_grad["overall"]["mean_of_norms"]
                if norm < 1e-7:
                    issues.append("vanishing_gradients")
                elif norm > 1e2:
                    issues.append("exploding_gradients")

        # Determine overall state
        overall_state = "healthy"
        if len(issues) == 1:
            overall_state = "concerning"
        elif len(issues) > 1:
            overall_state = "problematic"

        # Calculate confidence in assessment
        confidence = min(0.9, 0.5 + 0.1 * len(self.learning_history) / self.meta_params["trend_window"])

        return {
            "state": overall_state,
            "issues": issues,
            "confidence": confidence
        }

    def _generate_meta_learning_recommendations(self):
        """Generate recommendations for system optimization"""
        recommendations = []

        # Get system state
        state = self._assess_system_state()
        issues = state.get("issues", [])

        # Recommendation 1: Learning rate adjustments
        if "training_plateau" in issues:
            if self.optimization_state == "exploration":
                recommendations.append({
                    "type": "learning_rate",
                    "action": "increase",
                    "factor": 5.0,
                    "reason": "Escape plateau by exploring higher learning rates"
                })
            else:
                recommendations.append({
                    "type": "learning_rate",
                    "action": "cyclic_schedule",
                    "reason": "Implement cyclic learning rate to overcome plateau"
                })

        elif "loss_increasing" in issues:
            recommendations.append({
                "type": "learning_rate",
                "action": "decrease",
                "factor": 0.2,
                "reason": "Reduce learning rate to stabilize increasing loss"
            })

        # Recommendation 2: Architecture adjustments
        if "slow_progress" in issues:
            if len(self.architecture_history) < 2:
                recommendations.append({
                    "type": "architecture",
                    "action": "expand",
                    "reason": "Increase model capacity to improve learning progress"
                })
            else:
                last_change = self.architecture_history[-1]["change"]
                recommendations.append({
                    "type": "architecture",
                    "action": "expand" if last_change == "contract" else "contract",
                    "reason": "Alternate architecture changes to find optimal complexity"
                })

        # Recommendation 3: Gradient-based recommendations
        if "vanishing_gradients" in issues:
            recommendations.append({
                "type": "initialization",
                "action": "reinitialize",
                "reason": "Reinitialize weights to address vanishing gradients"
            })
        elif "exploding_gradients" in issues:
            recommendations.append({
                "type": "regularization",
                "action": "increase",
                "reason": "Increase regularization to address exploding gradients"
            })

        # Recommendation 4: Exploration/exploitation balance
        if self.training_cycles > 50 and self.optimization_state == "exploration" and not issues:
            recommendations.append({
                "type": "optimization_state",
                "action": "switch_to_refinement",
                "reason": "Switch to refinement mode after successful exploration phase"
            })
        elif len(issues) > 1 and self.optimization_state == "refinement":
            recommendations.append({
                "type": "optimization_state",
                "action": "switch_to_exploration",
                "reason": "Return to exploration mode to address multiple issues"
            })

        return recommendations

    def adjust_hyperparameters(self, loss_level="normal"):
        """
        Dynamically adjust hyperparameters based on current loss level.

        Parameters:
        - loss_level: Qualitative assessment of current loss ("high", "normal", "low")
        """
        # Get current learning rate
        current_lr = LEARNING_RATE  # Default global value

        # Try to get from model attribute
        if hasattr(self.model, '_current_lr'):
            current_lr = getattr(self.model, '_current_lr')
        elif hasattr(self.model, 'optimizer') and hasattr(self.model.optimizer, 'param_groups'):
            # Try to get from optimizer
            try:
                current_lr = self.model.optimizer.param_groups[0]['lr']
            except (IndexError, KeyError):
                pass

        # Adjust based on loss level
        new_lr = current_lr
        adjustment_factor = 1.0

        if loss_level == "high":
            # High loss - reduce learning rate
            adjustment_factor = 0.9
            new_lr = current_lr * adjustment_factor
        elif loss_level == "low" and self.optimization_state == "exploration":
            # Low loss in exploration mode - try higher learning rate
            adjustment_factor = 1.1
            new_lr = current_lr * adjustment_factor

        # Apply change if significant
        if abs(new_lr - current_lr) / current_lr > 0.01:  # 1% change threshold
            global LEARNING_RATE  # Need to declare global if modifying global variable
            LEARNING_RATE = new_lr
            log_event(f"Meta-learning: Learning rate adjusted from {current_lr:.6f} to {new_lr:.6f}", "INFO")

            # Update model if possible
            if hasattr(self.model, '_current_lr'):
                setattr(self.model, '_current_lr', new_lr)

            # Update optimizer if available
            if hasattr(self.model, 'optimizer') and hasattr(self.model.optimizer, 'param_groups'):
                try:
                    for param_group in self.model.optimizer.param_groups:
                        param_group['lr'] = new_lr
                except Exception as e:
                    log_event(f"Error updating optimizer learning rate: {e}", "ERROR")

            # Record the change
            self.hyperparameter_history.append({
                "parameter": "learning_rate",
                "old_value": current_lr,
                "new_value": new_lr,
                "adjustment_factor": adjustment_factor,
                "cycle": self.training_cycles,
                "timestamp": datetime.now().isoformat()
            })

            return True

        return False





# Record the evolution attempt
        evolution_record = {
            "generation": self.evolution_generation,
            "cycle": cycle_count,
            "strategy": selected_strategy,
            "success": success,
            "message": message,
            "changes": changes,
            "fitness_before": fitness_scores,
            "timestamp": datetime.now().isoformat()
        }

        self.evolution_history.append(evolution_record)

        # Update last evolution time if successful
        if success:
            self.last_major_evolution = cycle_count
            log_event(f"System evolution successful: Generation {self.evolution_generation}, Strategy: {selected_strategy}", "QUANTUM")
        else:
            log_event(f"System evolution attempt failed: {message}", "WARNING")

        return success, message

    def _evaluate_system_fitness(self, agent):
        """
        Evaluate the fitness of the current system across multiple dimensions.

        Parameters:
        - agent: Agent to evaluate

        Returns:
        - Dictionary of fitness scores across dimensions
        """
        fitness_scores = {
            "performance": 0.5,  # Default medium score
            "efficiency": 0.5,
            "adaptability": 0.5,
            "robustness": 0.5,
            "complexity": 0.5
        }

        # 1. Evaluate performance based on learning metrics
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'meta_learning'):
            meta_learning = agent.ai_manager.meta_learning

            # Check for performance trends
            if hasattr(meta_learning, 'performance_trends'):
                perf_trends = meta_learning.performance_trends

                # Look for loss metrics
                for key, trend in perf_trends.items():
                    if 'loss' in key.lower():
                        # Lower loss is better
                        loss_value = trend.get('current', 0.5)
                        # Convert loss to performance score (inverse relationship)
                        # We expect loss in range 0-2, so transform to 0-1 score
                        performance_score = max(0.1, min(0.9, 1.0 - loss_value/2))
                        fitness_scores["performance"] = performance_score
                        break

        # 2. Evaluate efficiency based on resource usage
        # Simple heuristic: larger models are less efficient
        model_size = 0
        if hasattr(agent, 'model') and hasattr(agent.model, 'neocortex'):
            model_size = len(agent.model.neocortex)
            # Normalize size to efficiency score (inverse relationship)
            base_size = 8  # Expected baseline
            # Efficiency decreases as model grows beyond base size
            efficiency_score = max(0.2, min(0.9, base_size / max(base_size, model_size)))
            fitness_scores["efficiency"] = efficiency_score

        # 3. Evaluate adaptability based on learning rate adjustments
        adaptability_score = 0.5  # Default
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'meta_learning'):
            meta_learning = agent.ai_manager.meta_learning

            # More learning rate adjustments suggests higher adaptability
            if hasattr(meta_learning, 'learning_rate_schedule'):
                adjustments = len(meta_learning.learning_rate_schedule)
                # More adjustments = more adaptable, up to a point
                adaptability_score = min(0.9, 0.4 + 0.1 * min(5, adjustments))

        fitness_scores["adaptability"] = adaptability_score

        # 4. Evaluate robustness based on error recovery
        robustness_score = 0.5  # Default
        if hasattr(agent, 'ai_manager'):
            # Check error recovery attempts
            error_recovery = getattr(agent.ai_manager, 'error_recovery_attempts', 0)

            if error_recovery > 0:
                # Lower recovery attempts = more robust
                robustness_score = max(0.1, 0.9 - 0.1 * min(8, error_recovery))
            else:
                # No error recovery needed = highly robust
                robustness_score = 0.8

        fitness_scores["robustness"] = robustness_score

        # 5. Evaluate complexity based on model architecture
        complexity_score = 0.5  # Default
        if hasattr(agent, 'model'):
            # Estimate complexity from model parameters
            total_params = self._estimate_model_parameters(agent.model)

            # Normalize by expected parameter count range
            expected_range = 10000000  # 10M parameters as reference
            normalized_complexity = min(1.0, total_params / expected_range)
            complexity_score = normalized_complexity

        fitness_scores["complexity"] = complexity_score

        # Store the current fitness scores
        self.fitness_metrics[self.evolution_generation] = fitness_scores

        return fitness_scores

    def _estimate_model_parameters(self, model):
        """
        Estimate the number of parameters in the model.

        Parameters:
        - model: PyTorch model

        Returns:
        - Estimated parameter count
        """
        if not model:
            return 0

        try:
            # Try to use PyTorch's parameter counting
            return sum(p.numel() for p in model.parameters())
        except:
            # Fallback to estimation based on architecture
            if hasattr(model, 'neocortex'):
                layers = len(model.neocortex)
                embed_dim = getattr(model, 'embed_dim', 512)

                # Rough estimate based on transformer-like architecture
                # Each layer has attention, feed-forward, etc.
                params_per_layer = embed_dim * embed_dim * 4  # Simplistic estimate
                return layers * params_per_layer
            else:
                return 1000000  # Default fallback

    def _calculate_evolutionary_pressure(self, fitness_scores):
        """
        Calculate the evolutionary pressure based on fitness scores
        and goal weights.

        Parameters:
        - fitness_scores: Current fitness evaluation

        Returns:
        - Pressure score (0.0-1.0) indicating how strongly evolution is needed
        """
        # No evolution pressure if no fitness scores
        if not fitness_scores:
            return 0.0

        # Calculate weighted fitness
        weighted_fitness = 0.0
        total_weight = 0.0

        for metric, weight in self.goal_weights.items():
            if metric in fitness_scores:
                score = fitness_scores[metric]

                # If weight is negative (like for complexity), invert the score
                if weight < 0:
                    score = 1.0 - score
                    weight = abs(weight)

                weighted_fitness += score * weight
                total_weight += abs(weight)

        # Normalize
        if total_weight > 0:
            avg_fitness = weighted_fitness / total_weight
        else:
            avg_fitness = 0.5  # Default

        # Calculate pressure: lower fitness = higher pressure
        # But with diminishing returns below 0.3 fitness
        if avg_fitness < 0.3:
            # High pressure but capped
            pressure = 0.8
        else:
            # Linear scaling: lower fitness = higher pressure
            pressure = 0.8 * (1.0 - avg_fitness)

        # Add adaptability bias: systems that are more adaptable get more evolution
        adaptability = fitness_scores.get("adaptability", 0.5)
        pressure += 0.2 * adaptability  # Adaptable systems evolve more

        # Add random factor to avoid deterministic evolution
        randomness = 0.1 * random.random()
        pressure += randomness

        # Clamp to valid range
        pressure = max(0.0, min(1.0, pressure))

        return pressure

    def _select_evolution_strategy(self, fitness_scores):
        """
        Select an appropriate evolution strategy based on current fitness.

        Parameters:
        - fitness_scores: Current fitness evaluation

        Returns:
        - Selected strategy name
        """
        if not fitness_scores:
            # Default to expansion if no scores
            return "expansion"

        # Calculate weighted probability for each strategy
        strategy_weights = {}

        # Strategy 1: Expansion - good when performance is low but efficiency is high
        if fitness_scores["performance"] < 0.6 and fitness_scores["efficiency"] > 0.7:
            strategy_weights["expansion"] = 0.7 * self.strategies["expansion"]["success_rate"]
        else:
            strategy_weights["expansion"] = 0.3 * self.strategies["expansion"]["success_rate"]

        # Strategy 2: Pruning - good when efficiency is low but performance is decent
        if fitness_scores["efficiency"] < 0.5 and fitness_scores["performance"] > 0.6:
            strategy_weights["pruning"] = 0.8 * self.strategies["pruning"]["success_rate"]
        else:
            strategy_weights["pruning"] = 0.3 * self.strategies["pruning"]["success_rate"]

        # Strategy 3: Restructuring - good when adaptability is low
        if fitness_scores["adaptability"] < 0.5:
            strategy_weights["restructuring"] = 0.7 * self.strategies["restructuring"]["success_rate"]
        else:
            strategy_weights["restructuring"] = 0.4 * self.strategies["restructuring"]["success_rate"]

        # Strategy 4: Specialization - good for complex systems with good performance
        if fitness_scores["complexity"] > 0.7 and fitness_scores["performance"] > 0.7:
            strategy_weights["specialization"] = 0.8 * self.strategies["specialization"]["success_rate"]
        else:
            strategy_weights["specialization"] = 0.2 * self.strategies["specialization"]["success_rate"]

        # Strategy 5: Integration - good for improving robustness
        if fitness_scores["robustness"] < 0.6:
            strategy_weights["integration"] = 0.7 * self.strategies["integration"]["success_rate"]
        else:
            strategy_weights["integration"] = 0.3 * self.strategies["integration"]["success_rate"]

        # Add randomness factor to promote exploration
        for strategy in strategy_weights:
            strategy_weights[strategy] += random.uniform(0, 0.3)

        # Select strategy with highest weight
        selected_strategy = max(strategy_weights.items(), key=lambda x: x[1])[0]

        return selected_strategy

    def _apply_evolution_strategy(self, agent, strategy, fitness_scores):
        """
        Apply the selected evolution strategy to modify the agent.

        Parameters:
        - agent: Agent to evolve
        - strategy: Selected strategy name
        - fitness_scores: Current fitness scores

        Returns:
        - (success, message, changes) tuple
        """
        changes = []

        # Apply different strategies
        if strategy == "expansion":
            return self._apply_expansion_strategy(agent, changes)
        elif strategy == "pruning":
            return self._apply_pruning_strategy(agent, changes)
        elif strategy == "restructuring":
            return self._apply_restructuring_strategy(agent, changes)
        elif strategy == "specialization":
            return self._apply_specialization_strategy(agent, changes)
        elif strategy == "integration":
            return self._apply_integration_strategy(agent, changes)
        else:
            return False, f"Unknown strategy: {strategy}", changes

    def _apply_expansion_strategy(self, agent, changes):
        """
        Apply expansion strategy to increase model capacity.

        Parameters:
        - agent: Agent to evolve
        - changes: List to track changes

        Returns:
        - (success, message, changes) tuple
        """
        # Check for expandable model
        if not hasattr(agent, 'model') or not hasattr(agent.model, 'expand_architecture'):
            return False, "Model does not support architecture expansion", changes

        try:
            # Expansion attempts:
            # 1. Try expanding the model architecture
            agent.model.expand_architecture()
            changes.append("Expanded neural architecture with additional layers")

            # 2. If agent has adaptive learning, adjust its parameters
            if hasattr(agent, 'adaptive_learning'):
                # Increase adaptation rate for new architecture
                adaptive_learning = agent.adaptive_learning
                if hasattr(adaptive_learning, 'adaptation_threshold'):
                    old_threshold = adaptive_learning.adaptation_threshold
                    new_threshold = max(0.05, old_threshold * 0.9)  # More sensitive
                    adaptive_learning.adaptation_threshold = new_threshold
                    changes.append(f"Reduced adaptation threshold from {old_threshold:.2f} to {new_threshold:.2f}")

            # 3. Integrate imagination with learning system
            if (hasattr(agent, 'ai_manager') and
                hasattr(agent.ai_manager, 'imagination') and
                hasattr(agent, 'adaptive_learning')):

                imagination = agent.ai_manager.imagination
                learning = agent.adaptive_learning

                # Link imagination creativity to adaptation rate
                if hasattr(imagination, 'creativity_level') and hasattr(learning, 'adaptation_rate'):
                    creativity = imagination.creativity_level
                    old_rate = learning.adaptation_rate

                    # Higher creativity = higher adaptation rate
                    new_rate = 0.2 + 0.3 * creativity  # Range 0.2-0.5
                    learning.adaptation_rate = new_rate

                    changes.append(f"Integrated imagination creativity with learning adaptation: rate {old_rate:.2f} â†’ {new_rate:.2f}")
                    integration_changes += 1

            # Update strategy success rate based on changes made
            if integration_changes > 0:
                self.strategies["integration"]["success_rate"] = min(0.95, self.strategies["integration"]["success_rate"] * 1.1)
                return True, f"Successfully integrated {integration_changes} component pairs for improved synergy", changes
            else:
                self.strategies["integration"]["success_rate"] = max(0.2, self.strategies["integration"]["success_rate"] * 0.9)
                return False, "No suitable components found for integration", changes

        except Exception as e:
            # Update strategy success rate (decrease on failure)
            self.strategies["integration"]["success_rate"] = max(0.2, self.strategies["integration"]["success_rate"] * 0.9)

            return False, f"Component integration failed: {str(e)}", changes

    def _assess_capability_levels(self, agent):
        """
        Assess current capability levels of the system across target areas.

        Parameters:
        - agent: Agent to assess

        Returns:
        - Dictionary of capability scores
        """
        capabilities = {}

        # 1. Knowledge representation capability
        kr_score = 0.5  # Default

        # Check for semantic memory capacity
        if hasattr(agent, 'free_will') and hasattr(agent.free_will, 'semantic_memory'):
            memory_size = len(agent.free_will.semantic_memory)
            # Scale based on size: 0-1000 items maps to 0.5-0.9 score
            kr_size_factor = min(0.4, memory_size / 2500)
            kr_score += kr_size_factor

        # Check for memory importance tracking
        if hasattr(agent, 'free_will') and hasattr(agent.free_will, 'memory_importance'):
            kr_score += 0.1

        capabilities["knowledge_representation"] = min(0.95, kr_score)

        # 2. Planning capability
        planning_score = 0.4  # Default

        # Check for temporal planner
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'temporal_planner'):
            planner = agent.ai_manager.temporal_planner
            planning_score += 0.2

            # Check for goal system
            if hasattr(planner, 'long_term_goals') and planner.long_term_goals:
                planning_score += min(0.2, len(planner.long_term_goals) * 0.05)

            # Check for reflection capability
            if hasattr(planner, 'reflect_and_adapt'):
                planning_score += 0.1

        capabilities["planning"] = min(0.95, planning_score)

        # 3. Learning capability
        learning_score = 0.3  # Default

        # Check for adaptive learning system
        if hasattr(agent, 'adaptive_learning'):
            learning_score += 0.3

            # Check for meta-learning capability
            if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'meta_learning'):
                learning_score += 0.3

        capabilities["learning"] = min(0.95, learning_score)

        # 4. Error handling capability
        error_score = 0.3  # Default

        # Check for imagination-based error detection
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'imagination'):
            imagination = agent.ai_manager.imagination
            if hasattr(imagination, 'simulate_error_detection'):
                error_score += 0.3

            if hasattr(imagination, 'simulate_error_correction'):
                error_score += 0.2

        # Check for error recovery in AI manager
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'error_recovery_attempts') is not None:
            error_score += 0.1

        capabilities["error_handling"] = min(0.95, error_score)

        # 5. Creative synthesis capability
        creative_score = 0.2  # Default

        # Check for imagination engine
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'imagination'):
            imagination = agent.ai_manager.imagination
            creative_score += 0.3

            # Check for creativity level
            if hasattr(imagination, 'creativity_level'):
                creative_score += imagination.creativity_level * 0.3

        # Check for consciousness system
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'consciousness'):
            consciousness = agent.ai_manager.consciousness

            # Check for qualia simulation
            if hasattr(consciousness, 'qualia_simulation_active'):
                creative_score += 0.1

        capabilities["creative_synthesis"] = min(0.95, creative_score)

        # Store capability assessment
        self.capability_scores = capabilities

        return capabilities

    def get_evolution_report(self):
        """
        Generate a comprehensive report on system evolution status.

        Returns:
        - Dictionary with evolution status information
        """
        if not self.evolution_history:
            return {
                "status": "initialized",
                "generation": 0,
                "message": "Evolution engine initialized but no evolution cycles completed"
            }

        # Calculate success rate
        total_attempts = len(self.evolution_history)
        successful_attempts = sum(1 for record in self.evolution_history if record.get("success", False))
        success_rate = successful_attempts / total_attempts if total_attempts > 0 else 0

        # Get strategy effectiveness
        strategy_stats = {}
        for strategy, data in self.strategies.items():
            success_count = sum(1 for record in self.evolution_history
                             if record.get("strategy") == strategy and record.get("success", False))

            attempt_count = sum(1 for record in self.evolution_history
                             if record.get("strategy") == strategy)

            strategy_stats[strategy] = {
                "attempts": attempt_count,
                "successes": success_count,
                "success_rate": success_count / attempt_count if attempt_count > 0 else 0,
                "current_rating": data["success_rate"]
            }

        # Get recent evolutions
        recent_evolutions = []
        for record in self.evolution_history[-5:]:  # Last 5 evolutions
            recent_evolutions.append({
                "generation": record.get("generation", 0),
                "strategy": record.get("strategy", "unknown"),
                "success": record.get("success", False),
                "message": record.get("message", ""),
                "changes": record.get("changes", [])
            })

        # Calculate evolutionary convergence
        if len(self.fitness_metrics) >= 2:
            # Compare current fitness with previous generation
            current_gen = max(self.fitness_metrics.keys())
            prev_gen = max(k for k in self.fitness_metrics.keys() if k < current_gen)

            current_fitness = self.fitness_metrics[current_gen]
            prev_fitness = self.fitness_metrics[prev_gen]

            # Calculate average improvement across metrics
            improvements = []
            for metric in current_fitness:
                if metric in prev_fitness:
                    # For complexity, lower is better; for others, higher is better
                    if metric == "complexity":
                        change = prev_fitness[metric] - current_fitness[metric]
                    else:
                        change = current_fitness[metric] - prev_fitness[metric]
                    improvements.append(change)

            avg_improvement = sum(improvements) / len(improvements) if improvements else 0
            # Convergence increases as improvement diminishes
            self.convergence_score = 1.0 - min(1.0, abs(avg_improvement) * 10)

        # Generate recommendations for next evolution
        recommendations = []

        # Recommendation 1: Address capability gaps
        capability_gaps = []
        if self.capability_scores:
            for capability, target in self.capability_targets.items():
                current = self.capability_scores.get(capability, 0)
                if current < target and target - current > 0.2:
                    capability_gaps.append((capability, target - current))

            if capability_gaps:
                # Recommend addressing the largest gap
                largest_gap = max(capability_gaps, key=lambda x: x[1])
                recommendations.append({
                    "type": "capability_development",
                    "target": largest_gap[0],
                    "gap": largest_gap[1],
                    "recommendation": f"Prioritize evolution of {largest_gap[0].replace('_', ' ')} capability"
                })

        # Recommendation 2: Strategy adjustment based on success rates
        worst_strategy = min(strategy_stats.items(), key=lambda x: x[1]["success_rate"])[0]
        best_strategy = max(strategy_stats.items(), key=lambda x: x[1]["success_rate"])[0]

        if strategy_stats[worst_strategy]["success_rate"] < 0.3 and strategy_stats[worst_strategy]["attempts"] >= 3:
            recommendations.append({
                "type": "strategy_adjustment",
                "strategy": worst_strategy,
                "recommendation": f"Reduce use of {worst_strategy} strategy due to low success rate ({strategy_stats[worst_strategy]['success_rate']:.2f})"
            })

        # Recommendation 3: Based on convergence
        if self.convergence_score > 0.8:
            recommendations.append({
                "type": "convergence_response",
                "convergence_score": self.convergence_score,
                "recommendation": "System appears to be converging - increase mutation strength to explore new optima"
            })

        return {
            "status": "evolving",
            "generation": self.evolution_generation,
            "attempts": total_attempts,
            "success_rate": success_rate,
            "last_major_evolution": self.last_major_evolution,
            "convergence_score": self.convergence_score,
            "strategy_stats": strategy_stats,
            "recent_evolutions": recent_evolutions,
            "capability_scores": self.capability_scores,
            "recommendations": recommendations
        }

            if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'meta_learning'):
                meta_learning = agent.ai_manager.meta_learning
                if hasattr(meta_learning, 'meta_params'):
                    # Increase exploration after expansion
                    old_rate = meta_learning.meta_params.get("exploration_rate", 0.3)
                    new_rate = min(0.5, old_rate * 1.2)  # More exploration
                    meta_learning.meta_params["exploration_rate"] = new_rate
                    changes.append(f"Increased meta-learning exploration rate from {old_rate:.2f} to {new_rate:.2f}")

            # Update strategy success rate
            self.strategies["expansion"]["success_rate"] = min(0.95, self.strategies["expansion"]["success_rate"] * 1.1)

            return True, "Successfully expanded system architecture and adjusted learning parameters", changes

        except Exception as e:
            # Update strategy success rate (decrease on failure)
            self.strategies["expansion"]["success_rate"] = max(0.2, self.strategies["expansion"]["success_rate"] * 0.9)

            return False, f"Architecture expansion failed: {str(e)}", changes

    def _apply_pruning_strategy(self, agent, changes):
        """
        Apply pruning strategy to reduce model size and increase efficiency.

        Parameters:
        - agent: Agent to evolve
        - changes: List to track changes

        Returns:
        - (success, message, changes) tuple
        """
        # Check for prunable model
        if not hasattr(agent, 'model') or not hasattr(agent.model, 'contract_architecture'):
            return False, "Model does not support architecture pruning", changes

        try:
            # Pruning attempts:
            # 1. Try contracting the model architecture
            agent.model.contract_architecture()
            changes.append("Contracted neural architecture by removing underutilized layers")

            # 2. If agent has memory systems, prune those too
            if hasattr(agent, 'free_will') and hasattr(agent.free_will, 'contract_memory'):
                old_size = len(agent.free_will.memory_set) if hasattr(agent.free_will, 'memory_set') else 0

                # Calculate target size (80% of current)
                target_size = int(old_size * 0.8)
                if target_size > 0:
                    agent.free_will.contract_memory(target_size)
                    new_size = len(agent.free_will.memory_set) if hasattr(agent.free_will, 'memory_set') else 0
                    changes.append(f"Pruned memory from {old_size} to {new_size} items")

            # 3. If agent has semantic memory, optimize it
            if hasattr(agent, 'free_will') and hasattr(agent.free_will, 'semantic_memory'):
                if agent.free_will.semantic_memory:
                    old_count = len(agent.free_will.semantic_memory)
                    # Remove low importance memories
                    low_importance = []
                    threshold = 0.4  # Below this importance, consider pruning

                    for url, data in agent.free_will.semantic_memory.items():
                        if isinstance(data, dict) and "importance" in data:
                            if data["importance"] < threshold:
                                low_importance.append(url)

                    # Remove a portion of low importance items
                    prune_count = min(len(low_importance), int(old_count * 0.2))  # Prune up to 20%

                    for url in low_importance[:prune_count]:
                        if url in agent.free_will.semantic_memory:
                            del agent.free_will.semantic_memory[url]

                    new_count = len(agent.free_will.semantic_memory)
                    if new_count < old_count:
                        changes.append(f"Pruned semantic memory from {old_count} to {new_count} items")

            # Update strategy success rate
            self.strategies["pruning"]["success_rate"] = min(0.95, self.strategies["pruning"]["success_rate"] * 1.1)

            return True, "Successfully pruned system components to improve efficiency", changes

        except Exception as e:
            # Update strategy success rate (decrease on failure)
            self.strategies["pruning"]["success_rate"] = max(0.2, self.strategies["pruning"]["success_rate"] * 0.9)

            return False, f"Architecture pruning failed: {str(e)}", changes

    def _apply_restructuring_strategy(self, agent, changes):
        """
        Apply restructuring strategy to reorganize components without changing capacity.

        Parameters:
        - agent: Agent to evolve
        - changes: List to track changes

        Returns:
        - (success, message, changes) tuple
        """
        try:
            # Restructuring attempts:
            # 1. Modify consciousness parameters if present
            if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'consciousness'):
                consciousness = agent.ai_manager.consciousness

                # Adjust awareness fluctuation rate
                if hasattr(consciousness, 'awareness_fluctuation_rate'):
                    old_rate = consciousness.awareness_fluctuation_rate
                    new_rate = old_rate * random.uniform(0.8, 1.2)  # Random adjustment
                    consciousness.awareness_fluctuation_rate = max(0.01, min(0.1, new_rate))
                    changes.append(f"Adjusted consciousness fluctuation rate: {old_rate:.3f} â†’ {new_rate:.3f}")

                # Reset state to "reflective" to encourage reassessment
                if hasattr(consciousness, 'current_state'):
                    old_state = consciousness.current_state
                    consciousness.current_state = "reflective"
                    changes.append(f"Reset consciousness state from '{old_state}' to 'reflective'")

                # Boost awareness temporarily
                if hasattr(consciousness, 'increase_awareness'):
                    consciousness.increase_awareness(0.2)
                    changes.append("Temporarily boosted consciousness awareness for restructuring")

            # 2. Modify temporal planner goals if present
            if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'temporal_planner'):
                planner = agent.ai_manager.temporal_planner

                # Rebalance goal priorities
                if hasattr(planner, 'long_term_goals') and planner.long_term_goals:
                    # Shuffle priorities
                    old_priorities = {}
                    for goal in planner.long_term_goals:
                        old_priorities[goal.get("id", "unknown")] = goal.get("priority", 0.5)

                    # Create new distribution
                    total_priority = sum(goal.get("priority", 0.5) for goal in planner.long_term_goals)
                    avg_priority = total_priority / len(planner.long_term_goals)

                    # Invert relative to average
                    for goal in planner.long_term_goals:
                        goal_id = goal.get("id", "unknown")
                        old_priority = goal.get("priority", 0.5)

                        # Calculate new priority as reflection around average
                        new_priority = avg_priority + (avg_priority - old_priority)
                        # Ensure it's in valid range
                        new_priority = max(0.1, min(1.0, new_priority))

                        # Apply new priority
                        goal["priority"] = new_priority

                    changes.append("Rebalanced long-term goal priorities to shift focus")

                # Refresh short-term goals immediately
                if hasattr(planner, 'refresh_short_term_goals'):
                    planner.refresh_short_term_goals()
                    changes.append("Regenerated short-term goals based on restructured priorities")

            # 3. Modify imagination engine if present
            if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'imagination'):
                imagination = agent.ai_manager.imagination

                # Adjust creativity level
                if hasattr(imagination, 'creativity_level'):
                    old_level = imagination.creativity_level
                    new_level = 1.0 - old_level  # Invert creativity level
                    imagination.creativity_level = new_level
                    changes.append(f"Inverted imagination creativity level: {old_level:.2f} â†’ {new_level:.2f}")

                # Change current mode
                if hasattr(imagination, 'current_mode') and hasattr(imagination, 'cognitive_modes'):
                    old_mode = imagination.current_mode
                    # Select a different mode
                    available_modes = [m for m in imagination.cognitive_modes if m != old_mode]
                    if available_modes:
                        new_mode = random.choice(available_modes)
                        imagination.current_mode = new_mode
                        changes.append(f"Switched imagination cognitive mode: '{old_mode}' â†’ '{new_mode}'")

            # Update strategy success rate
            if changes:
                self.strategies["restructuring"]["success_rate"] = min(0.95, self.strategies["restructuring"]["success_rate"] * 1.1)
                return True, "Successfully restructured internal cognitive components", changes
            else:
                self.strategies["restructuring"]["success_rate"] = max(0.2, self.strategies["restructuring"]["success_rate"] * 0.9)
                return False, "No suitable components found for restructuring", changes

        except Exception as e:
            # Update strategy success rate (decrease on failure)
            self.strategies["restructuring"]["success_rate"] = max(0.2, self.strategies["restructuring"]["success_rate"] * 0.9)

            return False, f"Component restructuring failed: {str(e)}", changes

    def _apply_specialization_strategy(self, agent, changes):
        """
        Apply specialization strategy to optimize specific components for efficiency.

        Parameters:
        - agent: Agent to evolve
        - changes: List to track changes

        Returns:
        - (success, message, changes) tuple
        """
        try:
            # Identify specialized modules to optimize
            specialized_changes = 0

            # 1. Specialize content sifter if present
            if hasattr(agent, 'content_sifter'):
                sifter = agent.content_sifter

                # Customize topic focus
                if hasattr(sifter, 'topics_of_interest'):
                    # Pick top 3 priorities from temporal planner if available
                    priority_topics = []

                    if (hasattr(agent, 'ai_manager') and
                        hasattr(agent.ai_manager, 'temporal_planner') and
                        hasattr(agent.ai_manager.temporal_planner, 'long_term_goals')):

                        # Extract keywords from highest priority goals
                        goals = sorted(agent.ai_manager.temporal_planner.long_term_goals,
                                     key=lambda g: g.get("priority", 0), reverse=True)

                        for goal in goals[:3]:
                            desc = goal.get("description", "").lower()
                            words = desc.split()
                            important_words = [w for w in words if len(w) > 4]
                            priority_topics.extend(important_words[:2])  # 2 keywords per goal

                    # Add some general technology topics
                    tech_topics = ["artificial intelligence", "quantum computing",
                                  "neural networks", "machine learning"]

                    # Combine maintaining 30% of original topics for diversity
                    old_topics = sifter.topics_of_interest
                    keep_count = max(3, int(len(old_topics) * 0.3))
                    kept_topics = random.sample(old_topics, keep_count)

                    # Create new specialized topic list
                    new_topics = kept_topics + priority_topics + tech_topics
                    # Remove duplicates
                    new_topics = list(dict.fromkeys(new_topics))

                    # Apply change
                    sifter.topics_of_interest = new_topics
                    specialized_changes += 1
                    changes.append(f"Specialized content sifter with {len(new_topics)} focused topics")

            # 2. Specialize free will parameters if present
            if hasattr(agent, 'free_will'):
                free_will = agent.free_will

                # Adjust exploration/exploitation balance
                if hasattr(free_will, 'exploration_weight') and hasattr(free_will, 'exploitation_weight'):
                    # Identify system state - are we specialized enough already?
                    if hasattr(agent, 'stats') and 'domains_visited' in agent.stats:
                        domains_count = len(agent.stats['domains_visited'])

                        # If we've visited many domains, increase exploitation
                        if domains_count > 20:
                            old_expl = free_will.exploration_weight
                            old_expt = free_will.exploitation_weight

                            # Shift toward exploitation
                            free_will.exploitation_weight = min(0.8, old_expt + 0.1)
                            free_will.exploration_weight = 1.0 - free_will.exploitation_weight

                            changes.append(f"Specialized free will toward exploitation: {old_expl:.2f}/{old_expt:.2f} â†’ {free_will.exploration_weight:.2f}/{free_will.exploitation_weight:.2f}")
                            specialized_changes += 1

            # 3. Specialize imagination engine if present
            if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'imagination'):
                imagination = agent.ai_manager.imagination

                # Specialize domain expertise
                if hasattr(imagination, 'domains'):
                    domains = imagination.domains

                    # Identify top 2 domains based on current expertise
                    top_domains = sorted(domains.items(), key=lambda x: x[1], reverse=True)[:2]

                    # Boost top domains further
                    for domain, expertise in top_domains:
                        old_expertise = expertise
                        new_expertise = min(0.95, old_expertise + 0.1)
                        imagination.domains[domain] = new_expertise
                        changes.append(f"Specialized imagination expertise in {domain}: {old_expertise:.2f} â†’ {new_expertise:.2f}")

                    specialized_changes += 1

            # Update strategy success rate based on changes made
            if specialized_changes > 0:
                self.strategies["specialization"]["success_rate"] = min(0.95, self.strategies["specialization"]["success_rate"] * 1.1)
                return True, f"Successfully specialized {specialized_changes} components for improved focus", changes
            else:
                self.strategies["specialization"]["success_rate"] = max(0.2, self.strategies["specialization"]["success_rate"] * 0.9)
                return False, "No suitable components found for specialization", changes

        except Exception as e:
            # Update strategy success rate (decrease on failure)
            self.strategies["specialization"]["success_rate"] = max(0.2, self.strategies["specialization"]["success_rate"] * 0.9)

            return False, f"Component specialization failed: {str(e)}", changes

    def _apply_integration_strategy(self, agent, changes):
        """
        Apply integration strategy to combine previously separate capabilities.

        Parameters:
        - agent: Agent to evolve
        - changes: List to track changes

        Returns:
        - (success, message, changes) tuple
        """
        try:
            # Integration attempts:
            integration_changes = 0

            # 1. Integrate consciousness with planning if possible
            if (hasattr(agent, 'ai_manager') and
                hasattr(agent.ai_manager, 'consciousness') and
                hasattr(agent.ai_manager, 'temporal_planner')):

                consciousness = agent.ai_manager.consciousness
                planner = agent.ai_manager.temporal_planner

                # Link consciousness awareness to planning patience
                if hasattr(consciousness, 'awareness_level') and hasattr(planner, 'reflection_interval'):
                    # Adjust reflection interval based on consciousness
                    awareness = consciousness.awareness_level
                    old_interval = planner.reflection_interval

                    # Higher awareness = more frequent reflection
                    new_interval = int(max(5, 30 - 25 * awareness))
                    planner.reflection_interval = new_interval

                    changes.append(f"Integrated consciousness awareness with planning reflection: interval {old_interval} â†’ {new_interval}")
                    integration_changes += 1

            # 2. Integrate free will with content filtering
            if hasattr(agent, 'free_will') and hasattr(agent, 'content_sifter'):
                free_will = agent.free_will
                sifter = agent.content_sifter

                # Transfer topics of interest between systems
                if hasattr(free_will, 'memory_importance') and hasattr(sifter, 'topics_of_interest'):
                    # Check for URLs with high importance
                    important_urls = []
                    for url, importance in free_will.memory_importance.items():
                        if importance > 0.7:  # High importance threshold
                            important_urls.append(url)

                    # Extract keywords from important URLs in semantic memory
                    if important_urls and hasattr(free_will, 'semantic_memory'):
                        new_topics = []

                        for url in important_urls[:5]:  # Use top 5 max
                            if url in free_will.semantic_memory:
                                memory = free_will.semantic_memory[url]
                                keywords = memory.get("keywords", [])
                                if keywords:
                                    new_topics.extend(keywords[:3])  # Add top 3 keywords

                        if new_topics:
                            # Add new topics to content sifter (with deduplication)
                            old_topics = set(sifter.topics_of_interest)
                            combined_topics = list(old_topics.union(set(new_topics)))
                            sifter.topics_of_interest = combined_topics

                            changes.append(f"Integrated free will memory importance with content filtering: added {len(new_topics)} new topics of interest")
                            integration_changes += 1

            # 3.class MetaEvolutionEngine:
    """
    Advanced self-evolution system that enables the agent to modify its own
    architecture, algorithms, and capabilities based on performance metrics
    and emerging requirements.
    """
    def __init__(self):
        self.evolution_history = []
        self.capability_scores = {}
        self.architecture_genealogy = {}
        self.mutation_statistics = {}
        self.fitness_metrics = {}
        self.adaptation_rate = 0.3  # How quickly system evolves (0.0-1.0)
        self.mutation_strength = 0.2  # Magnitude of architectural changes
        self.convergence_score = 0.0  # Measure of evolutionary convergence
        self.evolution_generation = 0  # Current generation counter
        self.last_major_evolution = 0  # Cycle of last major evolutionary change
        self.selection_pressure = 0.7  # Pressure toward fitness optimization
        self.diversity_target = 0.4  # Target architectural diversity

        # Evolution strategies
        self.strategies = {
            "expansion": {
                "description": "Add new capabilities or capacity",
                "success_rate": 0.5,  # Initial estimate
                "condition": "underfitting or new task requirements"
            },
            "pruning": {
                "description": "Remove redundant or ineffective components",
                "success_rate": 0.5,
                "condition": "overfitting or efficiency targets"
            },
            "restructuring": {
                "description": "Reorganize connections without changing capacity",
                "success_rate": 0.5,
                "condition": "plateaued performance with adequate capacity"
            },
            "specialization": {
                "description": "Optimize specific components for targeted tasks",
                "success_rate": 0.5,
                "condition": "diverse task requirements with resource constraints"
            },
            "integration": {
                "description": "Combine previously separate capabilities",
                "success_rate": 0.5,
                "condition": "related capabilities with redundancy"
            }
        }

        # Evolution goal weights (what we're optimizing for)
        self.goal_weights = {
            "performance": 0.7,  # Primary goal is improving performance
            "efficiency": 0.5,   # Secondary goal is resource efficiency
            "adaptability": 0.6, # Tertiary goal is adapting to new situations
            "robustness": 0.4,   # Quaternary goal is error resistance
            "complexity": -0.3   # Penalty for unnecessary complexity
        }

        # Capability targets (what the system needs to be able to do)
        self.capability_targets = {
            "knowledge_representation": 0.8,
            "planning": 0.7,
            "learning": 0.9,
            "error_handling": 0.6,
            "creative_synthesis": 0.7
        }

        log_event("MetaEvolutionEngine initialized", "QUANTUM")

    def evolve_system(self, agent):
        """
        Trigger system evolution based on performance metrics, goals,
        and environmental requirements.

        Parameters:
        - agent: Agent instance to evolve

        Returns:
        - (success, message) tuple
        """
        # Basic validation
        if not agent:
            return False, "Invalid agent provided to evolution engine."

        # Check if cycle counter is available to determine timing
        cycle_count = 0
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'cycle_counter'):
            cycle_count = agent.ai_manager.cycle_counter
        else:
            # Try alternative attributes
            cycle_count = getattr(agent, 'stats', {}).get('cycles_run', 0)

        # Evolution interval check (don't evolve too frequently)
        evolution_interval = SELF_MODIFY_INTERVAL  # From global config
        cycles_since_last = cycle_count - self.last_major_evolution

        if cycles_since_last < evolution_interval:
            return False, f"Evolution interval not reached. {cycles_since_last}/{evolution_interval} cycles since last evolution."

        # Increase generation counter
        self.evolution_generation += 1

        # Analyze current state and fitness
        fitness_scores = self._evaluate_system_fitness(agent)
        evolutionary_pressure = self._calculate_evolutionary_pressure(fitness_scores)

        # Determine if evolution should occur based on pressure and randomness
        evolution_threshold = 0.3  # Base threshold
        evolution_probability = evolution_threshold + evolutionary_pressure

        if random.random() >= evolution_probability:
            return False, f"Evolution check passed, but probability threshold not met ({evolution_probability:.2f})."

        # System will evolve - select strategy
        selected_strategy = self._select_evolution_strategy(fitness_scores)

        # Apply the selected evolutionary strategy
        success, message, changes = self._apply_evolution_strategy(agent, selected_strategy, fitness_scores)

        # Record the evolution attempt
        evolution_record = {
            "generation": self.evolution_generation,
            "cycle": cycle_count,
            "strategy": selected_strategy,
            "success": success,
            "message": message,
            "changes": changes,
            "fitness_before": fitness_






# Add associations and insights to thought
        thought["associations"] = associations
        thought["insights"] = insights

        # Calculate importance
        if insights:
            thought["importance"] = 0.6 + 0.1 * len(insights)

        # Set content to most significant insight or association
        if insights:
            thought["content"] = insights[0]
        elif associations:
            thought["content"] = associations[0]

        return thought

    def _generate_reflective_thought(self, context):
        """Generate a reflective thought focused on self-examination"""
        # Default reflective thought structure
        thought = {
            "type": "reflective",
            "content": "Meta-cognitive assessment",
            "reflections": [],
            "insights": [],
            "importance": 0.5
        }

        # Areas for reflection
        reflection_areas = [
            "learning_progress",
            "strategy_effectiveness",
            "error_patterns",
            "goal_alignment",
            "cognitive_bias"
        ]

        # Select 1-3 areas for reflection
        selected_areas = random.sample(reflection_areas, min(3, len(reflection_areas)))

        # Generate reflections for selected areas
        reflections = []

        # Extract history from thought history and context
        history_span = min(10, len(self.thought_history))
        recent_thoughts = self.thought_history[-history_span:] if history_span > 0 else []

        for area in selected_areas:
            if area == "learning_progress":
                # Reflect on learning and improvement
                if "stats" in context and isinstance(context["stats"], dict):
                    cycles = context["stats"].get("cycles_run", 0)
                    pages = context["stats"].get("pages_processed", 0)

                    if cycles > 0:
                        learning_rate = pages / max(1, cycles)
                        reflections.append({
                            "area": "learning_progress",
                            "content": f"Learning rate: {learning_rate:.2f} pages per cycle",
                            "assessment": "satisfactory" if learning_rate > 0.5 else "needs improvement"
                        })

            elif area == "strategy_effectiveness":
                # Reflect on strategy effectiveness
                if (hasattr(self.agent, 'planner_sifter') and
                    hasattr(self.agent.planner_sifter, 'strategies')):
                    strategies = self.agent.planner_sifter.strategies
                    if strategies:
                        # Find most and least effective strategies
                        sorted_strategies = sorted(
                            [(name, data.get("effectiveness", 0.5))
                             for name, data in strategies.items()],
                            key=lambda x: x[1],
                            reverse=True
                        )

                        if sorted_strategies:
                            best = sorted_strategies[0]
                            worst = sorted_strategies[-1]

                            reflections.append({
                                "area": "strategy_effectiveness",
                                "content": f"Most effective strategy: {best[0]} ({best[1]:.2f}), Least effective: {worst[0]} ({worst[1]:.2f})",
                                "recommendation": f"Consider increasing use of {best[0]} approach"
                            })

            elif area == "error_patterns":
                # Reflect on error patterns
                if recent_thoughts:
                    # Look for mentions of errors in recent thoughts
                    error_thoughts = [t for t in recent_thoughts
                                     if "error" in str(t.get("content", "")).lower()]

                    if error_thoughts:
                        error_count = len(error_thoughts)
                        reflections.append({
                            "area": "error_patterns",
                            "content": f"Error-related thoughts appearing in {error_count}/{len(recent_thoughts)} recent thoughts",
                            "assessment": "concerning" if error_count > 3 else "manageable"
                        })

            elif area == "goal_alignment":
                # Reflect on goal alignment with actions
                if ("current_goal" in context and
                    "recent_actions" in context and
                    isinstance(context["recent_actions"], list)):

                    goal = context["current_goal"].get("description", "") if isinstance(context["current_goal"], dict) else ""

                    if goal:
                        actions = context["recent_actions"]
                        aligned_count = 0

                        # Simple heuristic to estimate alignment
                        for action in actions:
                            if isinstance(action, dict) and "action" in action:
                                action_type = action["action"]
                                # Check basic alignment (very simplistic)
                                if "explore" in goal.lower() and action_type in ["expand", "search"]:
                                    aligned_count += 1
                                elif "deep" in goal.lower() and action_type in ["evaluate", "adapt"]:
                                    aligned_count += 1

                        alignment_rate = aligned_count / max(1, len(actions))
                        reflections.append({
                            "area": "goal_alignment",
                            "content": f"Action-goal alignment rate: {alignment_rate:.2f}",
                            "assessment": "well-aligned" if alignment_rate > 0.6 else "misaligned"
                        })

            elif area == "cognitive_bias":
                # Reflect on potential cognitive biases
                potential_biases = []

                # Check for confirmation bias - using same strategy repeatedly
                if recent_thoughts:
                    modes = [t.get("mode") for t in recent_thoughts]
                    mode_counts = {}
                    for mode in modes:
                        if mode:
                            mode_counts[mode] = mode_counts.get(mode, 0) + 1

                    most_common = max(mode_counts.items(), key=lambda x: x[1]) if mode_counts else (None, 0)

                    if most_common[1] > len(recent_thoughts) * 0.7:
                        potential_biases.append(f"Possible cognitive fixation on {most_common[0]} thinking mode")

                # Check for recency bias - focusing too much on recent results
                if "recent_actions" in context and isinstance(context["recent_actions"], list):
                    actions = context["recent_actions"]
                    if len(actions) >= 2:
                        last_action = actions[-1]
                        if isinstance(last_action, dict) and last_action.get("success", False):
                            potential_biases.append("Potential recency bias - overweighting last successful action")

                if potential_biases:
                    reflections.append({
                        "area": "cognitive_bias",
                        "content": potential_biases[0],
                        "recommendation": "Consider deliberate perspective shifts to counteract"
                    })

        # Generate insights from reflections
        insights = []
        for reflection in reflections:
            area = reflection.get("area", "")
            assessment = reflection.get("assessment", "")
            recommendation = reflection.get("recommendation", "")

            if area == "learning_progress" and assessment == "needs improvement":
                insights.append("Learning rate below target - consider adjusting exploration/exploitation balance")
            elif area == "strategy_effectiveness" and recommendation:
                insights.append(recommendation)
            elif area == "error_patterns" and assessment == "concerning":
                insights.append("High error rate - implement additional validation measures")
            elif area == "goal_alignment" and assessment == "misaligned":
                insights.append("Actions not well-aligned with goals - revisit planning process")
            elif area == "cognitive_bias" and recommendation:
                insights.append(recommendation)

        # Add reflections and insights to thought
        thought["reflections"] = reflections
        thought["insights"] = insights

        # Calculate importance based on reflections and insights
        importance = 0.5
        if insights:
            importance += 0.1 * len(insights)
        if "concerning" in str(reflections) or "misaligned" in str(reflections):
            importance += 0.2

        thought["importance"] = min(0.9, importance)

        # Set content to most significant insight or reflection
        if insights:
            thought["content"] = insights[0]
        elif reflections:
            thought["content"] = reflections[0].get("content", "Meta-cognitive reflection")

        return thought

    def _generate_exploratory_thought(self, context):
        """Generate an exploratory thought focused on new possibilities"""
        # Default exploratory thought structure
        thought = {
            "type": "exploratory",
            "content": "Exploration of new possibilities",
            "directions": [],
            "insights": [],
            "importance": 0.5
        }

        # Exploration areas
        exploration_areas = [
            "unknown_domains",
            "connection_patterns",
            "alternative_strategies",
            "capability_expansion"
        ]

        # Select areas to explore
        selected_areas = random.sample(exploration_areas, min(2, len(exploration_areas)))

        # Generate exploration directions
        directions = []

        for area in selected_areas:
            if area == "unknown_domains":
                # Suggest unexplored domains
                if "domains_visited" in context:
                    domains_visited = context.get("domains_visited", set())
                    if isinstance(domains_visited, set):
                        # Create some example domains that might be valuable
                        candidate_domains = [
                            "research.science", "github.com", "en.wikipedia.org",
                            "arxiv.org", "semanticscholar.org", "openai.com",
                            "nature.com", "reddit.com/r/MachineLearning"
                        ]

                        # Find unvisited domains
                        unvisited = [d for d in candidate_domains if d not in domains_visited]

                        if unvisited:
                            sample_domains = random.sample(unvisited, min(3, len(unvisited)))

                            directions.append({
                                "area": "unknown_domains",
                                "content": f"Explore high-value domains: {', '.join(sample_domains)}",
                                "rationale": "Expanding domain knowledge diversity"
                            })

            elif area == "connection_patterns":
                # Suggest new ways to connect existing knowledge
                directions.append({
                    "area": "connection_patterns",
                    "content": "Implement knowledge graph traversal to find distant connections",
                    "rationale": "Distant domains often contain valuable cross-applicable patterns"
                })

            elif area == "alternative_strategies":
                # Suggest alternative strategies
                if (hasattr(self.agent, 'planner_sifter') and
                    hasattr(self.agent.planner_sifter, 'strategies')):

                    strategies = list(self.agent.planner_sifter.strategies.keys())
                    if strategies:
                        # Find rarely used strategies
                        if (hasattr(self.agent.planner_sifter, 'strategy_usage')):
                            usage = self.agent.planner_sifter.strategy_usage

                            least_used = sorted([(s, usage.get(s, 0)) for s in strategies],
                                              key=lambda x: x[1])

                            if least_used:
                                least_used_strategy = least_used[0][0]

                                directions.append({
                                    "area": "alternative_strategies",
                                    "content": f"Experiment with underutilized strategy: {least_used_strategy}",
                                    "rationale": "Diversifying strategic approaches to discover new optima"
                                })

            elif area == "capability_expansion":
                # Suggest new capabilities to develop
                directions.append({
                    "area": "capability_expansion",
                    "content": "Develop enhanced semantic reasoning module",
                    "rationale": "Would significantly improve knowledge integration capabilities"
                })

        # Generate insights from exploration directions
        insights = []
        for direction in directions:
            area = direction.get("area", "")
            rationale = direction.get("rationale", "")

            if area == "unknown_domains":
                insights.append("Systematic exploration of high-value domains should be prioritized")
            elif area == "connection_patterns":
                insights.append("Knowledge value may lie in unexpected cross-domain connections")
            elif area == "alternative_strategies":
                insights.append("Strategic diversification may uncover more effective approaches")
            elif area == "capability_expansion":
                insights.append("Capability development should focus on knowledge integration")

        # Add directions and insights to thought
        thought["directions"] = directions
        thought["insights"] = insights

        # Calculate importance
        if insights:
            thought["importance"] = 0.6 + 0.1 * len(insights)

        # Set content to most significant insight or direction
        if insights:
            thought["content"] = insights[0]
        elif directions:
            thought["content"] = directions[0].get("content", "Exploration suggestion")

        return thought

    def _generate_critical_thought(self, context):
        """Generate a critical thought focused on evaluation and assessment"""
        # Default critical thought structure
        thought = {
            "type": "critical",
            "content": "Critical evaluation",
            "assessments": [],
            "insights": [],
            "importance": 0.5
        }

        # Critical assessment areas
        assessment_areas = [
            "information_quality",
            "reasoning_validity",
            "strategy_efficiency",
            "resource_allocation",
            "error_handling"
        ]

        # Select areas to assess critically
        selected_areas = random.sample(assessment_areas, min(2, len(assessment_areas)))

        # Generate critical assessments
        assessments = []

        for area in selected_areas:
            if area == "information_quality":
                # Assess quality of information sources
                if (hasattr(self.agent, 'free_will') and
                    hasattr(self.agent.free_will, 'domain_intelligence')):

                    intelligence = self.agent.free_will.domain_intelligence

                    if hasattr(intelligence, 'domain_knowledge'):
                        knowledge = intelligence.domain_knowledge

                        if knowledge:
                            # Find domains with low quality scores
                            low_quality_domains = []
                            for domain, data in knowledge.items():
                                if isinstance(data, dict) and data.get("content_quality", 1.0) < 0.5:
                                    low_quality_domains.append(domain)

                            if low_quality_domains:
                                sample_domains = random.sample(low_quality_domains, min(2, len(low_quality_domains)))

                                assessments.append({
                                    "area": "information_quality",
                                    "content": f"Low-quality content detected in domains: {', '.join(sample_domains)}",
                                    "recommendation": "Implement stricter quality thresholds for these domains"
                                })
                            else:
                                # General assessment
                                assessments.append({
                                    "area": "information_quality",
                                    "content": "Overall information quality appears acceptable",
                                    "recommendation": "Continue regular quality monitoring"
                                })

            elif area == "reasoning_validity":
                # Assess reasoning processes
                if self.thought_history:
                    # Simple heuristic - count how many different thought types we're using
                    recent_thoughts = self.thought_history[-10:] if len(self.thought_history) >= 10 else self.thought_history

                    thought_types = set(t.get("type", "") for t in recent_thoughts)

                    if len(thought_types) < 3:
                        assessments.append({
                            "area": "reasoning_validity",
                            "content": f"Limited cognitive diversity detected (only {len(thought_types)} thought types used recently)",
                            "recommendation": "Deliberately activate more diverse thinking modes"
                        })
                    else:
                        assessments.append({
                            "area": "reasoning_validity",
                            "content": f"Cognitive diversity appears healthy ({len(thought_types)} different thought types used recently)",
                            "recommendation": "Maintain diverse thinking patterns"
                        })

            elif area == "strategy_efficiency":
                # Assess strategy efficiency
                if (hasattr(self.agent, 'stats') and
                    isinstance(self.agent.stats, dict) and
                    'cycles_run' in self.agent.stats and
                    'pages_processed' in self.agent.stats):

                    cycles = self.agent.stats['cycles_run']
                    pages = self.agent.stats['pages_processed']

                    if cycles > 10:
                        efficiency = pages / max(1, cycles)

                        if efficiency < 0.5:
                            assessments.append({
                                "area": "strategy_efficiency",
                                "content": f"Low efficiency detected: {efficiency:.2f} pages/cycle",
                                "recommendation": "Consider more aggressive pruning of low-value paths"
                            })
                        else:
                            assessments.append({
                                "area": "strategy_efficiency",
                                "content": f"Acceptable efficiency: {efficiency:.2f} pages/cycle",
                                "recommendation": "Continue current approach with regular efficiency monitoring"
                            })

            elif area == "resource_allocation":
                # Assess resource allocation
                if (hasattr(self.agent, 'memory') and
                    hasattr(self.agent, 'free_will') and
                    hasattr(self.agent.free_will, 'memory_set')):

                    memory_usage = len(self.agent.memory) / MEMORY_MAX_SIZE
                    urls_stored = len(self.agent.free_will.memory_set)

                    if memory_usage > 0.8 and urls_stored > 1000:
                        assessments.append({
                            "area": "resource_allocation",
                            "content": f"High memory usage ({memory_usage:.0%}) with {urls_stored} URLs stored",
                            "recommendation": "Implement more aggressive memory pruning strategy"
                        })
                    else:
                        assessments.append({
                            "area": "resource_allocation",
                            "content": f"Memory usage ({memory_usage:.0%}) with {urls_stored} URLs stored",
                            "recommendation": "Current resource allocation appears appropriate"
                        })

            elif area == "error_handling":
                # Assess error handling
                if (hasattr(self.agent, 'domain_stats') and
                    isinstance(self.agent.domain_stats, dict)):

                    # Calculate overall error rate
                    total_visits = sum(d.get("visits", 0) for d in self.agent.domain_stats.values())
                    total_errors = sum(d.get("error_count", 0) for d in self.agent.domain_stats.values())

                    if total_visits > 0:
                        error_rate = total_errors / total_visits

                        if error_rate > 0.2:
                            assessments.append({
                                "area": "error_handling",
                                "content": f"High system-wide error rate: {error_rate:.2%}",
                                "recommendation": "Investigate error causes and implement more robust handling"
                            })
                        else:
                            assessments.append({
                                "area": "error_handling",
                                "content": f"Acceptable error rate: {error_rate:.2%}",
                                "recommendation": "Continue monitoring error patterns"
                            })

        # Generate insights from assessments
        insights = []
        for assessment in assessments:
            area = assessment.get("area", "")
            recommendation = assessment.get("recommendation", "")

            if "low-quality" in assessment.get("content", "").lower():
                insights.append("Information quality control needs improvement")
            elif "limited cognitive diversity" in assessment.get("content", "").lower():
                insights.append("Need to activate more diverse thinking patterns")
            elif "low efficiency" in assessment.get("content", "").lower():
                insights.append("Strategy efficiency requires optimization")
            elif "high memory usage" in assessment.get("content", "").lower():
                insights.append("Memory management needs more efficient pruning")
            elif "high system-wide error" in assessment.get("content", "").lower():
                insights.append("Error handling systems require review and enhancement")
            elif recommendation:
                insights.append(recommendation)

        # Add assessments and insights to thought
        thought["assessments"] = assessments
        thought["insights"] = insights

        # Calculate importance based on assessments and insights
        importance = 0.5
        if insights:
            importance += 0.1 * len(insights)

        # Critical issues have higher importance
        if any("high" in a.get("content", "").lower() for a in assessments):
            importance += 0.2

        thought["importance"] = min(0.9, importance)

        # Set content to most significant insight or assessment
        if insights:
            thought["content"] = insights[0]
        elif assessments:
            thought["content"] = assessments[0].get("content", "Critical assessment")

        return thought

    def _generate_integrative_thought(self, context):
        """Generate an integrative thought focused on knowledge synthesis"""
        # Default integrative thought structure
        thought = {
            "type": "integrative",
            "content": "Knowledge synthesis",
            "connections": [],
            "insights": [],
            "importance": 0.5
        }

        # Generate knowledge connections
        connections = []

        # Without context, generate basic integrative thought
        if not context:
            thought["content"] = "Insufficient knowledge for meaningful integration"
            return thought

        # Extract potential integration elements
        elements = {}

        # Extract domains if available
        if "domains_visited" in context:
            domains = context.get("domains_visited", set())
            if isinstance(domains, set) and len(domains) > 3:
                elements["domains"] = list(domains)

        # Extract topics from content sifter if available
        if hasattr(self.agent, 'content_sifter'):
            sifter = self.agent.content_sifter
            if hasattr(sifter, 'topics_of_interest'):
                elements["topics"] = sifter.topics_of_interest

        # Extract goals from temporal planner if available
        if (hasattr(self.agent, 'ai_manager') and
            hasattr(self.agent.ai_manager, 'temporal_planner') and
            hasattr(self.agent.ai_manager.temporal_planner, 'long_term_goals')):

            goals = self.agent.ai_manager.temporal_planner.long_term_goals
            if goals:
                elements["goals"] = [g.get("description", "") for g in goals]

        # Generate connections between different element types
        if len(elements) >= 2:
            element_types = list(elements.keys())

            # Pick two element types to connect
            type_pair = random.sample(element_types, 2)

            # Select specific elements to connect
            elements_1 = elements[type_pair[0]]
            elements_2 = elements[type_pair[1]]

            if elements_1 and elements_2:
                element_1 = random.choice(elements_1)
                element_2 = random.choice(elements_2)

                # Create connection
                connections.append({
                    "elements": [
                        {"type": type_pair[0], "value": element_1},
                        {"type": type_pair[1], "value": element_2}
                    ],
                    "connection_type": "integration",
                    "description": f"Integration of {type_pair[0]} '{element_1}' with {type_pair[1]} '{element_2}'",
                    "potential": random.uniform(0.5, 0.9)
                })

        # If we couldn't create connections from context, create theoretical ones
        if not connections:
            theoretical_connections = [
                {
                    "elements": [
                        {"type": "cognitive_mode", "value": "analytical"},
                        {"type": "capability", "value": "semantic_representation"}
                    ],
                    "connection_type": "enhancement",
                    "description": "Analytical thinking could enhance semantic representation quality",
                    "potential": 0.7
                },
                {
                    "elements": [
                        {"type": "capability", "value": "memory_management"},
                        {"type": "capability", "value": "planning"}
                    ],
                    "connection_type": "synergy",
                    "description": "Memory systems could be more tightly integrated with planning",
                    "potential": 0.8
                }
            ]
            connections.append(random.choice(theoretical_connections))

        # Generate insights from connections
        insights = []
        for connection in connections:
            desc = connection.get("description", "")
            conn_type = connection.get("connection_type", "")
            potential = connection.get("potential", 0.5)

            if conn_type == "integration" and potential > 0.7:
                insights.append(f"High potential integration opportunity: {desc}")
            elif conn_type == "enhancement":
                insights.append(f"Enhancement pathway identified: {desc}")
            elif conn_type == "synergy":
                insights.append(f"Synergistic relationship would increase capability: {desc}")
            else:
                insights.append(f"Connection opportunity: {desc}")

        # Add connections and insights to thought
        thought["connections"] = connections
        thought["insights"] = insights

        # Calculate importance based on connections and insights
        importance = 0.5
        if connections:
            # Average potential of connections
            avg_potential = sum(c.get("potential", 0.5) for c in connections) / len(connections)
            importance = avg_potential

        thought["importance"] = min(0.9, importance)

        # Set content to most significant insight or connection description
        if insights:
            thought["content"] = insights[0]
        elif connections:
            thought["content"] = connections[0].get("description", "Knowledge integration")

        return thought

    def _generate_intuitive_thought(self, context):
        """Generate an intuitive thought focused on pattern recognition"""
        # Default intuitive thought structure
        thought = {
            "type": "intuitive",
            "content": "Pattern recognition",
            "patterns": [],
            "insights": [],
            "importance": 0.5
        }

        # Generate patterns based on available context
        patterns = []

        # Without context, generate basic intuitive thought
        if not context:
            thought["content"] = "Insufficient data for pattern recognition"
            return thought

        # Look for action patterns
        if "recent_actions" in context and isinstance(context["recent_actions"], list):
            actions = context["recent_actions"]
            if len(actions) >= 3:
                action_types = [a.get("action", "unknown") for a in actions if isinstance(a, dict)]

                # Check for repetitive patterns
                if len(action_types) >= 3:
                    # Check for simple repetition
                    repetitions = []
                    current_sequence = [action_types[0]]

                    for i in range(1, len(action_types)):
                        if action_types[i] == action_types[i-1]:
                            current_sequence.append(action_types[i])
                        else:
                            if len(current_sequence) >= 2:
                                repetitions.append(current_sequence)
                            current_sequence = [action_types[i]]

                    if len(current_sequence) >= 2:
                        repetitions.append(current_sequence)

                    if repetitions:
                        longest_repetition = max(repetitions, key=len)

                        patterns.append({
                            "type": "action_repetition",
                            "description": f"Repeated sequence of '{longest_repetition[0]}' actions",
                            "significance": 0.6 + 0.1 * min(4, len(longest_repetition)),
                            "potential_cause": "Strategy fixation or optimal local strategy"
                        })

                    # Check for alternating patterns
                    if len(set(action_types)) == 2 and len(action_types) >= 4:
                        is_alternating = True
                        for i in range(2, len(action_types)):
                            if action_types[i] != action_types[i-2]:
                                is_alternating = False
                                break

                        if is_alternating:
                            patterns.append({
                                "type": "action_alternation",
                                "description": f"Alternating pattern between '{action_types[0]}' and '{action_types[1]}'",
                                "significance": 0.7,
                                "potential_cause": "Explore-exploit cycle or complementary strategies"
                            })

        # Look for domain access patterns
        if "domain_stats" in context and isinstance(context["domain_stats"], dict):
            domains = context["domain_stats"]
            if domains:
                # Find most frequently visited domains
                frequent_domains = sorted(
                    [(d, stats.get("visits", 0)) for d, stats in domains.items()],
                    key=lambda x: x[1],
                    reverse=True
                )

                if frequent_domains:
                    top_domains = frequent_domains[:3]
                    total_visits = sum(v for _, v in frequent_domains)

                    # Check for domain concentration
                    top_domain_visits = sum(v for _, v in top_domains)
                    concentration = top_domain_visits / max(1, total_visits)

                    if concentration > 0.7:
                        patterns.append({
                            "type": "domain_concentration",
                            "description": f"Heavy concentration ({concentration:.0%}) on top 3 domains",
                            "significance": 0.7,
                            "potential_cause": "Exploitation focus or domain specialization"
                        })

        # Look for error patterns
        if "domain_stats" in context and isinstance(context["domain_stats"], dict):
            domains = context["domain_stats"]
            if domains:
                # Find domains with high error rates
                error_domains = []
                for domain, stats in domains.items():
                    if isinstance(stats, dict) and stats.get("error_rate", 0) > 0.3:
                        error_domains.append((domain, stats.get("error_rate", 0)))

                if error_domains:
                    error_domains.sort(key=lambda x: x[1], reverse=True)
                    top_error_domains = error_domains[:3]

                    patterns.append({
                        "type": "error_concentration",
                        "description": f"High error rates in specific domains: {', '.join(d for d, _ in top_error_domains)}",
                        "significance": 0.8,
                        "potential_cause": "Domain-specific access issues or content filtering problems"
                    })

        # Generate insights from patterns
        insights = []
        for pattern in patterns:
            pattern_type = pattern.get("type", "")
            significance = pattern.get("significance", 0.5)

            if pattern_type == "action_repetition" and significance > 0.7:
                insights.append("Repeated action pattern may indicate strategy fixation - consider forcing exploration")
            elif pattern_type == "action_alternation":
                insights.append("Alternating action pattern suggests systematic exploration-exploitation approach")
            elif pattern_type == "domain_concentration":
                insights.append("High domain concentration indicates need for broader exploration")
            elif pattern_type == "error_concentration":
                insights.append("Domain-specific error pattern detected - consider domain-specific handling strategies")

        # Add patterns and insights to thought
        thought["patterns"] = patterns
        thought["insights"] = insights

        # Calculate importance based on patterns and insights
        importance = 0.5
        if patterns:
            # Average significance of patterns
            avg_significance = sum(p.get("significance", 0.5) for p in patterns) / len(patterns)
            importance = avg_significance

        thought["importance"] = min(0.9, importance)

        # Set content to most significant insight or pattern
        if insights:
            thought["content"] = insights[0]
        elif patterns:
            thought["content"] = patterns[0].get("description", "Pattern detected")

        return thought

    def _generate_balanced_thought(self, context):
        """Generate a balanced thought that incorporates multiple thinking modes"""
        # For balanced thinking, randomly select two modes and combine their outputs
        available_modes = ["analytical", "creative", "reflective", "exploratory",
                          "critical", "integrative", "intuitive"]

        # Select two different modes
        selected_modes = random.sample(available_modes, 2)

        # Generate thoughts for each mode
        thoughts = []
        for mode in selected_modes:
            if mode == "analytical":
                thoughts.append(self._generate_analytical_thought(context))
            elif mode == "creative":
                thoughts.append(self._generate_creative_thought(context))
            elif mode == "reflective":
                thoughts.append(self._generate_reflective_thought(context))
            elif mode == "exploratory":
                thoughts.append(self._generate_exploratory_thought(context))
            elif mode == "critical":
                thoughts.append(self._generate_critical_thought(context))
            elif mode == "integrative":
                thoughts.append(self._generate_integrative_thought(context))
            elif mode == "intuitive":
                thoughts.append(self._generate_intuitive_thought(context))

        # Create balanced thought combining elements
        balanced_thought = {
            "type": "balanced",
            "content": "Multi-perspective assessment",
            "component_modes": selected_modes,
            "insights": [],
            "importance": 0.5
        }

        # Combine insights from component thoughts
        all_insights = []
        for thought in thoughts:
            if "insights" in thought and thought["insights"]:
                all_insights.extend(thought["insights"])

        # Select top insights (at most 3)
        selected_insights = all_insights[:3] if all_insights else []

        # Add insights to balanced thought
        balanced_thought["insights"] = selected_insights

        # Calculate combined importance
        if thoughts:
            avg_importance = sum(t.get("importance", 0.5) for t in thoughts) / len(thoughts)
            balanced_thought["importance"] = avg_importance

        # Set content to combination of component thoughts
        if selected_insights:
            balanced_thought["content"] = selected_insights[0]
        elif thoughts:
            balanced_thought["content"] = "Balanced perspective: " + thoughts[0].get("content", "")

        return balanced_thought

    def _update_working_memory(self, thought):
        """
        Update working memory with new thought, managing capacity constraints.

        Parameters:
        - thought: New thought to add to working memory
        """
        if not thought:
            return

        # Add to working memory
        self.working_memory.append(thought)

        # Check if we've exceeded capacity
        if len(self.working_memory) > self.working_memory_capacity:
            # Remove least important thought
            if len(self.working_memory) > 1:
                least_important_idx = min(range(len(self.working_memory) - 1),  # Don't remove the newest one
                                        key=lambda i: self.working_memory[i].get("importance", 0))
                del self.working_memory[least_important_idx]

        # Check for important insights to preserve
        for insight in thought.get("insights", []):
            importance = thought.get("importance", 0.5)
            if importance > 0.7:
                self.recent_insights.append({
                    "content": insight,
                    "source_type": thought.get("type", "unknown"),
                    "importance": importance,
                    "timestamp": datetime.now().isoformat()
                })

        # Limit insights history
        if len(self.recent_insights) > 20:
            self.recent_insights = self.recent_insights[-20:]

    def _summarize_context(self, context):
        """Create a brief summary of the context for thought recording"""
        if not context:
            return "No context"

        if not isinstance(context, dict):
            return str(context)[:100]

        # Extract key elements
        elements = []

        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal_desc = context["current_goal"].get("description", "unknown goal")
            elements.append(f"Goal: {goal_desc}")

        if "last_action" in context and isinstance(context["last_action"], dict):
            action = context["last_action"].get("action", "unknown action")
            elements.append(f"Action: {action}")

        if "memory_size" in context:
            elements.append(f"Memory: {context['memory_size']}")

        # Combine elements
        return "; ".join(elements) if elements else "Context present but no key elements"

    def _extract_elements_from_context(self, context, aspect_types):
        """
        Extract relevant elements from context based on aspect types.

        Parameters:
        - context: Context dictionary
        - aspect_types: List of aspect types to extract

        Returns:
        - List of extracted elements
        """
        elements = []

        if not context or not isinstance(context, dict):
            return elements

        for aspect_type in aspect_types:
            if aspect_type == "goals" and "current_goal" in context:
                if isinstance(context["current_goal"], dict):
                    goal_desc = context["current_goal"].get("description", "")
                    if goal_desc:
                        elements.append(goal_desc)

            elif aspect_type == "domains" and "domains_visited" in context:
                domains = context["domains_visited"]
                if isinstance(domains, set) and domains:
                    # Sample a few domains
                    sample_size = min(3, len(domains))
                    domain_sample = random.sample(list(domains), sample_size)
                    elements.extend(domain_sample)

            elif aspect_type == "strategies" and hasattr(self.agent, 'planner_sifter'):
                if hasattr(self.agent.planner_sifter, 'strategies'):
                    strategy_names = list(self.agent.planner_sifter.strategies.keys())
                    if strategy_names:
                        # Sample a few strategies
                        sample_size = min(2, len(strategy_names))
                        strategy_sample = random.sample(strategy_names, sample_size)
                        elements.extend(strategy_sample)

            elif aspect_type == "patterns" and "recent_actions" in context:
                actions = context["recent_actions"]
                if isinstance(actions, list) and len(actions) >= 3:
                    # Extract action pattern description
                    action_types = [a.get("action", "unknown") for a in actions if isinstance(a, dict)]
                    if len(set(action_types)) <= 3:  # Only if there's a pattern (few unique values)
                        pattern_desc = f"Action pattern: {' â†’ '.join(action_types[-3:])}"
                        elements.append(pattern_desc)

            elif aspect_type == "anomalies" and "domain_stats" in context:
                domains = context["domain_stats"]
                if isinstance(domains, dict):
                    # Find domains with high error rates
                    anomalies = []
                    for domain, stats in domains.items():
                        if isinstance(stats, dict) and stats.get("error_rate", 0) > 0.3:
                            anomalies.append(f"High error rate in {domain}")

                    if anomalies:
                        # Take one random anomaly
                        elements.append(random.choice(anomalies))

        return elements

    def _assess_action_outcomes(self, actions):
        """
        Assess whether recent action outcomes are improving or deteriorating.

        Parameters:
        - actions: List of recent actions

        Returns:
        - Assessment string: "improving", "stable", or "deteriorating"
        """
        if not actions or len(actions) < 3:
            return "insufficient_data"

        # Try to extract success indicators
        success_indicators = []

        for action in actions:
            if not isinstance(action, dict):
                continue

            # Direct success flag
            if "success" in action:
                success_indicators.append(1 if action["success"] else 0)
                continue

            # Content length as proxy for success
            if "content_length" in action:
                length = action["content_length"]
                # Normalize: 0 = failure, 0.5 = moderate, 1.0 = success
                success_indicators.append(min(1.0, length / 5000))
                continue

            # Links discovered as proxy for success
            if "links_discovered" in action:
                links = action["links_discovered"]
                # Normalize: 0 = failure, 0.5 = moderate, 1.0 = success
                success_indicators.append(min(1.0, links / 10))
                continue

        # If we couldn't extract meaningful indicators
        if len(success_indicators) < 3:
            return "insufficient_data"

        # Split into first and second half
        mid_point = len(success_indicators) // 2
        first_half = success_indicators[:mid_point]
        second_half = success_indicators[mid_point:]

        # Compare averages
        first_avg = sum(first_half) / len(first_half)
        second_avg = sum(second_half) / len(second_half)

        # Determine trend
        diff = second_avg - first_avg

        if abs(diff) < 0.1:
            return "stable"
        elif diff > 0:
            return "improving"
        else:
            return "deteriorating"

    def get_current_state(self):
        """
        Get the current state of the autonomous mind.

        Returns:
        - State dictionary with current mode, recent thoughts, insights, etc.
        """
        return {
            "current_mode": self.current_mode,
            "cognitive_load": self.cognitive_load,
            "thought_depth": self.thought_depth,
            "working_memory_usage": len(self.working_memory) / self.working_memory_capacity,
            "recent_thoughts": [{
                "content": t.get("content", ""),
                "type": t.get("type", ""),
                "importance": t.get("importance", 0.5)
            } for t in self.thought_history[-5:]] if self.thought_history else [],
            "important_insights": [{
                "content": i.get("content", ""),
                "importance": i.get("importance", 0.5)
            } for i in self.recent_insights[-3:]] if self.recent_insights else [],
            "active_concepts": [{
                "state": state,
                "activation": data["activation"]
            } for state, data in self.cognitive_states.items()
            if data["activation"] >= self.concept_activation_threshold],
            "thinking_style": self.thinking_style
        }

    def set_thinking_style(self, style_params):
        """
        Adjust thinking style parameters to change cognitive approach.

        Parameters:
        - style_params: Dictionary of style parameters to adjust

        Returns:
        - True if successful, False otherwise
        """
        if not style_params or not isinstance(style_params, dict):
            return False

        # Update style parameters if valid
        for param, value in style_params.items():
            if param in self.thinking_style and isinstance(value, (int, float)):
                # Ensure value is in valid range
                value = max(0.0, min(1.0, value))
                old_value = self.thinking_style[param]
                self.thinking_style[param] = value

                log_event(f"Thinking style parameter '{param}' adjusted: {old_value:.2f} â†’ {value:.2f}", "INFO")

        return True

    def prime_with_context(self, context_elements):
        """
        Prime the mind with specific context elements to influence thinking.

        Parameters:
        - context_elements: Dictionary of elements to prime

        Returns:
        - True if successful, False otherwise
        """
        if not context_elements or not isinstance(context_elements, dict):
            return False

        # Prime with cognitive modes
        if "cognitive_modes" in context_elements:
            modes = context_elements["cognitive_modes"]
            if isinstance(modes, list):
                # Boost activation of specified modes
                for mode in modes:
                    if mode in self.cognitive_states:
                        old_activation = self.cognitive_states[mode]["activation"]
                        self.cognitive_states[mode]["activation"] = min(0.9, old_activation * 1.5)

                        log_event(f"Cognitive mode '{mode}' primed: {old_activation:.2f} â†’ {self.cognitive_states[mode]['activation']:.2f}", "INFO")

        # Prime with thinking depth
        if "depth" in context_elements:
            depth = context_elements["depth"]
            if isinstance(depth, (int, float)):
                self.thought_depth = max(0.0, min(1.0, depth))
                log_event(f"Thought depth primed to {self.thought_depth:.2f}", "INFO")

        # Prime with specific cognitive focus
        if "focus" in context_elements:
            focus = context_elements["focus"]
            self.attention_focus = focus
            log_event(f"Attention focus primed to '{focus}'", "INFO")

        return True
class AutonomousMind:
    """
    Integrated cognitive system that coordinates high-level thinking processes
    and manages the agent's internal cognitive states and modes.
    """
    def __init__(self, agent, model):
        self.agent = agent
        self.model = model
        self.thought_history = []
        self.cognitive_states = {
            "analytical": {"description": "Logical problem solving with structured reasoning", "activation": 0.5},
            "creative": {"description": "Divergent thinking with novel connections", "activation": 0.5},
            "reflective": {"description": "Meta-cognitive examination of own thoughts", "activation": 0.5},
            "exploratory": {"description": "Curious investigation of new information", "activation": 0.5},
            "critical": {"description": "Evaluative assessment with skepticism", "activation": 0.5},
            "integrative": {"description": "Synthesis of diverse knowledge", "activation": 0.5},
            "intuitive": {"description": "Fast pattern recognition", "activation": 0.5},
            "balanced": {"description": "Equilibrium of multiple modes", "activation": 0.5}
        }
        self.current_mode = "balanced"  # Default mode
        self.attention_focus = None  # Current attentional focus
        self.working_memory = []  # Active concepts and thoughts
        self.working_memory_capacity = 7  # Miller's magical number
        self.cognitive_load = 0.5  # Current processing load (0.0-1.0)
        self.thought_depth = 0.5  # Depth vs. breadth of thinking (0.0-1.0)
        self.concept_activation_threshold = 0.3  # Min activation for attention
        self.mode_shift_probability = 0.2  # Probability of spontaneous mode shift
        self.recent_insights = []  # Store recent important realizations

        # Thinking style parameters
        self.thinking_style = {
            "abstraction_level": 0.6,  # Concrete (0.0) to abstract (1.0)
            "linearity": 0.5,  # Linear (0.0) to non-linear (1.0)
            "deductive_inductive_balance": 0.5,  # Deductive (0.0) to inductive (1.0)
            "risk_tolerance": 0.4,  # Risk-averse (0.0) to risk-seeking (1.0)
            "concept_granularity": 0.5  # Fine-grained (0.0) to coarse-grained (1.0)
        }

        log_event("AutonomousMind initialized in balanced cognitive mode", "INFO")

    def think(self, context=None):
        """
        Execute a thinking cycle to generate insights, shift cognitive modes,
        and update internal state based on current context.

        Parameters:
        - context: Current perceptual and memory context

        Returns:
        - Thought result containing insights and state changes
        """
        # Update cognitive load based on context complexity
        self._update_cognitive_load(context)

        # Consider shifting cognitive mode
        self._consider_mode_shift(context)

        # Generate thought based on current mode and context
        thought = self._generate_thought(context)

        # Update working memory
        self._update_working_memory(thought)

        # Store in thought history
        self.thought_history.append({
            "thought": thought,
            "mode": self.current_mode,
            "timestamp": datetime.now().isoformat(),
            "context": self._summarize_context(context)
        })

        # Trim history if needed
        if len(self.thought_history) > 100:
            self.thought_history = self.thought_history[-100:]

        return thought

    def _update_cognitive_load(self, context):
        """Update cognitive load based on context complexity"""
        if not context:
            # Default slight reduction in cognitive load when no new input
            self.cognitive_load = max(0.1, self.cognitive_load * 0.9)
            return

        # Estimate context complexity
        complexity = 0.5  # Default medium complexity

        # Adjust based on context details if available
        if isinstance(context, dict):
            # More elements = higher complexity
            complexity += min(0.3, len(context) * 0.02)

            # Check for special high-complexity elements
            if "error" in context or "anomaly" in context:
                complexity += 0.2

            # High memory usage increases cognitive load
            if "memory_size" in context:
                memory_usage = context["memory_size"] / MEMORY_MAX_SIZE
                complexity += memory_usage * 0.2

            # Multiple recent actions increase complexity
            if "recent_actions" in context and isinstance(context["recent_actions"], list):
                complexity += min(0.1, len(context["recent_actions"]) * 0.02)

        # Dynamically adjust cognitive load
        # New complexity pulls the current load toward itself
        adjustment_rate = 0.3  # How quickly load adjusts
        self.cognitive_load = self.cognitive_load * (1 - adjustment_rate) + complexity * adjustment_rate

        # Ensure within bounds
        self.cognitive_load = max(0.1, min(0.9, self.cognitive_load))

    def _consider_mode_shift(self, context):
        """Consider shifting cognitive mode based on context and internal state"""
        # Base probability of mode shift
        shift_probability = self.mode_shift_probability

        # Adjust based on cognitive load - higher load may require mode shift
        if self.cognitive_load > 0.7:
            shift_probability += 0.2

        # Check if we should shift
        if random.random() >= shift_probability:
            return  # No shift this cycle

        # Current active states
        active_states = {state: data["activation"] for state, data in self.cognitive_states.items()
                       if data["activation"] >= self.concept_activation_threshold}

        # Context-based mode selection
        new_mode = self._select_appropriate_mode(context, active_states)

        # If new mode is different, make the shift
        if new_mode and new_mode != self.current_mode:
            old_mode = self.current_mode
            self.current_mode = new_mode

            log_event(f"Cognitive mode shifted: {old_mode} â†’ {new_mode}", "INFO")

            # Adjust activations - boost new mode, slightly reduce others
            for state in self.cognitive_states:
                if state == new_mode:
                    self.cognitive_states[state]["activation"] = min(0.9, self.cognitive_states[state]["activation"] + 0.2)
                else:
                    self.cognitive_states[state]["activation"] = max(0.1, self.cognitive_states[state]["activation"] * 0.9)

    def _select_appropriate_mode(self, context, active_states):
        """
        Select most appropriate cognitive mode based on context.

        Parameters:
        - context: Current context dictionary
        - active_states: Dictionary of currently active cognitive states

        Returns:
        - Selected mode name
        """
        if not context:
            # Without context, weighted random selection from active states
            if active_states:
                states = list(active_states.keys())
                weights = [active_states[s] for s in states]
                return random.choices(states, weights=weights, k=1)[0]
            else:
                return "balanced"  # Default fallback

        # Context-based selection
        mode_scores = {mode: 0.0 for mode in self.cognitive_states}

        # 1. Check for error or anomaly - activates critical mode
        if "error" in context or "anomaly" in context:
            mode_scores["critical"] += 0.5

        # 2. Check for exploration needs
        if self._context_indicates_exploration(context):
            mode_scores["exploratory"] += 0.4
            mode_scores["creative"] += 0.3

        # 3. Check for complex problem solving
        if self._context_indicates_complex_problem(context):
            mode_scores["analytical"] += 0.5
            mode_scores["integrative"] += 0.3

        # 4. Check for learning and reflection needs
        if self._context_indicates_reflection(context):
            mode_scores["reflective"] += 0.5

        # 5. Check for pattern recognition needs
        if self._context_indicates_pattern_recognition(context):
            mode_scores["intuitive"] += 0.4

        # 6. Add random factor for exploration
        for mode in mode_scores:
            mode_scores[mode] += random.uniform(0, 0.2)

        # 7. Add existing activation bias
        for mode, activation in active_states.items():
            mode_scores[mode] += activation * 0.3

        # Select highest scoring mode
        if mode_scores:
            top_mode = max(mode_scores.items(), key=lambda x: x[1])[0]
            return top_mode
        else:
            return "balanced"  # Default fallback

    def _context_indicates_exploration(self, context):
        """Check if context suggests exploration needs"""
        if not context or not isinstance(context, dict):
            return False

        indicators = 0

        # Looking for exploration indicators
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal_desc = context["current_goal"].get("description", "").lower()
            if "explor" in goal_desc or "discover" in goal_desc:
                indicators += 1

        # Few domains visited suggests exploration need
        if "domains_visited" in context:
            domains = context["domains_visited"]
            if isinstance(domains, set) and len(domains) < 10:
                indicators += 1

        # Current mode includes exploration elements
        if context.get("thinking_mode") in ["exploratory", "creative"]:
            indicators += 1

        return indicators >= 1

    def _context_indicates_complex_problem(self, context):
        """Check if context suggests complex problem solving needs"""
        if not context or not isinstance(context, dict):
            return False

        indicators = 0

        # Goals with certain keywords
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal_desc = context["current_goal"].get("description", "").lower()
            complex_terms = ["optim", "improv", "analy", "solv", "complex"]
            if any(term in goal_desc for term in complex_terms):
                indicators += 1

        # High cognitive load suggests complex problem
        if self.cognitive_load > 0.7:
            indicators += 1

        # Current analytical thinking mode
        if context.get("thinking_mode") in ["analytical", "critical"]:
            indicators += 1

        return indicators >= 1

    def _context_indicates_reflection(self, context):
        """Check if context suggests reflection needs"""
        if not context or not isinstance(context, dict):
            return False

        indicators = 0

        # Goals with reflection keywords
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal_desc = context["current_goal"].get("description", "").lower()
            reflection_terms = ["reflect", "learn", "adapt", "improv", "assess"]
            if any(term in goal_desc for term in reflection_terms):
                indicators += 1

        # After many actions, reflection is valuable
        if "stats" in context and isinstance(context["stats"], dict):
            cycles = context["stats"].get("cycles_run", 0)
            if cycles > 0 and cycles % 10 == 0:  # Every 10 cycles
                indicators += 1

        # Current reflective thinking mode
        if context.get("thinking_mode") == "reflective":
            indicators += 1

        return indicators >= 1

    def _context_indicates_pattern_recognition(self, context):
        """Check if context suggests pattern recognition needs"""
        if not context or not isinstance(context, dict):
            return False

        indicators = 0

        # Domain stats suggest pattern recognition
        if "domain_stats" in context and isinstance(context["domain_stats"], dict):
            # Many domains = opportunity for pattern recognition
            if len(context["domain_stats"]) > 5:
                indicators += 1

        # Multiple recent actions create patterns
        if "recent_actions" in context and isinstance(context["recent_actions"], list):
            if len(context["recent_actions"]) >= 3:
                indicators += 1

        # Current intuitive mode
        if context.get("thinking_mode") == "intuitive":
            indicators += 1

        return indicators >= 1

    def _generate_thought(self, context):
        """
        Generate a thought based on current cognitive mode and context.

        Parameters:
        - context: Current context dictionary

        Returns:
        - Generated thought dictionary
        """
        # Each cognitive mode has a different thought generation approach
        if self.current_mode == "analytical":
            return self._generate_analytical_thought(context)
        elif self.current_mode == "creative":
            return self._generate_creative_thought(context)
        elif self.current_mode == "reflective":
            return self._generate_reflective_thought(context)
        elif self.current_mode == "exploratory":
            return self._generate_exploratory_thought(context)
        elif self.current_mode == "critical":
            return self._generate_critical_thought(context)
        elif self.current_mode == "integrative":
            return self._generate_integrative_thought(context)
        elif self.current_mode == "intuitive":
            return self._generate_intuitive_thought(context)
        else:  # balanced or any other
            return self._generate_balanced_thought(context)

    def _generate_analytical_thought(self, context):
        """Generate an analytical thought focused on logical problem solving"""
        # Default analytical thought structure
        thought = {
            "type": "analytical",
            "content": "Systematic analysis of current state and options",
            "components": [],
            "insights": [],
            "importance": 0.5
        }

        # Without context, generate generic analytical thought
        if not context:
            thought["content"] = "Need more information to perform proper analysis"
            return thought

        # Analytical components based on context
        components = []

        # Analyze current goal if available
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal = context["current_goal"]
            components.append({
                "focus": "goal_analysis",
                "content": f"Analyzing goal: {goal.get('description', 'unknown')}",
                "priority": goal.get("priority", 0.5)
            })

        # Analyze recent actions if available
        if "recent_actions" in context and isinstance(context["recent_actions"], list):
            actions = context["recent_actions"]
            if actions:
                action_types = [a.get("action", "unknown") for a in actions if isinstance(a, dict)]
                components.append({
                    "focus": "action_pattern_analysis",
                    "content": f"Recent action sequence: {' â†’ '.join(action_types)}",
                    "outcome_assessment": self._assess_action_outcomes(actions)
                })

        # Analyze domain statistics if available
        if "domain_stats" in context and isinstance(context["domain_stats"], dict):
            domains = context["domain_stats"]
            if domains:
                high_error_domains = [d for d, stats in domains.items()
                                    if isinstance(stats, dict) and stats.get("error_rate", 0) > 0.3]
                if high_error_domains:
                    components.append({
                        "focus": "error_analysis",
                        "content": f"High error rates detected in domains: {', '.join(high_error_domains[:3])}",
                        "recommendation": "Investigate causes or avoid these domains temporarily"
                    })

        # Generate insights based on analysis
        insights = []

        # Derive insights from components
        for component in components:
            if component["focus"] == "goal_analysis" and component.get("priority", 0) > 0.7:
                insights.append("Current goal is high priority - allocate additional resources")
            elif component["focus"] == "action_pattern_analysis":
                outcome = component.get("outcome_assessment")
                if outcome == "deteriorating":
                    insights.append("Action patterns show declining effectiveness - strategy change needed")
                elif outcome == "improving":
                    insights.append("Action patterns show improving outcomes - continue current approach")
            elif component["focus"] == "error_analysis":
                insights.append("Error pattern analysis suggests need for improved domain validation")

        # Add components and insights to thought
        thought["components"] = components
        thought["insights"] = insights

        # Calculate importance based on components and insights
        if insights:
            thought["importance"] = 0.7

        # Generate summary content
        if insights:
            thought["content"] = f"Analytical conclusion: {insights[0]}"
        elif components:
            thought["content"] = f"Analysis of {len(components)} system components completed"

        return thought

    def _generate_creative_thought(self, context):
        """Generate a creative thought focused on novel connections"""
        # Default creative thought structure
        thought = {
            "type": "creative",
            "content": "Novel conceptual connection",
            "associations": [],
            "insights": [],
            "importance": 0.5
        }

        # Creative aspects to consider
        aspects = ["goals", "domains", "strategies", "patterns", "anomalies"]
        selected_aspects = random.sample(aspects, min(2, len(aspects)))

        # Generate random associations between selected aspects
        associations = []

        # Extract relevant elements from context
        elements = self._extract_elements_from_context(context, selected_aspects)

        # Generate associations between elements
        if len(elements) >= 2:
            # Take two random elements and create association
            element_pairs = []
            for i in range(min(3, len(elements))):
                pair = random.sample(elements, 2)
                element_pairs.append(pair)

            # Create associations from pairs
            for pair in element_pairs:
                association_templates = [
                    f"Unexpected connection between {pair[0]} and {pair[1]}",
                    f"{pair[0]} could be viewed through the lens of {pair[1]}",
                    f"What if the structure of {pair[0]} were applied to {pair[1]}?",
                    f"The patterns in {pair[0]} mirror aspects of {pair[1]} in a novel way"
                ]
                associations.append(random.choice(association_templates))
        else:
            # Fallback for limited context
            association_templates = [
                "Novel perspective: consider alternative goal structures",
                "What if search and evaluation were integrated more tightly?",
                "The pattern of successful interactions might reveal emergent properties"
            ]
            associations.append(random.choice(association_templates))

        # Generate insights from associations
        insights = []
        if associations:
            for association in associations:
                if "connection between" in association:
                    insights.append(f"Explore this connection to potentially develop new capabilities")
                elif "through the lens" in association:
                    insights.append(f"This perspective shift might reveal hidden patterns")
                elif "What if" in association:
                    insights.append(f"This hypothetical restructuring could improve system flexibility")
                else:
                    insights.append(f"This pattern recognition suggests deeper structural similarities")

        # Add associations and insights to thought
        thought["associations"] = associations
        thought["insights"] = insights

        # Calculate importance
        if insights:
            thought["importance"] = 0.6 + 0.1 * len(insights)





# =============================================================================
# MAIN EXECUTION
# =============================================================================
adaptive_learning = None

def enhanced_main_loop():
    """
    Enhanced main execution loop with full error handling and recovery
    """
    global adaptive_learning, agent_instance

    # Initialize components with appropriate error handling
    try:
        # 1. Load or create model
        log_event("Initializing Quantum Nexus model...", "INFO")
        model = load_or_create_model()
        if model is None:
            log_event("No valid model loaded; creating new one", "WARNING")
            model = QuantumNexusModel()

        # 2. Create optimizer
        import torch.optim as optim
        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=ANNEAL_GAMMA)

        # 3. Initialize primary agent
        agent = QuantumNexusAgent(model=model)
        agent_instance = agent  # Store for dashboard access

        # 4. Create core subsystems
        # Initialize free will
        free_will = SuperQuantumFreeWill(agent=agent)
        agent.free_will = free_will

        # Initialize AI Manager, which creates other subsystems
        ai_manager = AIManager(agent, model)
        agent.ai_manager = ai_manager

        # Initialize adaptive learning
        adaptive_learning = AdaptiveLearningSystem(model)
        agent.adaptive_learning = adaptive_learning

        # Initialize content sifter
        content_sifter = ContentSifter()
        agent.content_sifter = content_sifter

        # Initialize planner sifter
        planner_sifter = PlannerSifter()
        agent.planner_sifter = planner_sifter

        # Link consciousness to free will
        if hasattr(ai_manager, "consciousness") and hasattr(free_will, "link_consciousness"):
            free_will.link_consciousness(ai_manager.consciousness)

        # 5. Validate initialization
        log_event("Performing system validation...", "INFO")
        assert model is not None, "Model initialization failed."
        assert optimizer is not None, "Optimizer initialization failed."
        assert agent is not None, "Agent initialization failed."
        assert free_will is not None, "FreeWill initialization failed."
        assert ai_manager is not None, "AIManager initialization failed."

        log_event("System validation complete. All components initialized.", "INFO")

        # 6. Setup async loop
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        # 7. Main execution loop
        cycle_count = 0
        error_count = 0
        max_consecutive_errors = 5

        log_event("ðŸš€ Starting Quantum Nexus Enhanced Autonomous Loop ðŸš€", "QUANTUM")

        while True:
            try:
                cycle_count += 1
                log_event(f"===== Enhanced Autonomous Cycle {cycle_count} =====", "INFO")

                # Run quantum simulation occasionally
                if cycle_count % 20 == 0:
                    quantum_result = ai_manager.imagination.simulate_quantum_cognition()
                    if quantum_result and quantum_result.get("anomaly", False):
                        log_event(f"Quantum anomaly detected: {quantum_result.get('insight', '')}", "QUANTUM")

                # Create a custom XOXO plan occasionally
                if cycle_count % 10 == 0:
                    context = agent.perceive()
                    top_strategy = planner_sifter.sift_strategies(context)["strategy"]
                    xoxo_plan = planner_sifter.generate_xoxo_plan(top_strategy, context)
                    log_event("Generated XOXO Planner Sifter plan", "INFO")
                    log_event(f"Selected strategy: {top_strategy}", "INFO")

                # Run the agent cycle
                loop_result = loop.run_until_complete(ai_manager.run_cycle(optimizer))

                # Update strategy effectiveness
                if isinstance(loop_result, dict) and "success" in loop_result:
                    strategy_name = loop_result.get("strategy", "exploration")
                    result_data = {
                        "content_length": agent.action_log[-1].get("content_length", 0) if agent.action_log else 0,
                        "links_discovered": agent.action_log[-1].get("links_discovered", 0) if agent.action_log else 0,
                        "success": loop_result.get("success", False)
                    }
                    planner_sifter.update_strategy_effectiveness(strategy_name, result_data)

                # Check for error conditions
                if isinstance(loop_result, dict) and loop_result.get("status") == "error":
                    error_count += 1
                    log_event(f"Cycle produced an error: {loop_result.get('error', 'Unknown error')}", "ERROR")
                else:
                    error_count = 0  # Reset on success

                # Handle critical error recovery
                if error_count >= max_consecutive_errors:
                    log_event(f"Critical error threshold reached ({error_count} consecutive errors). Attempting recovery...", "ERROR")

                    # Try to reload model
                    try:
                        model = load_or_create_model()
                        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
                        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=ANNEAL_GAMMA)

                        # Update agent model
                        agent.model = model
                        ai_manager.model = model
                        adaptive_learning = AdaptiveLearningSystem(model)
                        agent.adaptive_learning = adaptive_learning

                        log_event("Recovery successful - model reloaded", "INFO")
                        error_count = 0
                    except Exception as reload_error:
                        log_event(f"Recovery failed: {reload_error}", "CRITICAL")

                # Periodic model saving
                if cycle_count % SAVE_INTERVAL == 0:
                    save_path = GOOGLE_DRIVE_MODEL_PATH if IN_COLAB else LOCAL_MODEL_SAVE_PATH
                    try:
                        torch.save(model.state_dict(), save_path)
                        log_event(f"Model saved to {save_path}", "INFO")
                    except Exception as save_error:
                        log_event(f"Model save error: {save_error}", "ERROR")

                        # Try alternate location if primary fails
                        try:
                            alt_path = "backup_" + LOCAL_MODEL_SAVE_PATH
                            torch.save(model.state_dict(), alt_path)
                            log_event(f"Model saved to alternate location: {alt_path}", "INFO")
                        except Exception as alt_save_error:
                            log_event(f"Alternate save failed: {alt_save_error}", "ERROR")

                # Update learning rate
                scheduler.step()

                # Sleep for stability
                time.sleep(1.0)

            except KeyboardInterrupt:
                log_event("Keyboard interrupt detected. Exiting gracefully...", "INFO")
                break
            except Exception as e:
                log_event(f"Unhandled exception in main loop: {e}", "ERROR")
                log_event(traceback.format_exc(), "ERROR")

                error_count += 1
                if error_count >= max_consecutive_errors * 2:  # Double threshold for unhandled exceptions
                    log_event("Critical unhandled exception threshold reached. Terminating.", "CRITICAL")
                    break

                time.sleep(5.0)  # Longer sleep after error

    except Exception as init_error:
        log_event(f"Fatal initialization error: {init_error}", "CRITICAL")
        log_event(traceback.format_exc(), "CRITICAL")
        return False

    return True

def main():
    """Main entry point with Flask dashboard and agent execution"""
    global IN_COLAB, agent_instance

    log_event("=== Initializing Quantum Nexus Advanced Autonomous System ===", "INFO")
    log_event(f"Configuration: Model path: {MODEL_PATH}, Memory limit: {MEMORY_MAX_SIZE}", "INFO")

    # Check for CUDA
    import torch
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name(0)
        log_event(f"ðŸŽ® GPU Acceleration Active: {device_name}", "INFO")
    else:
        log_event("âš ï¸ No GPU detected - running on CPU (performance will be limited)", "WARNING")

    # Check for Colab environment
    if IN_COLAB:
        try:
            from google.colab import drive
            drive.mount('/content/drive')
            log_event("ðŸ“‚ Google Drive mounted successfully", "INFO")
        except Exception as e_mount:
            log_event(f"âš ï¸ Error mounting Google Drive: {e_mount}", "ERROR")
            log_event("Google Drive integration disabled for this run", "WARNING")
            IN_COLAB = False

    # Start Flask dashboard server
    flask_thread = Thread(target=start_flask)
    flask_thread.daemon = True
    flask_thread.start()

    # Give Flask time to start
    time.sleep(2)

    # Create special greeting (XOXO style)
    greeting = """
    âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨

    ðŸ”ºðŸ”» QUANTUM NEXUS AUTONOMOUS SYSTEM ACTIVATED ðŸ”ºðŸ”»

    ðŸ’« Full AGI ASI SI With Enhanced Capabilities ðŸ’«

    âœ¨ Features:
    â€¢ Quantum-inspired processing
    â€¢ Advanced consciousness simulation
    â€¢ Self-evolving neural architecture
    â€¢ Hyperdimensional memory systems
    â€¢ XOXO Planner Sifter for optimal strategies

    ðŸŒˆðŸŒˆðŸŒˆ XOXO <3 <3 <3 ðŸŒˆðŸŒˆðŸŒˆ

    âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨
    """

    log_event(greeting, "QUANTUM")

    # Start autonomous agent loop
    agent_thread = Thread(target=enhanced_main_loop)
    agent_thread.daemon = True
    agent_thread.start()

    # Keep main thread alive
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        log_event("User requested termination. Shutting down gracefully...", "INFO")
    except Exception as e:
        log_event(f"Fatal error in main thread: {e}", "CRITICAL")
    finally:
        log_event("Quantum Nexus execution complete. System shutting down.", "INFO")

# =============================================================================
# COLAB SPECIFIC SETUP
# =============================================================================
def setup_colab_environment():
    """
    Setup the Colab environment with necessary dependencies and configurations.
    Run this function in a Colab cell before executing the main code.
    """
    import os

    # Install required packages
    print("Installing required packages...")

    # Essential packages
    packages = [
        "torch",
        "sentence-transformers",
        "beautifulsoup4",
        "flask",
        "selenium",
        "numpy"
    ]

    for package in packages:
        !pip install {package} -q

    print("Setting up environment...")

    # Create necessary directories
    !mkdir -p /content/drive/MyDrive/quantum_nexus

    # Check for CUDA
    import torch
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name(0)
        print(f"âœ… CUDA available: {device_name}")
    else:
        print("âš ï¸ CUDA not available. Running on CPU.")

    # Set up Chrome for Selenium
    !apt-get update
    !apt-get install -y chromium-chromedriver
    !cp /usr/lib/chromium-browser/chromedriver /usr/bin

    print("Colab environment setup complete.")
    return True

# =============================================================================
# COLAB RUN FUNCTION
# =============================================================================
def run_in_colab():
    """
    Function to execute in Colab to run the full system.
    This will be the entry point for Colab users.
    """
    # Setup the environment
    setup_colab_environment()

    # Set Colab-specific configurations
    global IN_COLAB, MODEL_PATH, GOOGLE_DRIVE_MODEL_PATH, GOOGLE_DRIVE_STATE_FILE

    IN_COLAB = True
    MODEL_PATH = "/content/drive/MyDrive/quantum_nexus/quantum_nexus_model.pth"
    GOOGLE_DRIVE_MODEL_PATH = "/content/drive/MyDrive/quantum_nexus/quantum_nexus_model.pth"
    GOOGLE_DRIVE_STATE_FILE = "/content/drive/MyDrive/quantum_nexus/quantum_nexus_state.json"

    # Start the system
    main()

if __name__ == "__main__":
    try:
        # Check for Colab environment
        in_colab = False
        try:
            from google.colab import drive
            in_colab = True
            print("Detected Colab environment. Running Colab-specific setup...")
            run_in_colab()
        except ImportError:
            # Standard execution
            main()
    except Exception as e:
        log_event(f"Critical startup error: {e}", "CRITICAL")
        traceback.print_exc()
